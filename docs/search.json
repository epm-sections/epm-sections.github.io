[
  {
    "objectID": "120B-F25/Wk06/wk6.html#announcements",
    "href": "120B-F25/Wk06/wk6.html#announcements",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Announcements",
    "text": "Announcements\n\nInformation about regrades\n\nAdditional Text"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#recap",
    "href": "120B-F25/Wk06/wk6.html#recap",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Recap",
    "text": "Recap\nFramework for Estimation\n\nGoal: estimate a particular population parameter.\nThree key terms:\n\nEstimand: another word for the parameter we are trying to estimate.\nEstimator: a statistic being used to estimate the estimand.\n\nAnother way to think about this: a “rule” used to estimate the parameter.\n\nEstimate: a particular realization (i.e. observed instance) of an estimator."
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#estimation",
    "href": "120B-F25/Wk06/wk6.html#estimation",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nAn Analogy\n\nHere’s an analogy from OpenIntro Statistics (a very good introductory statistics textbook!)\nSuppose we want to catch a fish in a murky lake, using a spear.\n\nThe location of the fish is akin to the estimand, and our spear throwing abilities are akin our estimator.\n\nOne strategy would be to throw the spear exactly where we last saw the fish.\n\nThis is like constructing an estimate from a realized dataset.\n\nBut, perhaps a better strategy is to throw a net in the vicinity of where we last saw the fish.\n\nSo, what’s the statistical analog of a net?"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nGeneral Setup\n\nInstead of reporting a single value as our estimate, we report an interval as our estimate.\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn interval estimator (aka confidence interval) is an interval \\[ \\left[ \\widehat{\\theta}_{L} \\ , \\ \\widehat{\\theta}_{U} \\right] \\] with random endpoints (i.e. point estimators) \\(\\widehat{\\theta}_{L}\\) and \\(\\widehat{\\theta}_{U}\\).\n\n\n\n\n\nWe set up our intervals to have specified coverage probability: \\[\\Prob( \\widehat{\\theta}_{L} \\leq \\theta \\leq \\widehat{\\theta}_U) = 1 - \\alpha \\]"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation-1",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nTwo Results\n\nNormal CI: \\(\\overline{Y}_n \\pm \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2} \\right) \\cdot \\frac{\\sigma}{\\sqrt{n}}\\)\n\nUse if the population is either normally distributed, or the sample size is large enough for the CLT to kick in\nUse if the population standard deviation \\(\\sigma\\) is known.\n\nt CI: \\(\\overline{Y}_n \\pm F_{t_{n - 1}}^{-1} \\left(1 - \\frac{\\alpha}{2} \\right) \\cdot \\frac{s}{\\sqrt{n}}\\)\n\nUse if the population is either normally distributed, or the sample size is large enough for the CLT to kick in\nUse if the population standard deviation \\(\\sigma\\) is unknown."
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation-2",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nInterpretation of Results\n\nSay \\([a, b]\\) is a numerical 95% confidence interval for \\(\\theta\\).\nThe interpretation of this interval is: we are 95% confident that the interval \\([a, b]\\) covers the true value of \\(\\theta\\).\n\nIt is INCORRECT to say that “there is a 95% probability that \\(\\theta\\) is in the interval \\([a, b]\\),” because none of these quantities (\\(a\\), \\(b\\), \\(\\theta\\)) are random!\n\nAn equivalent interpretation: the true value of \\(\\theta\\) is estimated to be between \\(a\\) and \\(b\\) for 95% of all intervals constructed from all possible samples."
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation-3",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nInterpretation of Results"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation-4",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation-4",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nInterpretation of Results"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#interval-estimation-5",
    "href": "120B-F25/Wk06/wk6.html#interval-estimation-5",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interval Estimation",
    "text": "Interval Estimation\nInterpretation of Results"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#consistency",
    "href": "120B-F25/Wk06/wk6.html#consistency",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nDefinition\n\n\n\n\n\n\nDefinition: Consistency\n\n\nAn estimator \\(\\widehat{\\theta}_n\\) is said to be a consistent estimator for \\(\\theta\\), denoted \\[ \\widehat{\\theta}_n \\probto \\theta \\] if, for any \\(\\varepsilon &gt; 0\\), either of the following equivalent statements hold: \\[\\begin{align*}\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon \\right)  & = 1 \\\\\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| &gt;  \\varepsilon \\right)  & = 0\n\\end{align*}\\]\n\n\n\n\nLet’s break this down."
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#consistency-1",
    "href": "120B-F25/Wk06/wk6.html#consistency-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nInterpretation\n\n\\(|\\widehat{\\theta}_n - \\theta|\\) is essentially the distance between \\(\\widehat{\\theta}_n\\) and \\(\\theta\\).\nSaying that \\(|\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon\\) for any \\(\\varepsilon &gt; 0\\) is saying that “the distance between \\(\\widehat{\\theta}_n\\) and \\(\\theta\\) is very small.”\n\nEquivalently: “\\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”\n\nThe definition of consistency asserts that this probability goes to zero as the sample size increases.\n\nThat is: “as our sample size becomes larger, we become more certain that \\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”\n\nSeems like a pretty nice property for an estimator to have, doesn’t it?"
  },
  {
    "objectID": "120B-F25/Wk06/wk6.html#consistency-2",
    "href": "120B-F25/Wk06/wk6.html#consistency-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nConsistency and Unbiasedness\n\nQuestion: are all consistent estimators unbiased?\n\nAnswer: no! For example, \\(S_n^2 := \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2\\) is a biased estimator for \\(\\sigma^2\\), but it turns out it is a consistent estimator for \\(\\sigma^2\\).\n\nQuestion: are all unbiased estimators consistent?\n\nAnswer: you tell me…\n\n\n\n\n\n\n\n\n\nTheorem 9.1\n\n\nAn unbiased estimator \\(\\widehat{\\theta}_n\\) for \\(\\theta\\) is consistent if \\(\\lim\\limits_{n \\to \\infty} \\Var(\\widehat{\\theta}_n) = 0\\)."
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#consistency",
    "href": "120B-F25/Wk07/wk7.html#consistency",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nDefinition\n\n\n\n\n\n\nDefinition: Consistency\n\n\nAn estimator \\(\\widehat{\\theta}_n\\) for \\(\\theta\\) is said to be a consistent estimator for \\(\\theta\\) if either of the following equivalent conditions hold: for any \\(\\varepsilon &gt; 0\\), \\[\\begin{align*}\n  \\lim_{n \\to \\infty} \\Prob(|\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon)  & = 1 \\\\\n  \\lim_{n \\to \\infty} \\Prob(|\\widehat{\\theta}_n - \\theta| &gt; \\varepsilon)  & = 0\n\\end{align*}\\]\n\n\n\n\nThis definition can seem scary at first; let’s break it down."
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#consistency-1",
    "href": "120B-F25/Wk07/wk7.html#consistency-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nDefinition: Interpretation\n\n\\(|\\widehat{\\theta}_n - \\theta|\\) is essentially the distance between our estimator and estimand.\nThe event \\(\\{|\\widehat{\\theta}_n - \\theta| &lt; \\varepsilon\\}\\) is then: “the distance between our estimator and estimand is small.”\n\nIn other words: “our estimator is very close to our estimand.”\n\nSaying that \\(\\Prob(|\\widehat{\\theta}_n - \\theta| &lt; \\varepsilon) \\to 1\\) as \\(n \\to \\infty\\) means that, as our sample size gets large, we are more and more certain that our estimator is very close to our estimand.\nThat’s all consistency is saying!\n\nI find this breakdown useful when trying to remember the definition of consistency."
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#consistency-2",
    "href": "120B-F25/Wk07/wk7.html#consistency-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nMain Theorem\n\nWe don’t always need to use the definition of consistency:\n\n\n\n\n\n\n\n\nTheorem\n\n\nIf \\(\\widehat{\\theta}_n\\) is an unbiased estimator for \\(\\theta\\), then it is also a consistent estimator for \\(\\theta\\) if and only if \\(\\Var(\\widehat{\\theta}_n) \\to 0\\) as \\(n \\to \\infty\\).\n\n\n\n\n\nCaution: If you want to use this theorem, you MUST first check that your estimator is unbiased! (Otherwise, we can’t appeal to this theorem.)\nQuestion: are all unbiased estimators consistent?\nQuestion: are all consistent estimators unbiased?"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#consistency-3",
    "href": "120B-F25/Wk07/wk7.html#consistency-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Consistency",
    "text": "Consistency\nBiased but Consistent\nExample: \\(\\widehat{\\sigma^2}_n := \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\bar{Y}_n)^2\\)"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods",
    "href": "120B-F25/Wk07/wk7.html#likelihoods",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\n\nA coin lands “heads” with probability \\(\\theta \\in (0, 1)\\).\nSuppose we toss the coin five times, and observe (H, T, H, H, T).\n\nLetting X denote the number of heads in 5 tosses, X ~ Bin(5, \\(\\theta\\))\n\nIf \\(\\theta = 0.3\\), how likely were we to have observed what we saw?\n\nIf \\(\\theta = 0.3\\), the probability of observing three heads is \\(\\Prob(X = 3) = \\binom{5}{3}(0.3)^3(0.7)^2 \\approx 0.1323\\)\n\nIf \\(\\theta = 0.4\\), how likely were we to have observed what we saw?\n\nIf \\(\\theta = 0.3\\), the probability of observing three heads is \\(\\Prob(X = 3) = \\binom{5}{3}(0.4)^3(0.6)^2 \\approx 0.2304\\)\n\nGiven that we observed (H, T, H, H, T), which was more likely: that \\(\\theta = 0.3\\) or that \\(\\theta = 0.4\\)?"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-1",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nMaximization\n\n\n\n\n\n\nIdea:\n\n\nTo estimate a parameter \\(\\theta\\) given data \\(Y_1, Y_2, \\cdots, Y_n\\), find the value of \\(\\theta\\) that was most likely to have given rise to the data we observed.\n\n\n\n\nThis procedure is called maximum likelihood estimation and the resulting estimator is called the maximum likelihood estimator\nThe likelihood gives a way of answering the question: “given data \\(Y_1, Y_2, \\cdots, Y_n\\), how likely was it that the true value of the parameter were \\(\\theta\\), for an arbitrary \\(\\theta\\)?”\nFor example, back to our coin-tossing example:"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-2",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-3",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample: Different Datasets"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-4",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-4",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nDefinition\n\nThe likelihood given a sample is just the marginal mass/density function.\nIndeed, the reason we call this a “likelihood” function instead of a “probability” function is because, in the continuous case, the likelihood at a given point doesn’t really represent a true probability (but, it is giving the same sort of information as a probability).\n\n\n\\[ \\mathcal{L}(\\theta; Y_1, Y_2, \\cdots, Y_n) := f_{Y_1, Y_2, \\cdots, Y_n}(Y_1, Y_2, \\cdots, Y_n; \\theta) \\]\n\n\nIf the sample is i.i.d.: \\(\\displaystyle \\mathcal{L}(\\theta; Y_1, Y_2, \\cdots, Y_n) = \\prod_{i=1}^{n} f(Y_i; \\theta)\\)"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-5",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-5",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nContinuous Example: Exponential\n\nExample Scenario: The wait time at The Arbor of a randomly-selected customer follows an Exponential distribution with unknown mean \\(\\theta\\).\nLikelihood (assuming i.i.d.): \\[\\begin{align*}\n  \\class{fragment}{{} \\mathcal{L}(\\theta; Y_1, Y_2, \\cdots, Y_n)}\n&\\class{fragment}{{} = \\prod_{i=1}^{n} f(Y_i; \\theta)}            \\\\[3px]\n&\\class{fragment}{{} = \\prod_{i=1}^{n} \\left[ \\frac{1}{\\theta} e^{-Y_i/\\theta} \\cdot 1 \\! \\! 1_{\\{Y_i \\geq 0\\}} \\right] }    \\\\[3px]\n&\\class{fragment}{{} = \\left( \\frac{1}{\\theta} \\right)^n \\cdot e^{-\\frac{1}{\\theta} \\sum_{i=1}^{n} Y_i} \\cdot 1 \\! \\! 1_{\\{Y_{(1)} \\geq 0\\}}}\n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-6",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-6",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nContinuous Example: Exponential\n\\[ \\mathcal{L}(\\theta; Y_1, Y_2, \\cdots, Y_n) = \\left( \\frac{1}{\\theta} \\right)^n \\cdot e^{-\\frac{1}{\\theta} \\sum_{i=1}^{n} Y_i} \\cdot 1 \\! \\! 1_{\\{Y_{(1)} \\geq 0\\}} \\]\n\nNote that we are viewing this as a function of \\(\\theta\\)!\n\nThe idea is: we assume that we already have our data \\((Y_1, Y_2, \\cdots, Y_n)\\); what we’re trying to do is figure out the most plausible \\(\\theta\\) value given the data we’ve observed.\n\nFurther note that this means likelihoods aren’t necessarily true density functions in \\(\\theta\\)."
  },
  {
    "objectID": "120B-F25/Wk07/wk7.html#likelihoods-7",
    "href": "120B-F25/Wk07/wk7.html#likelihoods-7",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Likelihoods",
    "text": "Likelihoods\nContinuous Example: Exponential\n\n\nCode\nexp_lik &lt;- function(theta, y) {\n  (1 / theta)^(length(y)) * exp(-(1 / theta) * sum(y))\n}"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\n\n\n\n\n\n\nGoal\n\n\nGiven a collection of random variables Y1, Y2, …, Yn, and a function h, we wish to identify the distribution of U := h(Y1, Y2, …, Yn).\n\n\n\n\nExamples:\n\nSample Mean:: \\(\\overline{Y}_n := n^{-1} \\sum_{i=1}^{n} Y_i\\)\nSample Variance:: \\(\\overline{Y}_n := (n-1)^{-1} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2\\)\nOrder Statistics:: \\(Y_{(i)}\\) := ith smallest of the Y’s\n\nSample Minimum:: \\(Y_{(1)} := \\min\\{Y_1, \\cdots, Y_n\\}\\)\nSample Maximum:: \\(Y_{(n)} := \\max\\{Y_1, \\cdots, Y_n\\}\\)"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-1",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nSpecial Cases\n\nIf:                          and                         , consider using the MGF Method.\n\nEven in this case, we need to be mindful of what we want at the end: if we only want the distribution, the MGF will be fine. But, if we want the density, we need some hope of being able to recognize the final MGF.\n\nGenerally, the CDF method will always work and give you a valid answer for the CDF and/or density.\n\nHowever, it is possible that the integrals involved are either intractable, or impossible to express in terms of elementary functions."
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-2",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nSample Maximum\n\n\n\n\n\n\nGoal\n\n\nGiven a collection of random variables Y1, Y2, …, Yn, we wish to identify the density of Y(n) := max{Y1, …, Yn }\n\n\n\n\nUsing the CDF method, we need to express \\(\\{Y_{(n)} \\leq y\\}\\) in terms of the original Yi’s.\n\nIf the largest of a collection of numbers is less than or equal to some value y, then so too must all the numbers be less than or equal to y.\n\nAll values are less than or equal to the maximum (by definition)\nThe maximum is less than y (by assertion)\nTherefore all values are less than y (by logic)"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-3",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nSample Maximum\n\n\n\n\n\n\nGoal\n\n\nGiven a collection of random variables Y1, Y2, …, Yn, we wish to identify the density of Y(n) := max{Y1, …, Yn }\n\n\n\n\nNote: the converse is not true; that is, \\(\\{Y_{(n)} &gt; y\\}\\) does not imply that all the Y’s are greater than y.\n\nFor example: max{2, 4} is greater than 3, but it is not true that both 2 and 4 are greater than three\n\nThink About This: How can we translate \\(\\{Y_{(1)} \\leq y\\}\\) in terms of the original Y’s?\n\nThis is relevant for finding the density of the sample minimum."
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-4",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-4",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOrder Statistics: Why Are They Random?\n\nIt might seem strange to think of order statistics as random. I find an example might help.\nSuppose we let Yi denote the weight of a randomly-selected cat.\n\nSince the cat is randomly selected, Yi is random; different cats have different weights.\n\nLet (Y1, …, Yn) denote a sample of n independent cat weights.\n\nDifferent samples of cats lead to different recorded cat weights.\nThe minimum weight of each of these samples isn’t necessarily the same across samples - there is variability across samples!\nHence, the sample minimum is a random quantity."
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-5",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-5",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOrder Statistics: Why Are They Random?"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-6",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-6",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOrder Statistics: Why Are They Random?"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-7",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-7",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOrder Statistics: Why Are They Random?"
  },
  {
    "objectID": "120B-F25/Wk02/wk2.html#multivariate-transformations-8",
    "href": "120B-F25/Wk02/wk2.html#multivariate-transformations-8",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOrder Statistics: Why Are They Random?"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#interlude-gamma-distribution",
    "href": "120B-F25/Wk03/wk3.html#interlude-gamma-distribution",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interlude: Gamma Distribution",
    "text": "Interlude: Gamma Distribution\nRelated to Homework 3\n\nHere is the convention we’re using for this class: if \\(X \\sim \\mathrm{Gamma}(\\alpha, \\beta)\\) then \\[ f_X(x) = \\frac{1}{\\Gamma(\\alpha) \\beta^\\alpha} x^{\\alpha - 1} e^{-x / \\beta} \\cdot 1 \\! \\! 1_{\\{x \\geq 0\\}} \\]\nAny other parametrization may not receive credit on quizzes/exams. For example, there is another way to write the Gamma density: \\[ f_X(x) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\lambda x} \\cdot 1 \\! \\! 1_{\\{x \\geq 0\\}} \\] with \\(\\E[X] = \\alpha / \\lambda\\) and \\(\\Var(X) = \\alpha / \\lambda^2\\)."
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#interlude-gamma-distribution-1",
    "href": "120B-F25/Wk03/wk3.html#interlude-gamma-distribution-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Interlude: Gamma Distribution",
    "text": "Interlude: Gamma Distribution\nRelated to Homework 3\n\nWhen it comes to expectations and variances, it doesn’t actually matter which parametrization you use. However, when you list the distribution’s parameters, it matters a lot.\nFor example, say \\(Y\\) is a random variable with density \\(f(y) = 9y e^{-3y} \\cdot 1 \\! \\! 1_{\\{y \\geq 0\\}}\\).\n\nIt is true that \\(\\E[Y] = 2/3\\) and \\(\\Var(Y) = 2/9\\); no ambiguities there.\nBut, for this class, we would write \\(Y \\sim \\mathrm{Gamma}(2, \\ 1/3)\\) and NOT \\(Y \\sim \\mathrm{Gamma}(2, 3)\\).\n\nPlease keep this mind for quizzes and exams!"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#sampling-distributions",
    "href": "120B-F25/Wk03/wk3.html#sampling-distributions",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nOverview\n\nGiven a sample Y1, …, Yn, a statistic is a function h(Y1, …, Yn) of the sample.\n\nStatistics are random, and therefore have distributions; a statistics’ distribution is called its sampling distribution\n\nHow do we find sampling distributions?\n\nUsing our material from the Transformations chapter of this course!\nAfter all, statistics are just functions of random variables.\n\nWe start with the case of a normal population; i.e. that our sample is an i.i.d. sample drawn from a normal distribution."
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#sampling-distributions-1",
    "href": "120B-F25/Wk03/wk3.html#sampling-distributions-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Population\n\nSuppose \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, \\sigma^2)\\).\nWhat is the sampling distribution of the sample mean \\[ \\overline{Y}_n := \\frac{1}{n} \\sum_{i=1}^{n} Y_i \\]\nWhat do we know about the sampling distribution of the sample variance \\[ S_n^2 := \\frac{1}{n - 1} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2 \\]"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#sampling-distributions-2",
    "href": "120B-F25/Wk03/wk3.html#sampling-distributions-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Population: Sample Mean\n\n\nCode\nset.seed(120); means &lt;- c(); n &lt;- 25\nfor(k in 1:1000) {\n  means &lt;- c(means, mean(rnorm(n, 3, 1.2)))\n}"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#sampling-distributions-3",
    "href": "120B-F25/Wk03/wk3.html#sampling-distributions-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Population: Sample Variance\n\n\nCode\nset.seed(120); var_stat &lt;- c(); n &lt;- 25\nfor(k in 1:1000) {\n  var_stat &lt;- c(var_stat, ((n - 1) / (1.2^2)) * var(rnorm(n, 3, 1.2)))\n}"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#standard-normal-distribution",
    "href": "120B-F25/Wk03/wk3.html#standard-normal-distribution",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Standard Normal Distribution",
    "text": "Standard Normal Distribution\nQuick Review\n\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\)\nPDF: \\(\\displaystyle \\phi(z) := \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} z^2}\\)\nCDF: \\(\\displaystyle \\Phi(z) := \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x^2} \\ \\mathrm{d}x\\)"
  },
  {
    "objectID": "120B-F25/Wk03/wk3.html#lookup-tables",
    "href": "120B-F25/Wk03/wk3.html#lookup-tables",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Lookup Tables",
    "text": "Lookup Tables\nNormal and Chi-Squared\n\n\\(\\Phi(z)\\) has no closed-form expression; as such, it must be (in general) evaluated numerically. (One exception: \\(\\Phi(0)\\).)\n\nThis means we either have to use a computer, or a table\n\nOur table (for PSTAT 120B) gives right-tail areas, meaning it actually gives values of \\(1 - \\Phi(z)\\).\n\nThis is likely the opposite of the tables you saw in PSTAT 120A.\n\nExample: Evaluate \\(\\Phi(0.53)\\) using the table.\nExample: Evaluate \\(\\Phi^{-1}(0.9265)\\) using the table.\nExample: If \\(U \\sim \\chi^2_{8}\\), find \\(c\\) such that \\(\\Prob(U &gt; c) = 0.05\\)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#roadmap-for-today",
    "href": "120B-F25/FinRev/FinRev_v3.html#roadmap-for-today",
    "title": "Final Exam Review",
    "section": " Roadmap for Today",
    "text": "Roadmap for Today\n\nGo through some slides (including some interactive problems)\nWork through some problems together (on the worksheet; copies can be found at the front of the room)\n\n\n\n\n\n\n\n\nDisclaimer\n\n\nI have not seen the exam yet, so I do not know exactly what will or will not be on it. Just because something does or does not show up on these slides doesn’t mean it is guaranteed to show up / not show up on the exam.\n\n\n\n\n\n\n\n\n\n\n\nDisclaimer\n\n\nThis review is not intended to be comprehensive; I encourage you to consult the lecture notes, textbook, homework, and your own notes."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#roadmap-for-today-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#roadmap-for-today-1",
    "title": "Final Exam Review",
    "section": " Roadmap for Today",
    "text": "Roadmap for Today\n\nNow, there is far too much material for me to be able to meaningfully cover everything that I think is important for the final.\nInstead, I’ve elected to select a handful of topics which I think might be confusing (or topics I’d like to expound upon). I’ll go through these relatively quickly, though, as the best way to learn is to practice - so I’d like to leave plenty of time for us to work through some of the problems on the worksheet!\nOrder of coverage:\n\nEstimation\nCI for a Difference in Means (time permitting)\nHypothesis Testing"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#estimation-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#estimation-1",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nGeneral Framework\n\n\n\nWe have a population, governed by a set of population parameters that are unobserved (but that we’d like to make claims about).\nTo make claims about the population parameters, we take a sample.\nWe then use our sample to make inferences (i.e. claims) about the population parameters.\n\n\n\n\n\n\n\nInference can mean either estimation or hypothesis testing."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#estimation-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#estimation-2",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nTerminology\n\nIn estimation, we seek to estimate a particular population parameter.\nWe do so by taking a sample (Y1, …, Yn) from the population, and constructing an estimator: \\[ \\widehat{\\theta}_n := \\widehat{\\theta}_n(Y_1, \\cdots, Y_n) \\]\nCrucially, an estimator is a random quantity.\n\nContrast this with an estimate, which we obtain by plugging specific data into our estimator.\nE.g. we use the sample mean as an estimator for the population mean; after getting a specific set of observations, their numerical sample mean is the estimate."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#estimation-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#estimation-3",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nProperties\n\nA “good” point estimator is one that possesses one (or several) desirable properties, which we can measure in a few different ways:\n\nUnbiasedness: \\(\\E[\\widehat{\\theta}_n] = \\theta\\)\nConsistency: \\(\\widehat{\\theta}_n \\probto \\theta\\)\nMSE: \\(\\mathrm{MSE}(\\widehat{\\theta}_n) = \\mathrm{Bias}^2(\\widehat{\\theta}_n) + \\Var(\\widehat{\\theta}_n)\\)\n\nQuestion: do we want high or low MSE?\n\nMVUE: \\(\\widehat{\\theta}_n\\) is unbiased and possesses the smallest variance among all possible unbiased estimators.\n\nCheck your understanding: are all consistent estimators unbiased? Are all unbiased estimators consistent?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#consistency",
    "href": "120B-F25/FinRev/FinRev_v3.html#consistency",
    "title": "Final Exam Review",
    "section": " Consistency",
    "text": "Consistency\nDefinition\n\n\n\n\n\n\nDefinition: Consistency\n\n\nAn estimator \\(\\widehat{\\theta}_n\\) is said to be a consistent estimator for \\(\\theta\\), denoted \\(\\widehat{\\theta}_n \\probto \\theta\\) if, for any \\(\\varepsilon &gt; 0\\), either of the following equivalent statements hold: \\[\\begin{align*}\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon \\right)  & = \\underline{\\qquad \\qquad} \\\\\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| &gt;  \\varepsilon \\right)  & = \\underline{\\qquad \\qquad}\n\\end{align*}\\]\n\n\n\n\n\\(|\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon\\) means “the distance between \\(\\widehat{\\theta}_n\\) and \\(\\theta\\) is very small.” Equivalently: “\\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”\nThe definition of consistency asserts that this probability goes to zero as the sample size increases. That is: “as our sample size becomes larger, we become more certain that \\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#consistency-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#consistency-1",
    "title": "Final Exam Review",
    "section": " Consistency",
    "text": "Consistency\nBiased but Consistent\nExample: \\(\\widehat{\\sigma^2}_n := \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\bar{Y}_n)^2\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#estimation-4",
    "href": "120B-F25/FinRev/FinRev_v3.html#estimation-4",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nConstructing Estimators\n\nSo far, we’ve primarily been concerned with assessing the performance of an estimator. Now, we turn our attention to the question of how to construct an estimator.\nThere are two main methods we use:\n\nThe Method of Moments (MoM)\nThe method of Maximum Likelihood Estimation (MLE)\n\nIntuition behind the method of moments: our sample moments should closely match the population moments (the sample average cat weight should probably be close to the true average of all cat weights).\nIntuition behind maximum likelihood estimation: a good guess for the true value of the parameter is that was most likely to have given rise to the data we observed."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#method-of-moments",
    "href": "120B-F25/FinRev/FinRev_v3.html#method-of-moments",
    "title": "Final Exam Review",
    "section": " Method of Moments",
    "text": "Method of Moments\n\n\n\n\n\n\nMethod of Moments\n\n\n\nSet up p equations (where p is the number of parameters that are desired to be estimated) of the form \\[\\begin{align*}\n  M_1   &= \\mu_1 \\\\\n  M_2   & = \\mu_2  \\\\\n  \\vdots & \\hspace{5mm} \\vdots \\\\\n  M_p   & = \\mu_p\n\\end{align*}\\] where \\[ M_k := \\frac{1}{n} \\sum_{i=1}^{n} Y_i^k ; \\qquad \\mu_k := \\E[Y_i^k] \\] denote the kth sample moment and population moment, respectively\nSolve the equations for the p parameters; these will be the method of moments estimators for the parameters."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-2",
    "title": "Final Exam Review",
    "section": " Example 2",
    "text": "Example 2\n\n\n\n\n\n\nExample 1\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathrm{Geom}(p)\\). Derive an expression for \\(\\widehat{p}_{\\mathrm{MoM}}\\), the method of moments estimator for p.\n\n\n\n\nWe have only one parameter, so we only need to set up one equation.\nThe first population moment is given by \\(\\mu_1 := \\E[Y_i] = 1/p\\)\nHence, our method of moments estimator satisfies the equation \\[ \\overline{Y}_n = \\frac{1}{\\widehat{p}_{\\mathrm{MoM}}} \\]\nWhen solved for \\(\\widehat{p}_{\\mathrm{MoM}}\\), we obtain \\(\\boxed{\\widehat{p}_{\\mathrm{MoM}} = \\frac{1}{\\overline{Y}_n}}\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#sampling",
    "href": "120B-F25/FinRev/FinRev_v3.html#sampling",
    "title": "Final Exam Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#sampling-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#sampling-1",
    "title": "Final Exam Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#sampling-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#sampling-2",
    "title": "Final Exam Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#sampling-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#sampling-3",
    "title": "Final Exam Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#leadup",
    "href": "120B-F25/FinRev/FinRev_v3.html#leadup",
    "title": "Final Exam Review",
    "section": " Leadup",
    "text": "Leadup\n\nEach one of these samples provides some information about µ, the true average weight of all cats.\nFor example, suppose we only observed the first sample: \\[ \\vec{\\boldsymbol{y}} = (8.5, \\ 12.0, \\ 7.5, \\ 11.1, ... , \\ 8.8, 10.4) \\]\n\nFor reference, the average weight of cats in this sample is 9.11 lbs.\n\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, 8 lbs?\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, 30 lbs?\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, some arbitrary value µ?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#likelihoods",
    "href": "120B-F25/FinRev/FinRev_v3.html#likelihoods",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\n\nThe answer to this last question is precisely the likelihood of a sample.\nMore generally, \\[ \\Lik(\\theta; Y_1, \\cdots, Y_n) \\] denotes the likelihood of the true value of the parameter being θ, given observations (Y1, …, Yn).\nMathematically, the likelihood is just the joint density function of (Y1, …, Yn); conceptually, we are now viewing it as a function of θ.\nAs a concrete example, suppose \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\) (if it helps, you can think of these at cat weights)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#likelihoods-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#likelihoods-1",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample\n\nSince our sample is stated to be i.i.d.,\n\n\\[\\begin{align*}\n  \\class{fragment}{{} \\Lik(\\theta; Y_1, \\cdots, Y_n) }\n    &\\class{fragment}{{} := f_{Y_1, \\cdots, Y_n}(y_1, \\cdots, y_n ; \\theta) }            \\\\[3px]\n    &\\class{fragment}{{}  = \\prod_{i=1}^{n} f_{Y_i}(y_i; \\theta) }    \\\\[3px]\n    &\\class{fragment}{{}  = \\prod_{i=1}^{n} \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ - \\frac{1}{2} (Y_i - \\mu)^2 \\right\\} \\right]  }    \\\\[3px]\n    &\\class{fragment}{{}  = \\left( \\frac{1}{2\\pi} \\right)^{n/2} \\cdot \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^{n} (\\mu - Y_i)^2 \\right\\}  }\n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#likelihoods-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#likelihoods-2",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#likelihoods-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#likelihoods-3",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#maximum-likelihood-estimation",
    "href": "120B-F25/FinRev/FinRev_v3.html#maximum-likelihood-estimation",
    "title": "Final Exam Review",
    "section": " Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nConsider again the likelihood of a sample; \\(\\Lik(\\theta; Y_1, \\cdots, Y_n)\\).\nRecall that this represents how likely any specified value of θ is to be the truth, given the data (Y1, …, Yn).\nA good guess for the true value of θ, therefore, is perhaps the one that was most likely to have given rise to the data we observed.\n\nIn other words, the value that maximizes the likelihood.\n\n\n\n\n\n\n\n\n\nDefinition: Maximum Likelihood Estimator\n\n\n\\[ \\widehat{\\theta}_{\\mathrm{MLE}} := \\argmax_{\\theta} \\left\\{ \\Lik(\\theta; Y_1, \\cdots, Y_n) \\right\\} \\]\n\n\n\n\n\nSometimes it’s more convenient to work with the log-likelihood, though it is not always necessary."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-3-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-3-1",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\n\n\n\n\n\n\nExample 3\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\). Derive an expression for \\(\\widehat{\\mu}_{\\mathrm{MLE}}\\), the maximum likelihood estimator for µ.\n\n\n\n\nFrom before, the likelihood is \\[ \\Lik(\\mu; Y_1, \\cdots, Y_n) = \\left( \\frac{1}{2\\pi} \\right)^{n/2} \\cdot \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^{n} (\\mu - Y_i)^2 \\right\\}\\]\nThe log-likelihood and its first derivative are therefore given by \\[\\begin{align*}\n  \\class{fragment}{{} \\ell(\\mu; Y_1, \\cdots, Y_n) }\n&\\class{fragment}{{} = -\\frac{n}{2} \\ln(2\\pi) - \\frac{1}{2} \\sum_{i=1}^{n}(Y_i - \\mu)^2 }            \\\\[3px]\n\\class{fragment}{{} \\frac{\\partial}{\\partial \\mu} \\ell(\\mu; Y_1, \\cdots, Y_n) } & \\class{fragment}{{}  = \\sum_{i=1}^{n} (Y_i - \\mu) = n \\bar{Y} - n \\mu }  \n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-2-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-2-1",
    "title": "Final Exam Review",
    "section": " Example 2",
    "text": "Example 2\n\n\n\n\n\n\nExample 2\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\). Derive an expression for \\(\\widehat{\\mu}_{\\mathrm{MLE}}\\), the maximum likelihood estimator for µ.\n\n\n\n\nSetting this equal to zero and solving for µ reveals that a critical value of the likelihood is given by \\(\\mu = \\overline{Y}_n\\).\n\n\nThe second derivative of the log-likelihood is given by \\[\\frac{\\partial^2}{\\partial \\mu^2} \\ell(\\theta; Y_1, \\cdots, Y_n) = - n \\] which is negative everywhere; hence the critical value we found above must be a maximum.\nThus, \\(\\boxed{\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{Y}_n}\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#maximum-likelihood-estimation-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#maximum-likelihood-estimation-1",
    "title": "Final Exam Review",
    "section": " Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nIf the support of the population distribution depends on the parameter of interest, the likelihood will be nondifferentiable (with respect to the parameter of interest).\nIn such cases, the likelihood must be maximized by inspection - there’s an example of this on the worksheet we’ll go over later today.\n\n\n\n\n\n\n\n\nCaution\n\n\nIn cases like this (where the support depends on the parameter), do NOT forget about the indicator in the density function."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#leadup-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#leadup-1",
    "title": "Final Exam Review",
    "section": " Leadup",
    "text": "Leadup\n\nDo UCSB students have, on average, the same commute times as SBCC students?\nAssume we have two samples: \\[\\begin{align*}\n  Y_{1,1}, Y_{1,2}, \\cdots, Y_{1, n_1} & \\iid \\mathcal{N}(\\mu_1, \\ \\sigma^2) \\\\\n  Y_{2,1}, Y_{2,2}, \\cdots, Y_{2, n_2} & \\iid \\mathcal{N}(\\mu_2, \\ \\sigma^2)\n\\end{align*}\\] (note crucially that we are assuming the two population variances are equal).\n\nFor example, the Y1,i might represent UCSB commute times and the Y2,i might represent SBCC commute times.\n\nSay we want to construct a confidence interval for (µ1 - µ2 ), the difference in true average commute times."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means",
    "href": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\nBy previously-established results, \\[\\begin{align*}\n  \\bar{Y}_1 := \\frac{1}{n_1} \\sum_{i=1}^{n_1} Y_i & \\sim  \\\\\n  \\bar{Y}_2 := \\frac{1}{n_2} \\sum_{i=1}^{n_2} Y_i & \\sim\n\\end{align*}\\] which in turn implies \\[ (\\bar{Y}_1 - \\bar{Y}_2)  \\sim  \\] \\[ \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - \\qquad \\qquad \\qquad }{} \\sim \\mathcal{N}(0, 1) \\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means-1",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\n\nIn practice, \\(\\sigma^2\\) is often unknown so we replace it with an unbiased estimator: the pooled sample variance \\[ S_p^2 := \\left( \\frac{n_1 - 1}{n_1 + n_2 - 2} \\right) S_1^2  + \\left( \\frac{n_2 - 1}{n_1 + n_2 - 2} \\right) S_2^2 \\]\n\nIntuition: we take a weighted average of the two sample standard deviations, placing more weight on the sample with more information (i.e. a greater sample size), that is still an unbiased estimator for \\(\\sigma^2\\).\n\nReplacing \\(\\sigma^2\\) with \\(S_p := \\sqrt{S_p^2}\\) breaks the normality of our point estimator, requiring us to instead use the \\(t_{n_1 + n_2 - 2}\\) distribution."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#confidence-interval-for-a-difference-in-means-2",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\n\\[ (\\bar{Y}_1 - \\bar{Y}_2) \\pm t_{n_1 + n_2 - 2, \\ \\frac{\\alpha}{2}} \\cdot S_p \\cdot \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\\]\n\nAssumptions:\n\n\nNormally-distributed population\nEqual population variances\n\n\n\n\nMake sure you understand how to interpret these intervals with respect to whether or not zero is contained in them."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#cats",
    "href": "120B-F25/FinRev/FinRev_v3.html#cats",
    "title": "Final Exam Review",
    "section": " Cats",
    "text": "Cats\nToe Beans…\n\nAccording to a Quora post, the average cat has about a 10% chance of being born with polydactyly\n\n\n\n\n\n\n\nImage Source: https://www.treehugger.com/thing-didnt-know-polydactyl-cats-4864197\n\n\n\n\n\nPolydactyly refers to a condition whereby an animal is born with extra digits (e.g. extra fingers in humans, extra toes in cats, etc.)\nSuppose we wish to assess the validity of the Quora claim, using data.\n\nNote that we’re not necessarily trying to estimate the true incidence of polydactyly among cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#cats---again",
    "href": "120B-F25/FinRev/FinRev_v3.html#cats---again",
    "title": "Final Exam Review",
    "section": " Cats - Again!",
    "text": "Cats - Again!\nToe Beans…\n\nSay we collect a simple random sample of 100 cats, and observe 9 polydactyl cats in this sample (i.e. \\(\\widehat{p}\\) = 9%).\nDoes this provide concrete evidence that the Quora claim is incorrect? Not really!\nBut, say our sample of 100 cats contains 80 polydactyl cats (\\(\\widehat{p}\\) = 80%). Or, say we saw only 1 polydactyl cat in a sample of 100 (\\(\\widehat{p}\\) = 1%).\nNow, it is possible that the Quora claim is true and we just happened to get extraordinarily lucky (or unlucky).\nBut, it’s probably more likely that we should start to question the validity of the Quora statistic."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-1",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nGeneral Framework\n\nSo where’s the cutoff - how many polydactyl cats do we need to observe in a sample of n before we start to question the Quora statistic?\nThis is the general framework of hypothesis testing.\nWe start off with a pair of competing claims, called the null hypothesis and the alternative hypothesis.\n\nThe null hypothesis is usually set to be the “status quo”. For instance, in our polydactyly example, we would set the null hypothesis (denoted H0, and read “H-naught”) to be “10% of cats are polydactyl.”\n\nFor the purposes of this class, the null hypothesis is always a statement of equality: \\(H_0: \\ \\theta = \\theta_0\\) for some null value \\(\\theta_0\\)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-2",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nGeneral Framework\n\nGiven a null \\(H_0: \\ \\theta = \\theta_0\\), three possible alternative hypotheses present themselves to us (among which we must pick one):\n\n\\(H_1: \\ \\theta &lt; \\theta_0\\) (lower-tailed)\n\\(H_1: \\ \\theta &gt; \\theta_0\\) (upper-tailed)\n\\(H_1: \\ \\theta \\neq \\theta_0\\) (two-tailed)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThere should be NO OVERLAP between the null and alternative.\n\n\n\n\n\nFor example, it is incorrect to write a lower-tailed alternative as \\(H_1: \\ \\theta \\leq \\theta_0\\). Can anyone tell me why, conceptually, this is?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world",
    "href": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\n\nIn a given hypothesis testing setting, the null is either true or not (though we won’t ever get to know for sure).\nIndependently, our test will either reject the null or not.\nThis leads to four states of the world:\n\n\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\n\n\n\n\n\n\nFalse\n\n\n\n\n\n\n\n\n\nSome of these states are good, others are bad. Which are which?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world-1",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\nBAD\n\n\nGOOD\n\n\n\n\nFalse\n\n\nGOOD\n\n\nBAD\n\n\n\n\nWe give names to the two “bad” situations: Type I and Type II errors.\n\n\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\nType I Error\n\n\nGOOD\n\n\n\n\nFalse\n\n\nGOOD\n\n\nType II Error\n\n\n\n\n\n\n\n\n\n\n\nDefinition: Type I and Type II errors\n\n\n\n\nA Type I Error occurs when we reject \\(H_0\\), when \\(H_0\\) was actually true.\nA Type II Error occurs when we fail to reject \\(H_0\\), when \\(H_0\\) was actually false."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world-2",
    "href": "120B-F25/FinRev/FinRev_v3.html#states-of-the-world-2",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\nLevel and Power\n\nThe level of significance (aka “significance level”; aka “level”) of a test, denoted by \\(\\alpha\\), is defined to be the probability of committing a Type I error.\nThe power of a test, often denoted \\(Q(\\theta')\\), is \\[Q(\\theta') := \\mathbb{P}(\\text{Reject $H_0$, when the true value of $\\theta$ was $\\theta'$}) \\]\nGenerally, we fix the level and try and find the test with the most power (or, equivalently, with the smallest probability of committing a Type II error).\n\nThis leads us to the notion of a Most Powerful Test of Level α (from Topic 15)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-1-1",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-1-1",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\n\n\n\n\n\n\nExample 1\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\) for some unknown µ, and suppose we wish to test H0: µ = µ0 vs HA: µ &gt; µ0 at a 0.05 level of significance. We propose two tests:\n\nTest 1: Reject H0 when \\(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)\\)\nTest 2: Reject H0 when \\(\\frac{\\overline{Y}_n - \\mu_0}{1/\\sqrt{n}} &gt; \\Phi^{-1}(0.95)\\)\n\n\nVerify that both tests have a 5% level of significance.\nDerive expressions for the power functions of both tests."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-1-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-1-3",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\nPart (a)\n\nLet’s focus on Test 1.\nBy definition, the level of the test is the probability of rejecting the null when the null was true.\nSaying that “the null was true” is saying that the true value of µ is µ0, in which case \\(Y_1 \\sim \\mathcal{N}(\\mu_0, 1)\\).\nHence, the probability of rejecting the null (i.e. that \\(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)\\)) if the null is true is:\n\n\n\\[\\begin{align*}\n  \\Prob_{H_0}(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)) & = 1 - \\Prob_{H_0}(Y_1 - \\mu_0 \\leq \\Phi^{-1}(0.95)) \\\\\n    & = 1 - \\Phi[\\Phi^{-1}(0.95)] = 1 - 0.95 = 0.05 \\ \\checkmark\n\\end{align*}\\]\n\n\nTry Test 2 on your own."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-1-4",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-1-4",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\nPart (b)\n\nWe now turn our attention to the power curves. Again, we start with Test 1.\nQ(µA) is the probability of rejecting the null when the true value of µ is in fact µA.\nSaying that “the true value of µ is in fact µA” means \\(Y_1 \\sim \\mathcal{N}(\\mu_A, 1)\\). Furthermore, we reject the null when \\(Y_1 &gt; \\Phi^{-1}(0.95)\\).\nHence,"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-3-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-3-3",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\nPart (b)\n\n\\[\\begin{align*}\n  Q_1(\\mu_A) & = \\Prob_{\\mu_A}(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)) \\\\\n  &  = \\Prob_{\\mu_A}(Y_1 - {\\color{blue} \\mu_A + \\mu_A} -  \\mu_0 &gt; \\Phi^{-1}(0.95)) \\\\\n   &  = \\Prob_{\\mu_A}({\\color{red}Y_1 - \\mu_A} &gt; \\Phi^{-1}(0.95) + (\\mu_0 - \\mu_A)) \\\\\n   &  = 1 - \\Phi[\\Phi^{-1}(0.95) + (\\mu_0 - \\mu_A)]\n\\end{align*}\\]\n\n\nFor test 2:\n\n\n\\[\\begin{align*}\n  Q_2(\\mu_A) & = \\Prob_{\\mu_A}\\left(\\frac{\\overline{Y}_n - {\\color{blue} \\mu_A + \\mu_A} - \\mu_0}{1/\\sqrt{n}} &gt; \\Phi^{-1}(0.95) \\right) \\\\\n  & = \\cdots = 1 - \\Phi\\left[\\Phi^{-1}(0.95) + \\sqrt{n}(\\mu_0 - \\mu_A) \\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#example-3-4",
    "href": "120B-F25/FinRev/FinRev_v3.html#example-3-4",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\nPart (b)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-3",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-3",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\np-Value Framework\n\nInstead of the critical value framework, we can also conduct hypothesis tests using p-values\nThe p-value is the probability of observing something as or more extreme (in the direction of the alternative) than what we actually observed.\n\n\n\n\nLower-tailed: ℙ(TS &lt; ts)\nUpper-tailed: ℙ(TS &gt; ts)\nTwo-sided: ℙ(|TS| &gt; ts)\nA picture is worth a thousand words!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-4",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-4",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nIn PSTAT 120B, we covered:\n\nLarge- and small-sample tests for the mean\nSmall-sample tests for a difference in means\nTests for the variance (assuming a normal population)\n\nMake sure that, for each, you understand:\n\nWhat assumptions are required\nHow to conduct them (in both the critical value and p-value frameworks)\n\nKeep in mind, hypothesis test questions on the final exam for PSTAT 120B are often (not always, though) word problems!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-5",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-5",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nI find it useful to also quickly review how these tests are derived. This can, in my opinion, help with the memorization aspect.\nFor example, suppose we are testing \\(H_0: \\mu = \\mu_0\\) against \\(H_A: \\mu \\neq \\mu_0\\) using data \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\).\n\nA natural point estimator for \\(\\mu\\) is \\(\\bar{Y}\\), which we know is normally-distributed, so a natural test statistic is its standardized form, under the null: \\(Z := (\\bar{Y} - \\mu_0)/(\\sigma / \\sqrt{n})\\).\nIf \\(\\bar{Y}\\) is far from \\(\\mu_0\\) (equivalently, that \\(Z\\) is far from zero), we have evidence that the true mean is not \\(\\mu_0\\): i.e. we have evidence against the null and in favor of the alternative.\nThis reveals a rejection region of the form \\(|Z| &gt; c\\) for some critical value \\(c\\), which can be derived by setting the level of the test to be \\(\\alpha\\)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-6",
    "href": "120B-F25/FinRev/FinRev_v3.html#hypothesis-testing-6",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nTake a look through 10.7 of the textbook, titled “Some Comments on the Theory of Hypothesis Testing.” The authors provide some (in my opinion) very useful and practical comments on hypothesis testing.\nAlso, even though material from Topic 15 will not feature heavily on the exam (if at all - again, I haven’t seen the exam yet!) I HIGHLY recommend you take a look at it before moving on to your future statistics courses.\n\nPretty much every course will at least in part make reference to that material, even if behind the scenes.\n\nAny time you perform a hypothesis test (e.g. in: Machine Learning, Time Series, etc.), you’re often concerned with finding a test with optimal power. The Neyman-Pearson Lemma and Likelihood Ratio Tests gives you such a test in many cases!"
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#hello",
    "href": "120B-W26/Wk01/wk1.html#hello",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Hello!",
    "text": "Hello!\nA Quick Introduction\n\nHello! My name is Ethan (he/him), and I am very much looking forward to being your TA!\n\nI am a sixth year PhD; this is my fifth time with this course (including having been the Instructor once :) )\n\nMy Office Hours: Tuesdays, 1:30 - 2:30 pm in SH 5607 F  Thursdays, 10:30 - 11:30 am in SH 5607 F\nMy Email: epmarzban@pstat.ucsb.edu (please allow a 24 business hour response time)\n\n\n\n\n\n\n\n\nGoal for Today\n\n\nBriefly review PSTAT 120A and Calculus material."
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#probability-spaces-random-variables",
    "href": "120B-W26/Wk01/wk1.html#probability-spaces-random-variables",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Probability Spaces; Random Variables",
    "text": "Probability Spaces; Random Variables\nHigh-Level Overview\n\nProbability Space: \\((\\Omega, \\F, \\Prob)\\) where:\n\n\\(\\Omega\\) denotes the outcome space\n\\(\\F\\) denotes the event space\n\\(\\Prob: \\F \\to \\R\\) denotes the probability measure\n\nA random variable \\(X\\) is a mapping \\(X : \\Omega \\to \\R\\)\n\nSupport: \\(X(\\Omega)\\) (set of values over which the random variable is defined)\n\nFinite or countable support \\(\\implies\\) \\(X\\) is discrete\nUncountable support \\(\\implies\\) \\(X\\) is continuous"
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#probability-spaces-random-variables-1",
    "href": "120B-W26/Wk01/wk1.html#probability-spaces-random-variables-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Probability Spaces; Random Variables",
    "text": "Probability Spaces; Random Variables\nExample\n\n\n\n\n\n\nExample 1\n\n\nA fair coin is tossed twice, and the outcomes are recorded; let X denote the number of heads.\n\n\n\n\nOutcome Space: \\(\\Omega =\\) {H, T}2 = {(H, H), (H, T), (T, H), (T, T) }\nX should map each element in \\(\\Omega\\) to a real number, by counting the number of heads in the outcome.\n\nX((H, H)) = 2;       X((H, T)) = 1;       X((T, H)) = 1;       X((T, T)) = 0\n\nThe support of X is {0, 1, 2}, which is finite, meaning X is a discrete random variable\nFair Coin implies we should use the equally-likely probability measure; \\(\\Prob(E) = |E| / |\\Omega|\\) for every event E.\n\nAllows us to construct the probability mass function (PMF) of X."
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#random-variables",
    "href": "120B-W26/Wk01/wk1.html#random-variables",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Random Variables",
    "text": "Random Variables\nRelevant Quantities\n\n\nDiscrete:\n\nPMF: \\(f(x) := \\Prob(X = x)\\)\nProbabilities: \\(\\Prob(X \\in B) = \\sum_{x \\in B} f(x)\\)\nCMF: \\(F(x) := \\Prob(X \\leq x) = \\sum_{t \\leq x} f(t)\\)\nLOTUS: \\(\\E[g(X)] = \\sum_{x} g(x) f(x)\\)\nVariance: \\(\\Var(X) := \\E\\left\\{(X - \\E[X])^2\\right\\}\\)\n\n\nContinuous:\n\nPDF: \\(f(x) \\geq 0\\) and \\(\\int_{\\R} f(x) = 1\\)\nProbabilities: \\(\\Prob(X \\in B) = \\int_{B} f(x) \\ \\mathrm{d}x\\)\nCDF: \\(F(x) := \\Prob(X \\leq x) = \\int_{-\\infty}^{x} f(t) \\ \\mathrm{d}t\\)\nLOTUS: \\(\\E[g(X)] = \\int_{\\R} g(x) f(x) \\ \\mathrm{d}x\\)\nVariance: \\(\\Var(X) := \\E\\left\\{(X - \\E[X])^2\\right\\}\\)"
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#moment-generating-functions",
    "href": "120B-W26/Wk01/wk1.html#moment-generating-functions",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Moment Generating Functions",
    "text": "Moment Generating Functions\nOverview\n\n\n\n\n\n\nDefinition: MGF\n\n\nThe moment generating function (MGF) of a random variable X is defined as \\[ M_X(t) := \\E[e^{tX}] \\]\n\n\n\nProperties:\n\nIf it is continuous in a neighborhood of zero, then it uniquely determines a distribution.\n\\(M_X^{(n)}(0) = \\E[X^n]\\) for any \\(n \\in \\N\\) (Homework Hint: What is \\(M_X(0)\\)?)\n\\(M_{X + Y}(t) = M_X(t) \\cdot M_Y(t)\\) provided that \\(X \\perp Y\\)\n\\(M_{aX + b}(t) = e^{tb} \\cdot M_X(at)\\) for constants \\(a, b\\)"
  },
  {
    "objectID": "120B-W26/Wk01/wk1.html#parameters",
    "href": "120B-W26/Wk01/wk1.html#parameters",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Parameters",
    "text": "Parameters\nExample: Normal Distribution\nThink of parameters as dials that control the shape of a distribution.\n\nviewof µ = Inputs.range(\n  [-3, 3], \n  {value: 0, step: 0.1, label: \"µ:\"}\n)\n\nviewof σ = Inputs.range(\n  [0.2, 3.1], \n  {value: 1, step: 0.01, label: \"σ:\"}\n)\n\nsigsquared = σ**2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njstat = require(\"jstat\")\n\nplt_pdf = Plot.plot({\n    width: 850,\n    height: 375,\n    color: {\n      legend: true\n    },\n    x: {\n      label: \"x\",\n      axis: true\n    },\n    y: {\n      label: \"f(x)\",\n      //axis: false,\n      //domain: [0, d3.max(pdfvals.map(d =&gt; d.pdf))]  \n    },\n    marks: [\n      Plot.ruleY([0]),\n      Plot.ruleX([0]),\n      Plot.line(pdfvals, {x: \"x\", y: \"pdf\", stroke : \"blue\", strokeWidth: 4})\n    ]\n  })\n  \npdfvals = {\n  const x = d3.range(-12, 12, 0.01);\n  var pdf;\n  pdf = x.map(x =&gt; ({x: x, pdf: jstat.normal.pdf(x, µ, σ)}));\n  return pdf\n}"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#some-questions",
    "href": "DSCol-F25/DataVis/DataVis.html#some-questions",
    "title": "Data Visualization",
    "section": " Some Questions",
    "text": "Some Questions\nLeadup\n\n\n\nHow do the GDPs of countries vary as a function of average life expectancy at birth?\nDoes the nature of this relationship change across continents?\nCan you justify your answers?\n\nWhat sort of data could be used to answer these questions and provide appropriate justification?"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset",
    "href": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset",
    "title": "Data Visualization",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nThe World Bank is a collection of organization aiming to study the effects of poverty worldwide.\n\nYou can read more about them at their website.\n\nSome variables with corresponding data:\n\n\n\n\n\nCountry Name\nCountry Code (abbreviation)\nContinent\nYear of observation\nGDP (Gross Domestic Product)\n\n\n\nFemale Life Expectancy at Birth\nMale Life Expectancy at Birth\nTotal Life Expectancy at Birth\nFemale Adult Literacy Rate\nMale Adult Literacy Rate\nTotal Adult Literacy Rate\n\n\n\nFemale Youth Literacy Rate\nMale Youth Literacy Rate\nTotal Youth Literacy Rate\nPopulation"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-1",
    "href": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-1",
    "title": "Data Visualization",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nHow do the GDPs of countries vary as a function of average life expectancy at birth?\nDoes the nature of this relationship change across continents?\n\n\nwb &lt;- read.csv(\"data/wb_cont.csv\", check.names = FALSE)\nwb %&gt;% head(100)\n\n           Country Name Country Code     Continent\n1           Afghanistan          AFG          Asia\n2           Afghanistan          AFG          Asia\n3           Afghanistan          AFG          Asia\n4           Afghanistan          AFG          Asia\n5           Afghanistan          AFG          Asia\n6           Afghanistan          AFG          Asia\n7           Afghanistan          AFG          Asia\n8           Afghanistan          AFG          Asia\n9           Afghanistan          AFG          Asia\n10          Afghanistan          AFG          Asia\n11          Afghanistan          AFG          Asia\n12              Albania          ALB        Europe\n13              Albania          ALB        Europe\n14              Albania          ALB        Europe\n15              Albania          ALB        Europe\n16              Albania          ALB        Europe\n17              Albania          ALB        Europe\n18              Albania          ALB        Europe\n19              Albania          ALB        Europe\n20              Albania          ALB        Europe\n21              Albania          ALB        Europe\n22              Albania          ALB        Europe\n23              Algeria          DZA        Africa\n24              Algeria          DZA        Africa\n25              Algeria          DZA        Africa\n26              Algeria          DZA        Africa\n27              Algeria          DZA        Africa\n28              Algeria          DZA        Africa\n29              Algeria          DZA        Africa\n30              Algeria          DZA        Africa\n31              Algeria          DZA        Africa\n32              Algeria          DZA        Africa\n33              Algeria          DZA        Africa\n34       American Samoa          ASM North America\n35       American Samoa          ASM North America\n36       American Samoa          ASM North America\n37       American Samoa          ASM North America\n38       American Samoa          ASM North America\n39       American Samoa          ASM North America\n40       American Samoa          ASM North America\n41       American Samoa          ASM North America\n42       American Samoa          ASM North America\n43       American Samoa          ASM North America\n44       American Samoa          ASM North America\n45              Andorra          AND        Europe\n46              Andorra          AND        Europe\n47              Andorra          AND        Europe\n48              Andorra          AND        Europe\n49              Andorra          AND        Europe\n50              Andorra          AND        Europe\n51              Andorra          AND        Europe\n52              Andorra          AND        Europe\n53              Andorra          AND        Europe\n54              Andorra          AND        Europe\n55              Andorra          AND        Europe\n56               Angola          AGO        Africa\n57               Angola          AGO        Africa\n58               Angola          AGO        Africa\n59               Angola          AGO        Africa\n60               Angola          AGO        Africa\n61               Angola          AGO        Africa\n62               Angola          AGO        Africa\n63               Angola          AGO        Africa\n64               Angola          AGO        Africa\n65               Angola          AGO        Africa\n66               Angola          AGO        Africa\n67  Antigua and Barbuda          ATG North America\n68  Antigua and Barbuda          ATG North America\n69  Antigua and Barbuda          ATG North America\n70  Antigua and Barbuda          ATG North America\n71  Antigua and Barbuda          ATG North America\n72  Antigua and Barbuda          ATG North America\n73  Antigua and Barbuda          ATG North America\n74  Antigua and Barbuda          ATG North America\n75  Antigua and Barbuda          ATG North America\n76  Antigua and Barbuda          ATG North America\n77  Antigua and Barbuda          ATG North America\n78            Argentina          ARG South America\n79            Argentina          ARG South America\n80            Argentina          ARG South America\n81            Argentina          ARG South America\n82            Argentina          ARG South America\n83            Argentina          ARG South America\n84            Argentina          ARG South America\n85            Argentina          ARG South America\n86            Argentina          ARG South America\n87            Argentina          ARG South America\n88            Argentina          ARG South America\n89              Armenia          ARM        Europe\n90              Armenia          ARM        Europe\n91              Armenia          ARM        Europe\n92              Armenia          ARM        Europe\n93              Armenia          ARM        Europe\n94              Armenia          ARM        Europe\n95              Armenia          ARM        Europe\n96              Armenia          ARM        Europe\n97              Armenia          ARM        Europe\n98              Armenia          ARM        Europe\n99              Armenia          ARM        Europe\n100               Aruba          ABW North America\n                                                     Series Name         1960\n1                                              GDP (current US$)           NA\n2                       Life expectancy at birth, female (years) 3.354900e+01\n3                         Life expectancy at birth, male (years) 3.213600e+01\n4                        Life expectancy at birth, total (years) 3.279900e+01\n5   Literacy rate, adult female (% of females ages 15 and above)           NA\n6       Literacy rate, adult male (% of males ages 15 and above)           NA\n7     Literacy rate, adult total (% of people ages 15 and above)           NA\n8          Literacy rate, youth female (% of females ages 15-24)           NA\n9              Literacy rate, youth male (% of males ages 15-24)           NA\n10           Literacy rate, youth total (% of people ages 15-24)           NA\n11                                             Population, total 9.035043e+06\n12                                             GDP (current US$)           NA\n13                      Life expectancy at birth, female (years) 5.887700e+01\n14                        Life expectancy at birth, male (years) 5.400500e+01\n15                       Life expectancy at birth, total (years) 5.641300e+01\n16  Literacy rate, adult female (% of females ages 15 and above)           NA\n17      Literacy rate, adult male (% of males ages 15 and above)           NA\n18    Literacy rate, adult total (% of people ages 15 and above)           NA\n19         Literacy rate, youth female (% of females ages 15-24)           NA\n20             Literacy rate, youth male (% of males ages 15-24)           NA\n21           Literacy rate, youth total (% of people ages 15-24)           NA\n22                                             Population, total 1.608800e+06\n23                                             GDP (current US$) 2.723615e+09\n24                      Life expectancy at birth, female (years) 4.385800e+01\n25                        Life expectancy at birth, male (years) 3.822500e+01\n26                       Life expectancy at birth, total (years) 4.083900e+01\n27  Literacy rate, adult female (% of females ages 15 and above)           NA\n28      Literacy rate, adult male (% of males ages 15 and above)           NA\n29    Literacy rate, adult total (% of people ages 15 and above)           NA\n30         Literacy rate, youth female (% of females ages 15-24)           NA\n31             Literacy rate, youth male (% of males ages 15-24)           NA\n32           Literacy rate, youth total (% of people ages 15-24)           NA\n33                                             Population, total 1.142492e+07\n34                                             GDP (current US$)           NA\n35                      Life expectancy at birth, female (years) 6.710700e+01\n36                        Life expectancy at birth, male (years) 6.317600e+01\n37                       Life expectancy at birth, total (years) 6.505300e+01\n38  Literacy rate, adult female (% of females ages 15 and above)           NA\n39      Literacy rate, adult male (% of males ages 15 and above)           NA\n40    Literacy rate, adult total (% of people ages 15 and above)           NA\n41         Literacy rate, youth female (% of females ages 15-24)           NA\n42             Literacy rate, youth male (% of males ages 15-24)           NA\n43           Literacy rate, youth total (% of people ages 15-24)           NA\n44                                             Population, total 2.013300e+04\n45                                             GDP (current US$)           NA\n46                      Life expectancy at birth, female (years) 7.508100e+01\n47                        Life expectancy at birth, male (years) 6.910900e+01\n48                       Life expectancy at birth, total (years) 7.209400e+01\n49  Literacy rate, adult female (% of females ages 15 and above)           NA\n50      Literacy rate, adult male (% of males ages 15 and above)           NA\n51    Literacy rate, adult total (% of people ages 15 and above)           NA\n52         Literacy rate, youth female (% of females ages 15-24)           NA\n53             Literacy rate, youth male (% of males ages 15-24)           NA\n54           Literacy rate, youth total (% of people ages 15-24)           NA\n55                                             Population, total 9.510000e+03\n56                                             GDP (current US$)           NA\n57                      Life expectancy at birth, female (years) 3.973900e+01\n58                        Life expectancy at birth, male (years) 3.624800e+01\n59                       Life expectancy at birth, total (years) 3.793300e+01\n60  Literacy rate, adult female (% of females ages 15 and above)           NA\n61      Literacy rate, adult male (% of males ages 15 and above)           NA\n62    Literacy rate, adult total (% of people ages 15 and above)           NA\n63         Literacy rate, youth female (% of females ages 15-24)           NA\n64             Literacy rate, youth male (% of males ages 15-24)           NA\n65           Literacy rate, youth total (% of people ages 15-24)           NA\n66                                             Population, total 5.231654e+06\n67                                             GDP (current US$)           NA\n68                      Life expectancy at birth, female (years) 6.475500e+01\n69                        Life expectancy at birth, male (years) 6.011700e+01\n70                       Life expectancy at birth, total (years) 6.263500e+01\n71  Literacy rate, adult female (% of females ages 15 and above)           NA\n72      Literacy rate, adult male (% of males ages 15 and above)           NA\n73    Literacy rate, adult total (% of people ages 15 and above)           NA\n74         Literacy rate, youth female (% of females ages 15-24)           NA\n75             Literacy rate, youth male (% of males ages 15-24)           NA\n76           Literacy rate, youth total (% of people ages 15-24)           NA\n77                                             Population, total 5.560300e+04\n78                                             GDP (current US$)           NA\n79                      Life expectancy at birth, female (years) 6.778900e+01\n80                        Life expectancy at birth, male (years) 6.120200e+01\n81                       Life expectancy at birth, total (years) 6.424200e+01\n82  Literacy rate, adult female (% of females ages 15 and above)           NA\n83      Literacy rate, adult male (% of males ages 15 and above)           NA\n84    Literacy rate, adult total (% of people ages 15 and above)           NA\n85         Literacy rate, youth female (% of females ages 15-24)           NA\n86             Literacy rate, youth male (% of males ages 15-24)           NA\n87           Literacy rate, youth total (% of people ages 15-24)           NA\n88                                             Population, total 2.038604e+07\n89                                             GDP (current US$)           NA\n90                      Life expectancy at birth, female (years) 6.215000e+01\n91                        Life expectancy at birth, male (years) 5.612300e+01\n92                       Life expectancy at birth, total (years) 5.906300e+01\n93  Literacy rate, adult female (% of females ages 15 and above)           NA\n94      Literacy rate, adult male (% of males ages 15 and above)           NA\n95    Literacy rate, adult total (% of people ages 15 and above)           NA\n96         Literacy rate, youth female (% of females ages 15-24)           NA\n97             Literacy rate, youth male (% of males ages 15-24)           NA\n98           Literacy rate, youth total (% of people ages 15-24)           NA\n99                                             Population, total 1.863705e+06\n100                                            GDP (current US$)           NA\n            1961         1962         1963         1964         1965\n1             NA           NA           NA           NA           NA\n2   3.404300e+01 3.450200e+01 3.494500e+01 3.542800e+01 3.590000e+01\n3   3.262600e+01 3.309800e+01 3.354300e+01 3.400400e+01 3.443800e+01\n4   3.329100e+01 3.375700e+01 3.420100e+01 3.467300e+01 3.512400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  9.214083e+06 9.404406e+06 9.604487e+06 9.814318e+06 1.003601e+07\n12            NA           NA           NA           NA           NA\n13  5.999500e+01 6.104700e+01 6.208600e+01 6.304800e+01 6.393400e+01\n14  5.502800e+01 5.600000e+01 5.693800e+01 5.782400e+01 5.867700e+01\n15  5.748800e+01 5.849400e+01 5.947900e+01 6.040400e+01 6.127300e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  1.659800e+06 1.711319e+06 1.762621e+06 1.814135e+06 1.864791e+06\n23  2.434747e+09 2.001445e+09 2.702982e+09 2.909316e+09 3.136284e+09\n24  4.377000e+01 4.270600e+01 4.360700e+01 4.342900e+01 4.327000e+01\n25  3.819400e+01 3.681300e+01 4.267400e+01 4.254300e+01 4.242600e+01\n26  4.079200e+01 3.952700e+01 4.314300e+01 4.298700e+01 4.284600e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.162888e+07 1.180077e+07 1.198212e+07 1.217981e+07 1.236598e+07\n34            NA           NA           NA           NA           NA\n35  6.791600e+01 6.842700e+01 6.856700e+01 6.845400e+01 6.821100e+01\n36  6.362800e+01 6.388800e+01 6.406000e+01 6.410100e+01 6.404400e+01\n37  6.564800e+01 6.600800e+01 6.616100e+01 6.613500e+01 6.599600e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.066600e+04 2.129800e+04 2.196600e+04 2.267300e+04 2.340600e+04\n45            NA           NA           NA           NA           NA\n46  7.574400e+01 7.637200e+01 7.687100e+01 7.735200e+01 7.768800e+01\n47  6.945400e+01 6.973500e+01 6.992400e+01 7.017500e+01 7.038600e+01\n48  7.257300e+01 7.299300e+01 7.329800e+01 7.362400e+01 7.385600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  1.028300e+04 1.108600e+04 1.191500e+04 1.276400e+04 1.363400e+04\n56            NA           NA           NA           NA           NA\n57  3.988500e+01 4.021800e+01 4.050700e+01 4.081300e+01 4.112000e+01\n58  3.426600e+01 3.448900e+01 3.472000e+01 3.499600e+01 3.523600e+01\n59  3.690200e+01 3.716800e+01 3.741900e+01 3.770400e+01 3.796800e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.301583e+06 5.354310e+06 5.408320e+06 5.464187e+06 5.521981e+06\n67            NA           NA           NA           NA           NA\n68  6.552000e+01 6.623200e+01 6.700200e+01 6.778600e+01 6.858400e+01\n69  6.076600e+01 6.139100e+01 6.203600e+01 6.272800e+01 6.340700e+01\n70  6.333500e+01 6.399500e+01 6.469700e+01 6.542800e+01 6.617100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  5.654000e+04 5.733600e+04 5.813800e+04 5.902000e+04 5.997000e+04\n78            NA 2.445060e+10 1.827212e+10 2.560525e+10 2.834471e+10\n79  6.823600e+01 6.828200e+01 6.857500e+01 6.853700e+01 6.881900e+01\n80  6.152600e+01 6.147400e+01 6.165000e+01 6.160900e+01 6.178300e+01\n81  6.463100e+01 6.461800e+01 6.485500e+01 6.481600e+01 6.505300e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.072628e+07 2.107254e+07 2.142170e+07 2.176945e+07 2.211263e+07\n89            NA           NA           NA           NA           NA\n90  6.259800e+01 6.303800e+01 6.346700e+01 6.388100e+01 6.427700e+01\n91  5.653800e+01 5.694400e+01 5.733900e+01 5.771700e+01 5.807300e+01\n92  5.949410e+01 5.991668e+01 6.032827e+01 6.072383e+01 6.109934e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  1.927484e+06 1.991689e+06 2.056023e+06 2.120135e+06 2.183635e+06\n100           NA           NA           NA           NA           NA\n            1966         1967         1968         1969         1970\n1             NA           NA           NA           NA           NA\n2   3.638000e+01 3.685100e+01 3.728100e+01 3.775800e+01 3.826100e+01\n3   3.487700e+01 3.532400e+01 3.582500e+01 3.628700e+01 3.674800e+01\n4   3.558300e+01 3.604200e+01 3.651000e+01 3.697900e+01 3.746000e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.026640e+07 1.050596e+07 1.075692e+07 1.101741e+07 1.129013e+07\n12            NA           NA           NA           NA           NA\n13  6.481400e+01 6.564200e+01 6.647600e+01 6.723700e+01 6.794600e+01\n14  5.954300e+01 6.036400e+01 6.115100e+01 6.188800e+01 6.258100e+01\n15  6.214900e+01 6.297600e+01 6.378800e+01 6.453800e+01 6.523400e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  1.914573e+06 1.965598e+06 2.022272e+06 2.081695e+06 2.135479e+06\n23  3.039859e+09 3.370870e+09 3.852147e+09 4.257253e+09 4.863527e+09\n24  4.315500e+01 4.312200e+01 4.318900e+01 4.338100e+01 4.373800e+01\n25  4.234700e+01 4.234300e+01 4.242600e+01 4.260600e+01 4.292600e+01\n26  4.274500e+01 4.273100e+01 4.280600e+01 4.299100e+01 4.332800e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.259007e+07 1.287612e+07 1.317261e+07 1.347596e+07 1.378372e+07\n34            NA           NA           NA           NA           NA\n35  5.858300e+01 6.801900e+01 6.812800e+01 6.846500e+01 6.902000e+01\n36  5.803300e+01 6.385200e+01 6.383000e+01 6.391800e+01 6.404600e+01\n37  5.828400e+01 6.580700e+01 6.584700e+01 6.605000e+01 6.636400e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.413600e+04 2.486300e+04 2.561400e+04 2.637500e+04 2.702600e+04\n45            NA           NA           NA           NA 7.861771e+07\n46  7.790900e+01 7.797900e+01 7.800200e+01 7.798800e+01 7.807500e+01\n47  7.058300e+01 7.074100e+01 7.093400e+01 7.111100e+01 7.135300e+01\n48  7.402000e+01 7.411900e+01 7.422000e+01 7.429600e+01 7.445200e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  1.462600e+04 1.583700e+04 1.717600e+04 1.855500e+04 1.997700e+04\n56            NA           NA           NA           NA           NA\n57  4.148700e+01 4.183700e+01 4.223000e+01 4.257700e+01 4.296400e+01\n58  3.548000e+01 3.584900e+01 3.618000e+01 3.655900e+01 3.690800e+01\n59  3.825800e+01 3.861600e+01 3.896800e+01 3.932900e+01 3.968800e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.581386e+06 5.641807e+06 5.702699e+06 5.763685e+06 5.852788e+06\n67            NA           NA           NA           NA           NA\n68  6.935300e+01 7.009300e+01 7.077800e+01 7.139700e+01 7.196600e+01\n69  6.408500e+01 6.469800e+01 6.527800e+01 6.582900e+01 6.631500e+01\n70  6.690200e+01 6.758600e+01 6.823000e+01 6.882700e+01 6.937100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.090000e+04 6.183700e+04 6.280900e+04 6.381900e+04 6.452800e+04\n78  2.863047e+10 2.425667e+10 2.643686e+10 3.125628e+10 3.158421e+10\n79  6.909500e+01 6.928800e+01 6.919300e+01 6.913300e+01 6.956400e+01\n80  6.215700e+01 6.212600e+01 6.177900e+01 6.155300e+01 6.216500e+01\n81  6.539800e+01 6.546700e+01 6.523400e+01 6.508500e+01 6.564700e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.245389e+07 2.279906e+07 2.315058e+07 2.350871e+07 2.387833e+07\n89            NA           NA           NA           NA           NA\n90  6.465300e+01 6.500800e+01 6.534300e+01 6.565800e+01 6.595400e+01\n91  5.840700e+01 5.871500e+01 5.899900e+01 5.925800e+01 5.949300e+01\n92  6.145383e+01 6.178476e+01 6.209363e+01 6.237995e+01 6.264471e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.246159e+06 2.307492e+06 2.367319e+06 2.424030e+06 2.475633e+06\n100           NA           NA           NA           NA           NA\n            1971         1972         1973         1974         1975\n1             NA           NA           NA           NA           NA\n2   3.875200e+01 3.925500e+01 3.977800e+01 4.029100e+01 4.081300e+01\n3   3.720200e+01 3.768100e+01 3.821300e+01 3.873400e+01 3.926100e+01\n4   3.793200e+01 3.842300e+01 3.895100e+01 3.946900e+01 3.999400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.156767e+07 1.185370e+07 1.215800e+07 1.246913e+07 1.277395e+07\n12            NA           NA           NA           NA           NA\n13  6.861200e+01 6.924600e+01 6.984400e+01 7.040000e+01 7.091800e+01\n14  6.324600e+01 6.387000e+01 6.444200e+01 6.495400e+01 6.542500e+01\n15  6.589600e+01 6.652600e+01 6.710700e+01 6.763300e+01 6.812000e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.187853e+06 2.243126e+06 2.296752e+06 2.350124e+06 2.404831e+06\n23  5.077183e+09 6.766744e+09 8.707859e+09 1.320987e+10 1.555790e+10\n24  4.423400e+01 4.489400e+01 4.567900e+01 4.660700e+01 4.766900e+01\n25  4.334400e+01 4.389500e+01 4.455300e+01 4.533700e+01 4.622100e+01\n26  4.378200e+01 4.438400e+01 4.510200e+01 4.595300e+01 4.692100e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.409894e+07 1.442707e+07 1.477115e+07 1.513350e+07 1.567860e+07\n34            NA           NA           NA           NA           NA\n35  6.969600e+01 7.029400e+01 7.069800e+01 7.104000e+01 7.133100e+01\n36  6.425800e+01 6.454100e+01 6.496000e+01 6.528900e+01 6.559400e+01\n37  6.677000e+01 6.718600e+01 6.760400e+01 6.795000e+01 6.825600e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.753300e+04 2.799500e+04 2.843600e+04 2.887500e+04 2.939000e+04\n45  8.940661e+07 1.134144e+08 1.508416e+08 1.865571e+08 2.201126e+08\n46  7.819300e+01 7.846100e+01 7.875100e+01 7.907200e+01 7.939100e+01\n47  7.158300e+01 7.185500e+01 7.208400e+01 7.231100e+01 7.251400e+01\n48  7.461500e+01 7.486400e+01 7.509600e+01 7.534000e+01 7.556700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  2.144200e+04 2.295700e+04 2.452300e+04 2.613000e+04 2.777300e+04\n56            NA           NA           NA           NA           NA\n57  4.331100e+01 4.370200e+01 4.404000e+01 4.441900e+01 4.417900e+01\n58  3.731600e+01 3.770100e+01 3.814300e+01 3.853100e+01 3.793600e+01\n59  4.007600e+01 4.046900e+01 4.087100e+01 4.126000e+01 4.081700e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.991102e+06 6.174262e+06 6.388528e+06 6.613367e+06 6.842947e+06\n67            NA           NA           NA           NA           NA\n68  7.248700e+01 7.295700e+01 7.337400e+01 7.377700e+01 7.414500e+01\n69  6.678900e+01 6.722300e+01 6.763600e+01 6.802100e+01 6.837400e+01\n70  6.986100e+01 7.030400e+01 7.071000e+01 7.109500e+01 7.144700e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.472900e+04 6.461500e+04 6.434200e+04 6.405800e+04 6.383900e+04\n78  3.329320e+10 3.473300e+10 5.254400e+10 7.243678e+10 5.243865e+10\n79  6.941700e+01 6.976400e+01 7.008700e+01 7.037100e+01 7.091300e+01\n80  6.221000e+01 6.251700e+01 6.267100e+01 6.280800e+01 6.336700e+01\n81  6.561900e+01 6.595300e+01 6.618600e+01 6.640500e+01 6.696500e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.425721e+07 2.464433e+07 2.504600e+07 2.546135e+07 2.587411e+07\n89            NA           NA           NA           NA           NA\n90  6.623200e+01 6.647500e+01 6.671500e+01 6.695900e+01 6.721700e+01\n91  5.970500e+01 5.991400e+01 6.010800e+01 6.029700e+01 6.048300e+01\n92  6.288890e+01 6.311449e+01 6.333093e+01 6.354676e+01 6.376788e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.525345e+06 2.577079e+06 2.630860e+06 2.686445e+06 2.743660e+06\n100           NA           NA           NA           NA           NA\n            1976         1977         1978         1979         1980\n1             NA           NA           NA           NA           NA\n2   4.133300e+01 4.188000e+01 4.147900e+01 4.088100e+01 4.137900e+01\n3   3.978700e+01 4.036300e+01 3.885500e+01 3.709000e+01 3.742800e+01\n4   4.051800e+01 4.108200e+01 4.008600e+01 3.884400e+01 3.925800e+01\n5             NA           NA           NA 5.000000e+00           NA\n6             NA           NA           NA 3.000000e+01           NA\n7             NA           NA           NA 1.800000e+01           NA\n8             NA           NA           NA 1.100000e+01           NA\n9             NA           NA           NA 4.600000e+01           NA\n10            NA           NA           NA 3.000000e+01           NA\n11  1.305985e+07 1.334076e+07 1.361144e+07 1.365557e+07 1.316931e+07\n12            NA           NA           NA           NA 1.578102e+09\n13  7.139900e+01 7.185200e+01 7.226900e+01 7.259700e+01 7.296700e+01\n14  6.586100e+01 6.627100e+01 6.662500e+01 6.682800e+01 6.704000e+01\n15  6.857000e+01 6.899200e+01 6.936700e+01 6.961700e+01 6.990300e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.458526e+06 2.513546e+06 2.566266e+06 2.617832e+06 2.671997e+06\n23  1.772824e+10 2.097211e+10 2.636449e+10 3.324371e+10 4.234583e+10\n24  4.890300e+01 5.027900e+01 5.182200e+01 5.378000e+01 5.603100e+01\n25  4.721900e+01 4.828600e+01 4.949300e+01 5.114200e+01 5.310400e+01\n26  4.803400e+01 4.924900e+01 5.061500e+01 5.240900e+01 5.451200e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.640917e+07 1.701599e+07 1.750697e+07 1.803666e+07 1.860717e+07\n34            NA           NA           NA           NA           NA\n35  7.159000e+01 7.182200e+01 7.203100e+01 7.224000e+01 7.253800e+01\n36  6.579500e+01 6.603000e+01 6.619800e+01 6.645100e+01 6.674700e+01\n37  6.847500e+01 6.870100e+01 6.888100e+01 6.911400e+01 6.941300e+01\n38            NA           NA           NA           NA 9.700000e+01\n39            NA           NA           NA           NA 9.700000e+01\n40            NA           NA           NA           NA 9.700000e+01\n41            NA           NA           NA           NA 9.700000e+01\n42            NA           NA           NA           NA 9.800000e+01\n43            NA           NA           NA           NA 9.800000e+01\n44  2.995900e+04 3.052100e+04 3.107600e+04 3.161100e+04 3.240300e+04\n45  2.272839e+08 2.539979e+08 3.080203e+08 4.115487e+08 4.463778e+08\n46  7.978500e+01 8.015400e+01 8.056900e+01 8.097500e+01 8.137000e+01\n47  7.278700e+01 7.305400e+01 7.335700e+01 7.366300e+01 7.395600e+01\n48  7.586900e+01 7.615400e+01 7.648800e+01 7.681900e+01 7.713700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  2.943600e+04 3.109700e+04 3.273500e+04 3.430600e+04 3.578200e+04\n56            NA           NA           NA           NA 5.930503e+09\n57  4.423300e+01 4.458500e+01 4.488900e+01 4.518400e+01 4.547000e+01\n58  3.788200e+01 3.831200e+01 3.870000e+01 3.906200e+01 3.941100e+01\n59  4.081200e+01 4.121500e+01 4.157300e+01 4.191300e+01 4.224200e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  7.074664e+06 7.317829e+06 7.576734e+06 7.847207e+06 8.133872e+06\n67            NA 7.749630e+07 8.803333e+07 1.095852e+08 1.324407e+08\n68  7.450200e+01 7.488300e+01 7.526200e+01 7.559500e+01 7.585300e+01\n69  6.872700e+01 6.906800e+01 6.940300e+01 6.972900e+01 7.002200e+01\n70  7.179400e+01 7.214900e+01 7.250000e+01 7.282300e+01 7.309400e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.376200e+04 6.386200e+04 6.403800e+04 6.427400e+04 6.451300e+04\n78  5.116950e+10 5.678100e+10 8.904945e+10 6.925233e+10 7.696192e+10\n79  7.098300e+01 7.155900e+01 7.170800e+01 7.200100e+01 7.204700e+01\n80  6.340600e+01 6.394400e+01 6.453500e+01 6.507200e+01 6.528200e+01\n81  6.703000e+01 6.759500e+01 6.799900e+01 6.843400e+01 6.857600e+01\n82            NA           NA           NA           NA 9.400000e+01\n83            NA           NA           NA           NA 9.400000e+01\n84            NA           NA           NA           NA 9.400000e+01\n85            NA           NA           NA           NA 9.700000e+01\n86            NA           NA           NA           NA 9.600000e+01\n87            NA           NA           NA           NA 9.700000e+01\n88  2.628228e+07 2.670180e+07 2.713216e+07 2.756890e+07 2.801160e+07\n89            NA           NA           NA           NA           NA\n90  6.748800e+01 6.778400e+01 6.808800e+01 6.839800e+01 6.870600e+01\n91  6.068100e+01 6.089200e+01 6.113400e+01 6.141400e+01 6.174100e+01\n92  6.400149e+01 6.425395e+01 6.452620e+01 6.482083e+01 6.513856e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.818165e+06 2.912827e+06 3.012807e+06 3.078501e+06 3.107415e+06\n100           NA           NA           NA           NA           NA\n            1981         1982         1983         1984         1985\n1             NA           NA           NA           NA           NA\n2   4.169500e+01 3.951800e+01 4.009300e+01 3.642200e+01 3.710100e+01\n3   3.743300e+01 3.325100e+01 3.359900e+01 2.782300e+01 2.839300e+01\n4   3.940600e+01 3.605800e+01 3.651700e+01 3.147300e+01 3.213200e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.193758e+07 1.099138e+07 1.091798e+07 1.119022e+07 1.142685e+07\n12  1.808177e+09 1.861163e+09 1.881413e+09 1.857338e+09 1.897050e+09\n13  7.328700e+01 7.361800e+01 7.397000e+01 7.432900e+01 7.468400e+01\n14  6.721000e+01 6.744100e+01 6.765800e+01 6.786700e+01 6.811500e+01\n15  7.014500e+01 7.042500e+01 7.070500e+01 7.098400e+01 7.128200e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.726056e+06 2.784278e+06 2.843960e+06 2.904429e+06 2.964762e+06\n23  4.434859e+10 4.520717e+10 4.880137e+10 5.369855e+10 5.793787e+10\n24  5.908400e+01 6.124700e+01 6.274200e+01 6.408600e+01 6.543100e+01\n25  5.587600e+01 5.804800e+01 5.984800e+01 6.142700e+01 6.293800e+01\n26  5.742200e+01 5.959400e+01 6.125100e+01 6.272200e+01 6.415500e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.922070e+07 1.987235e+07 2.055812e+07 2.127197e+07 2.200854e+07\n34            NA           NA           NA           NA           NA\n35  7.287500e+01 7.307000e+01 7.318700e+01 7.327500e+01 7.351100e+01\n36  6.705400e+01 6.734300e+01 6.759300e+01 6.781900e+01 6.800700e+01\n37  6.973100e+01 6.997500e+01 7.016300e+01 7.032600e+01 7.053200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  3.358400e+04 3.490900e+04 3.627100e+04 3.766700e+04 3.910300e+04\n45  3.889833e+08 3.759147e+08 3.278500e+08 3.300731e+08 3.467427e+08\n46  8.169000e+01 8.197100e+01 8.219600e+01 8.240400e+01 8.257100e+01\n47  7.419900e+01 7.440300e+01 7.454800e+01 7.465400e+01 7.471900e+01\n48  7.739100e+01 7.761700e+01 7.778700e+01 7.791600e+01 7.800600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  3.716900e+04 3.876400e+04 4.056500e+04 4.227300e+04 4.382500e+04\n56  5.550483e+09 5.550483e+09 5.784342e+09 6.131475e+09 7.554065e+09\n57  4.575000e+01 4.601600e+01 4.545600e+01 4.568600e+01 4.589100e+01\n58  3.973800e+01 4.005400e+01 3.892300e+01 3.921300e+01 3.948000e+01\n59  4.255600e+01 4.285700e+01 4.197200e+01 4.224500e+01 4.249500e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  8.435607e+06 8.751648e+06 9.082983e+06 9.425917e+06 9.779120e+06\n67  1.493778e+08 1.664259e+08 1.848481e+08 2.121926e+08 2.463444e+08\n68  7.605000e+01 7.623700e+01 7.638100e+01 7.649900e+01 7.657300e+01\n69  7.028800e+01 7.051900e+01 7.070300e+01 7.084000e+01 7.092600e+01\n70  7.332000e+01 7.352500e+01 7.368400e+01 7.380800e+01 7.387300e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.466500e+04 6.478500e+04 6.493400e+04 6.488200e+04 6.459100e+04\n78  7.867684e+10 8.430749e+10 1.039791e+11 1.169151e+11 8.815089e+10\n79  7.243600e+01 7.255700e+01 7.270600e+01 7.277800e+01 7.340200e+01\n80  6.545500e+01 6.555900e+01 6.600200e+01 6.605400e+01 6.647400e+01\n81  6.885800e+01 6.897300e+01 6.929000e+01 6.935300e+01 6.987900e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.846396e+07 2.892426e+07 2.939133e+07 2.986309e+07 3.033644e+07\n89            NA           NA           NA           NA           NA\n90  6.901100e+01 6.931900e+01 6.962100e+01 6.991500e+01 7.020100e+01\n91  6.212200e+01 6.254800e+01 6.299900e+01 6.342600e+01 6.378600e+01\n92  6.548249e+01 6.585093e+01 6.622924e+01 6.659137e+01 6.691527e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.135349e+06 3.163144e+06 3.191539e+06 3.224547e+06 3.260432e+06\n100           NA           NA           NA           NA           NA\n            1986         1987         1988         1989         1990\n1             NA           NA           NA           NA           NA\n2   4.207200e+01 4.260300e+01 4.596200e+01 4.704200e+01 4.770300e+01\n3   3.527000e+01 3.560100e+01 4.074200e+01 4.213200e+01 4.271200e+01\n4   3.840000e+01 3.883100e+01 4.323800e+01 4.449600e+01 4.511800e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.142007e+07 1.138782e+07 1.152330e+07 1.187409e+07 1.204566e+07\n12  2.097326e+09 2.080796e+09 2.051236e+09 2.253090e+09 2.028554e+09\n13  7.513800e+01 7.547700e+01 7.572600e+01 7.595600e+01 7.619500e+01\n14  6.843700e+01 6.872700e+01 6.894000e+01 6.917400e+01 6.941200e+01\n15  7.166500e+01 7.198100e+01 7.221700e+01 7.245700e+01 7.271000e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.022635e+06 3.083605e+06 3.142336e+06 3.227943e+06 3.286542e+06\n23  6.369201e+10 6.674582e+10 5.908940e+10 5.563472e+10 6.204851e+10\n24  6.648600e+01 6.718900e+01 6.765700e+01 6.807900e+01 6.824200e+01\n25  6.411600e+01 6.511300e+01 6.617900e+01 6.685600e+01 6.708800e+01\n26  6.527300e+01 6.613000e+01 6.691000e+01 6.746100e+01 6.765800e+01\n27            NA 3.600000e+01           NA           NA           NA\n28            NA 6.300000e+01           NA           NA           NA\n29            NA 5.000000e+01           NA           NA           NA\n30            NA 6.200000e+01           NA           NA           NA\n31            NA 8.600000e+01           NA           NA           NA\n32            NA 7.400000e+01           NA           NA           NA\n33  2.274550e+07 2.344362e+07 2.410954e+07 2.475448e+07 2.537581e+07\n34            NA           NA           NA           NA           NA\n35  7.388700e+01 7.429100e+01 7.466300e+01 7.485200e+01 7.524200e+01\n36  6.801700e+01 6.793400e+01 6.777100e+01 6.773900e+01 6.777200e+01\n37  7.070400e+01 7.082800e+01 7.088300e+01 7.092900e+01 7.110700e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  4.057100e+04 4.207200e+04 4.361500e+04 4.519100e+04 4.664000e+04\n45  4.819960e+08 6.112999e+08 7.214259e+08 7.954896e+08 1.028990e+09\n46  8.277500e+01 8.296000e+01 8.311700e+01 8.323500e+01 8.338700e+01\n47  7.479000e+01 7.484500e+01 7.503300e+01 7.528100e+01 7.581500e+01\n48  7.810700e+01 7.818900e+01 7.836400e+01 7.855700e+01 7.896100e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  4.573400e+04 4.765300e+04 4.941600e+04 5.062000e+04 5.259700e+04\n56  7.072536e+09 8.084412e+09 8.769837e+09 1.020178e+10 1.122952e+10\n57  4.607200e+01 4.462400e+01 4.512500e+01 4.531500e+01 4.543000e+01\n58  3.975900e+01 3.744100e+01 3.823400e+01 3.846800e+01 3.863900e+01\n59  4.273900e+01 4.078600e+01 4.147100e+01 4.169800e+01 4.185400e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.013945e+07 1.049786e+07 1.086129e+07 1.123856e+07 1.162636e+07\n67  2.975370e+08 3.468407e+08 4.113741e+08 4.551481e+08 4.786926e+08\n68  7.660300e+01 7.659000e+01 7.653200e+01 7.632800e+01 7.633800e+01\n69  7.096900e+01 7.097700e+01 7.094400e+01 7.081800e+01 7.079600e+01\n70  7.389300e+01 7.387300e+01 7.381100e+01 7.362800e+01 7.360200e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.427600e+04 6.394600e+04 6.362300e+04 6.332500e+04 6.306600e+04\n78  1.058724e+11 1.088109e+11 1.268902e+11 7.662973e+10 1.413526e+11\n79  7.381000e+01 7.421900e+01 7.462300e+01 7.503900e+01 7.487800e+01\n80  6.685200e+01 6.725600e+01 6.763200e+01 6.800800e+01 6.834700e+01\n81  7.028100e+01 7.069900e+01 7.109700e+01 7.150200e+01 7.161500e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.081198e+07 3.129176e+07 3.178053e+07 3.227095e+07 3.275590e+07\n89            NA           NA           NA           NA 2.256863e+09\n90  7.047500e+01 7.073700e+01 5.356100e+01 7.123300e+01 7.146100e+01\n91  6.403800e+01 6.414200e+01 5.168500e+01 6.398100e+01 6.382400e+01\n92  6.717800e+01 6.735907e+01 5.260012e+01 6.751856e+01 6.754937e+01\n93            NA           NA           NA 9.800000e+01           NA\n94            NA           NA           NA 9.900000e+01           NA\n95            NA           NA           NA 9.900000e+01           NA\n96            NA           NA           NA 1.000000e+02           NA\n97            NA           NA           NA 1.000000e+02           NA\n98            NA           NA           NA 1.000000e+02           NA\n99  3.294847e+06 3.328520e+06 3.355125e+06 3.443100e+06 3.552128e+06\n100 4.055866e+08 4.877095e+08 5.966480e+08 6.955307e+08 7.648045e+08\n            1991         1992         1993         1994         1995\n1             NA           NA           NA           NA           NA\n2   4.828200e+01 4.960700e+01 5.229600e+01 5.313500e+01 5.369400e+01\n3   4.295900e+01 4.376500e+01 4.975500e+01 4.888300e+01 5.053600e+01\n4   4.552100e+01 4.656900e+01 5.102100e+01 5.096900e+01 5.210300e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.223888e+07 1.327897e+07 1.494317e+07 1.625079e+07 1.706584e+07\n12  1.099559e+09 6.521750e+08 1.185315e+09 1.880951e+09 2.392765e+09\n13  7.645200e+01 7.672000e+01 7.700000e+01 7.720600e+01 7.740700e+01\n14  6.970500e+01 7.001400e+01 7.038000e+01 7.056600e+01 7.073400e+01\n15  7.300100e+01 7.330300e+01 7.363800e+01 7.383700e+01 7.402200e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.266790e+06 3.247039e+06 3.227287e+06 3.207536e+06 3.187784e+06\n23  4.571568e+10 4.800313e+10 4.994558e+10 4.254318e+10 4.176429e+10\n24  6.851200e+01 6.872700e+01 6.913900e+01 6.921900e+01 6.953500e+01\n25  6.690100e+01 6.677000e+01 6.654800e+01 6.552400e+01 6.600300e+01\n26  6.769200e+01 6.772500e+01 6.779700e+01 6.728400e+01 6.769100e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  2.598793e+07 2.662857e+07 2.727705e+07 2.788728e+07 2.847019e+07\n34            NA           NA           NA           NA           NA\n35  7.555100e+01 7.578400e+01 7.566200e+01 7.555400e+01 7.542200e+01\n36  6.788300e+01 6.803400e+01 6.816100e+01 6.828500e+01 6.837500e+01\n37  7.131200e+01 7.151100e+01 7.154000e+01 7.156900e+01 7.156500e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  4.788200e+04 4.903800e+04 5.015900e+04 5.125100e+04 5.231600e+04\n45  1.106891e+09 1.209992e+09 1.007090e+09 1.017544e+09 1.178745e+09\n46  8.347100e+01 8.360900e+01 8.382300e+01 8.408500e+01 8.429400e+01\n47  7.636700e+01 7.702100e+01 7.754900e+01 7.807100e+01 7.820700e+01\n48  7.934600e+01 7.979400e+01 8.018600e+01 8.058700e+01 8.080400e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  5.666700e+04 6.020000e+04 6.327200e+04 6.461200e+04 6.391200e+04\n56  1.060378e+10 8.307811e+09 5.768720e+09 4.438321e+09 5.538749e+09\n57  4.684400e+01 4.556300e+01 4.672300e+01 4.774500e+01 4.816000e+01\n58  4.099100e+01 3.924300e+01 3.822700e+01 3.981900e+01 4.414500e+01\n59  4.381200e+01 4.226700e+01 4.219000e+01 4.356700e+01 4.613900e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.202353e+07 1.242371e+07 1.282714e+07 1.324976e+07 1.369978e+07\n67  5.043074e+08 5.251037e+08 5.656333e+08 6.250519e+08 6.160148e+08\n68  7.622000e+01 7.612800e+01 7.616800e+01 7.634700e+01 7.652600e+01\n69  7.069500e+01 7.062200e+01 7.059400e+01 7.062100e+01 7.060700e+01\n70  7.347200e+01 7.338600e+01 7.339000e+01 7.349300e+01 7.357600e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.338700e+04 6.440400e+04 6.558700e+04 6.684300e+04 6.818900e+04\n78  1.897200e+11 2.287789e+11 2.367417e+11 2.574400e+11 2.580318e+11\n79  7.534400e+01 7.549600e+01 7.570700e+01 7.590900e+01 7.617000e+01\n80  6.868100e+01 6.869100e+01 6.889200e+01 6.950100e+01 6.952100e+01\n81  7.202000e+01 7.209600e+01 7.230300e+01 7.273200e+01 7.286400e+01\n82  9.600000e+01           NA           NA           NA           NA\n83  9.600000e+01           NA           NA           NA           NA\n84  9.600000e+01           NA           NA           NA           NA\n85  9.900000e+01           NA           NA           NA           NA\n86  9.800000e+01           NA           NA           NA           NA\n87  9.800000e+01           NA           NA           NA           NA\n88  3.323029e+07 3.369353e+07 3.415272e+07 3.461349e+07 3.507002e+07\n89  2.069870e+09 1.272835e+09 1.201313e+09 1.315159e+09 1.468317e+09\n90  7.169900e+01 7.189600e+01 7.214400e+01 7.237500e+01 7.261900e+01\n91  6.374900e+01 6.374000e+01 6.400100e+01 6.436400e+01 6.482800e+01\n92  6.762705e+01 6.771854e+01 6.797320e+01 6.827180e+01 6.862849e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.613977e+06 3.571861e+06 3.453332e+06 3.364610e+06 3.307581e+06\n100 8.720670e+08 9.586592e+08 1.083240e+09 1.245810e+09 1.320670e+09\n            1996         1997         1998         1999         2000\n1             NA           NA           NA           NA 3.521418e+09\n2   5.442600e+01 5.472000e+01 5.439200e+01 5.596600e+01 5.655500e+01\n3   5.126000e+01 5.172500e+01 5.063600e+01 5.310200e+01 5.346300e+01\n4   5.283000e+01 5.321200e+01 5.248700e+01 5.453200e+01 5.500500e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.776327e+07 1.845209e+07 1.916000e+07 1.988778e+07 2.013033e+07\n12  3.199641e+09 2.258514e+09 2.545965e+09 3.212122e+09 3.480355e+09\n13  7.753300e+01 7.705200e+01 7.772500e+01 7.782200e+01 7.792600e+01\n14  7.079800e+01 6.986600e+01 7.109200e+01 7.140500e+01 7.180400e+01\n15  7.411300e+01 7.338300e+01 7.435700e+01 7.456800e+01 7.482600e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.168033e+06 3.148281e+06 3.128530e+06 3.108778e+06 3.089027e+06\n23  4.694155e+10 4.817761e+10 4.818778e+10 4.864067e+10 5.479040e+10\n24  6.991800e+01 7.051700e+01 7.103100e+01 7.151000e+01 7.194400e+01\n25  6.665000e+01 6.732400e+01 6.775000e+01 6.875400e+01 6.928900e+01\n26  6.821900e+01 6.885900e+01 6.932700e+01 7.008800e+01 7.057600e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  2.903304e+07 2.957930e+07 3.005413e+07 3.047435e+07 3.090389e+07\n34            NA           NA           NA           NA           NA\n35  7.532200e+01 7.524600e+01 7.489000e+01 7.459100e+01 7.435100e+01\n36  6.846800e+01 6.857100e+01 6.871300e+01 6.882200e+01 6.891100e+01\n37  7.157600e+01 7.160600e+01 7.154200e+01 7.148400e+01 7.144300e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.335300e+04 5.436200e+04 5.533400e+04 5.624800e+04 5.685500e+04\n45  1.224024e+09 1.180646e+09 1.211954e+09 1.240295e+09 1.432606e+09\n46  8.451000e+01 8.471300e+01 8.486400e+01 8.506800e+01 8.509800e+01\n47  7.839200e+01 7.847900e+01 7.857700e+01 7.885600e+01 7.935300e+01\n48  8.100900e+01 8.114500e+01 8.128000e+01 8.155000e+01 8.186300e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  6.398400e+04 6.470000e+04 6.538200e+04 6.571000e+04 6.568500e+04\n56  7.526447e+09 7.648377e+09 6.506230e+09 6.152923e+09 9.129595e+09\n57  4.840200e+01 4.868400e+01 4.804700e+01 4.900300e+01 4.913200e+01\n58  4.445700e+01 4.471600e+01 4.295400e+01 4.279900e+01 4.396300e+01\n59  4.641800e+01 4.668800e+01 4.545200e+01 4.580800e+01 4.650100e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.417097e+07 1.466041e+07 1.515937e+07 1.566724e+07 1.619487e+07\n67  6.791111e+08 7.343926e+08 7.897630e+08 8.355148e+08 9.005519e+08\n68  7.694900e+01 7.730400e+01 7.751700e+01 7.786400e+01 7.829500e+01\n69  7.071800e+01 7.078200e+01 7.082600e+01 7.099100e+01 7.125900e+01\n70  7.383900e+01 7.404500e+01 7.418700e+01 7.445600e+01 7.481900e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.961200e+04 7.105300e+04 7.241200e+04 7.366600e+04 7.491200e+04\n78  2.721498e+11 2.928590e+11 2.989482e+11 2.835230e+11 2.842038e+11\n79  7.643300e+01 7.683800e+01 7.687600e+01 7.707500e+01 7.728800e+01\n80  6.965600e+01 6.995000e+01 6.993500e+01 7.026300e+01 7.049800e+01\n81  7.305600e+01 7.340700e+01 7.341200e+01 7.368300e+01 7.391000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.551379e+07 3.594779e+07 3.637286e+07 3.679468e+07 3.721398e+07\n89  1.596969e+09 1.639492e+09 1.893726e+09 1.845482e+09 1.911564e+09\n90  7.286500e+01 7.311800e+01 7.339700e+01 7.368700e+01 7.580000e+01\n91  6.533100e+01 6.584700e+01 6.637300e+01 6.687700e+01 7.010000e+01\n92  6.900612e+01 6.939383e+01 6.979934e+01 7.019895e+01 7.288049e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA 1.000000e+02\n97            NA           NA           NA           NA 1.000000e+02\n98            NA           NA           NA           NA 1.000000e+02\n99  3.278735e+06 3.246289e+06 3.208401e+06 3.167286e+06 3.221100e+06\n100 1.379888e+09 1.531844e+09 1.665363e+09 1.722905e+09 1.873453e+09\n            2001         2002         2003         2004         2005\n1   2.813572e+09 3.825701e+09 4.520947e+09 5.224897e+09 6.203257e+09\n2   5.708900e+01 5.744200e+01 5.847200e+01 5.907300e+01 5.958800e+01\n3   5.394100e+01 5.498600e+01 5.584900e+01 5.651900e+01 5.688000e+01\n4   5.551100e+01 5.622500e+01 5.717100e+01 5.781000e+01 5.824700e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  2.028431e+07 2.137812e+07 2.273305e+07 2.356065e+07 2.440457e+07\n12  3.922101e+09 4.348068e+09 5.611496e+09 7.184686e+09 8.052077e+09\n13  7.803100e+01 7.814200e+01 7.832900e+01 7.875300e+01 7.930300e+01\n14  7.220400e+01 7.252900e+01 7.286400e+01 7.324200e+01 7.366300e+01\n15  7.508300e+01 7.529900e+01 7.555700e+01 7.595100e+01 7.642700e+01\n16  9.800000e+01           NA           NA           NA           NA\n17  9.900000e+01           NA           NA           NA           NA\n18  9.900000e+01           NA           NA           NA           NA\n19  9.900000e+01           NA           NA           NA 9.949000e+01\n20  9.900000e+01           NA           NA           NA           NA\n21  9.900000e+01           NA           NA           NA           NA\n22  3.060173e+06 3.051010e+06 3.039616e+06 3.026939e+06 3.011487e+06\n23  5.941340e+10 6.151610e+10 7.348226e+10 9.191368e+10 1.070466e+11\n24  7.229500e+01 7.284200e+01 7.302700e+01 7.364200e+01 7.396200e+01\n25  6.982300e+01 7.050500e+01 7.083700e+01 7.147800e+01 7.176000e+01\n26  7.102500e+01 7.164400e+01 7.190600e+01 7.253600e+01 7.283600e+01\n27            NA 6.000000e+01           NA           NA           NA\n28            NA 7.900000e+01           NA           NA           NA\n29            NA 7.000000e+01           NA           NA           NA\n30            NA 8.600000e+01           NA           NA           NA\n31            NA 9.400000e+01           NA           NA           NA\n32            NA 9.000000e+01           NA           NA           NA\n33  3.133122e+07 3.175084e+07 3.217582e+07 3.262829e+07 3.310925e+07\n34            NA 5.120000e+08 5.240000e+08 5.090000e+08 5.000000e+08\n35  7.448300e+01 7.465700e+01 7.459000e+01 7.512500e+01 7.512500e+01\n36  6.904100e+01 6.923100e+01 6.918300e+01 6.979100e+01 6.997300e+01\n37  7.157300e+01 7.175500e+01 7.169800e+01 7.227700e+01 7.238200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.705300e+04 5.706200e+04 5.697100e+04 5.681800e+04 5.661700e+04\n45  1.548266e+09 1.764280e+09 2.366942e+09 2.900245e+09 3.161084e+09\n46  8.516700e+01 8.513000e+01 8.511600e+01 8.497900e+01 8.527200e+01\n47  7.977800e+01 8.026600e+01 8.073400e+01 8.099000e+01 8.124000e+01\n48  8.216200e+01 8.244800e+01 8.271800e+01 8.281500e+01 8.308600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  6.585200e+04 6.650600e+04 6.948600e+04 7.432500e+04 7.742100e+04\n56  8.936079e+09 1.528559e+10 1.781270e+10 2.355206e+10 3.697090e+10\n57  5.004700e+01 5.036700e+01 5.218100e+01 5.307400e+01 5.405100e+01\n58  4.416200e+01 4.544600e+01 4.825800e+01 4.917000e+01 5.020300e+01\n59  4.703200e+01 4.787400e+01 5.021800e+01 5.112300e+01 5.213000e+01\n60  5.400000e+01           NA           NA           NA           NA\n61  8.300000e+01           NA           NA           NA           NA\n62  6.700000e+01           NA           NA           NA           NA\n63  6.300000e+01           NA           NA           NA           NA\n64  8.400000e+01           NA           NA           NA           NA\n65  7.200000e+01           NA           NA           NA           NA\n66  1.674721e+07 1.732770e+07 1.794371e+07 1.860042e+07 1.929116e+07\n67  8.775148e+08 8.979889e+08 9.479556e+08 1.026181e+09 1.143715e+09\n68  7.859200e+01 7.851900e+01 7.827600e+01 7.817900e+01 7.829800e+01\n69  7.153100e+01 7.181800e+01 7.215300e+01 7.227200e+01 7.223600e+01\n70  7.510800e+01 7.523700e+01 7.531300e+01 7.532900e+01 7.536400e+01\n71  9.900000e+01           NA           NA           NA           NA\n72  9.800000e+01           NA           NA           NA           NA\n73  9.900000e+01           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  7.606900e+04 7.703200e+04 7.788400e+04 7.871900e+04 7.961100e+04\n78  2.686968e+11 9.772400e+10 1.275870e+11 1.646579e+11 1.987371e+11\n79  7.764200e+01 7.791100e+01 7.780800e+01 7.817700e+01 7.863200e+01\n80  7.063700e+01 7.070400e+01 7.079600e+01 7.150000e+01 7.176700e+01\n81  7.415400e+01 7.431200e+01 7.430700e+01 7.487100e+01 7.523100e+01\n82  9.700000e+01           NA           NA           NA           NA\n83  9.700000e+01           NA           NA           NA           NA\n84  9.700000e+01           NA           NA           NA           NA\n85  9.900000e+01           NA           NA           NA           NA\n86  9.900000e+01           NA           NA           NA           NA\n87  9.900000e+01           NA           NA           NA           NA\n88  3.762482e+07 3.802935e+07 3.842428e+07 3.881592e+07 3.921679e+07\n89  2.118468e+09 2.376335e+09 2.807061e+09 3.576615e+09 4.900470e+09\n90  7.610000e+01 7.590000e+01 7.590000e+01 7.610000e+01 7.620000e+01\n91  7.000000e+01 6.990000e+01 6.990000e+01 7.010000e+01 7.010000e+01\n92  7.297561e+01 7.282683e+01 7.282683e+01 7.302683e+01 7.307561e+01\n93  9.900000e+01           NA           NA           NA           NA\n94  1.000000e+02           NA           NA           NA           NA\n95  9.900000e+01           NA           NA           NA           NA\n96  1.000000e+02           NA           NA           NA           NA\n97  1.000000e+02           NA           NA           NA           NA\n98  1.000000e+02           NA           NA           NA           NA\n99  3.211800e+06 3.199800e+06 3.182500e+06 3.164900e+06 3.146400e+06\n100 1.896457e+09 1.961844e+09 2.044112e+09 2.254831e+09 2.360017e+09\n            2006         2007         2008         2009         2010\n1   6.971758e+09 9.747886e+09 1.010930e+10 1.241615e+10 1.585667e+10\n2   6.012300e+01 6.080400e+01 6.142800e+01 6.179100e+01 6.228300e+01\n3   5.697400e+01 5.712200e+01 5.798400e+01 5.868100e+01 5.909700e+01\n4   5.855300e+01 5.895600e+01 5.970800e+01 6.024800e+01 6.070200e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  2.542409e+07 2.590985e+07 2.648262e+07 2.746610e+07 2.828409e+07\n12  8.896075e+09 1.067732e+10 1.288135e+10 1.204421e+10 1.192693e+10\n13  7.994300e+01 8.058400e+01 8.107600e+01 8.128200e+01 8.110800e+01\n14  7.418300e+01 7.492200e+01 7.553100e+01 7.584200e+01 7.582500e+01\n15  7.699400e+01 7.769100e+01 7.824800e+01 7.850900e+01 7.841400e+01\n16            NA           NA 9.500000e+01           NA           NA\n17            NA           NA 9.700000e+01           NA           NA\n18            NA           NA 9.600000e+01           NA           NA\n19            NA           NA 9.900000e+01 9.661000e+01           NA\n20            NA           NA 9.900000e+01 9.482000e+01           NA\n21            NA           NA 9.900000e+01 9.568000e+01           NA\n22  2.992547e+06 2.970017e+06 2.947314e+06 2.927519e+06 2.913021e+06\n23  1.230843e+11 1.424827e+11 1.803838e+11 1.503173e+11 1.777851e+11\n24  7.428300e+01 7.455600e+01 7.482700e+01 7.507400e+01 7.531900e+01\n25  7.200300e+01 7.219200e+01 7.246400e+01 7.272100e+01 7.301700e+01\n26  7.311600e+01 7.334600e+01 7.361800e+01 7.387100e+01 7.414400e+01\n27  6.400000e+01           NA 6.800000e+01           NA           NA\n28  8.100000e+01           NA 8.300000e+01           NA           NA\n29  7.300000e+01           NA 7.500000e+01           NA           NA\n30  8.900000e+01           NA 9.200000e+01           NA           NA\n31  9.400000e+01           NA 9.600000e+01           NA           NA\n32  9.200000e+01           NA 9.400000e+01           NA           NA\n33  3.362351e+07 3.418942e+07 3.481696e+07 3.549044e+07 3.618824e+07\n34  4.930000e+08 5.180000e+08 5.600000e+08 6.750000e+08 5.730000e+08\n35  7.504300e+01 7.494700e+01 7.503000e+01 7.312300e+01 7.519900e+01\n36  7.006100e+01 7.007200e+01 7.011600e+01 6.878900e+01 7.024000e+01\n37  7.239700e+01 7.236500e+01 7.243000e+01 7.083900e+01 7.258700e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.637400e+04 5.611300e+04 5.582800e+04 5.552800e+04 5.522800e+04\n45  3.459338e+09 3.957625e+09 4.102319e+09 3.688976e+09 3.449926e+09\n46  8.559300e+01 8.597600e+01 8.629200e+01 8.661100e+01 8.668400e+01\n47  8.150100e+01 8.167600e+01 8.184600e+01 8.203700e+01 8.213800e+01\n48  8.337400e+01 8.363200e+01 8.385500e+01 8.410000e+01 8.419700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.958500e+04 8.187700e+04 8.349500e+04 8.388800e+04 8.070600e+04\n56  5.238103e+10 6.526642e+10 8.853867e+10 7.030720e+10 8.379947e+10\n57  5.481100e+01 5.604100e+01 5.716200e+01 5.812900e+01 5.922100e+01\n58  5.110700e+01 5.234500e+01 5.338600e+01 5.430800e+01 5.525300e+01\n59  5.296500e+01 5.420000e+01 5.528100e+01 5.622500e+01 5.724200e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  2.001528e+07 2.077856e+07 2.157866e+07 2.241477e+07 2.329482e+07\n67  1.303548e+09 1.487300e+09 1.557541e+09 1.386444e+09 1.298256e+09\n68  7.857500e+01 7.881700e+01 7.916500e+01 7.950900e+01 7.987900e+01\n69  7.225400e+01 7.243200e+01 7.277800e+01 7.304900e+01 7.330500e+01\n70  7.550600e+01 7.572000e+01 7.607500e+01 7.638600e+01 7.670100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.060400e+04 8.170400e+04 8.291200e+04 8.417300e+04 8.532000e+04\n78  2.325573e+11 2.875305e+11 3.615580e+11 3.329765e+11 4.236274e+11\n79  7.843700e+01 7.792500e+01 7.857700e+01 7.859300e+01 7.873200e+01\n80  7.202100e+01 7.157400e+01 7.219200e+01 7.244900e+01 7.254200e+01\n81  7.527900e+01 7.478300e+01 7.542800e+01 7.557700e+01 7.568000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.962212e+07 4.001676e+07 4.042415e+07 4.085483e+07 4.128869e+07\n89  6.384452e+09 9.206301e+09 1.166204e+10 8.647937e+09 9.260286e+09\n90  7.600000e+01 7.610000e+01 7.630000e+01 7.630000e+01 7.640000e+01\n91  6.980000e+01 6.980000e+01 7.000000e+01 7.000000e+01 7.010000e+01\n92  7.282439e+01 7.287317e+01 7.307317e+01 7.307317e+01 7.317317e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.127100e+06 3.107400e+06 3.087100e+06 3.066000e+06 3.044800e+06\n100 2.469783e+09 2.677641e+09 2.843025e+09 2.553793e+09 2.453597e+09\n            2011         2012         2013         2014         2015\n1   1.780510e+10 1.990733e+10 2.014642e+10 2.049713e+10 1.913422e+10\n2   6.285200e+01 6.334400e+01 6.381400e+01 6.400900e+01 6.417800e+01\n3   5.962500e+01 6.009900e+01 6.053400e+01 6.049500e+01 6.036300e+01\n4   6.125000e+01 6.173500e+01 6.218800e+01 6.226000e+01 6.227000e+01\n5   1.700000e+01           NA           NA           NA 1.708624e+01\n6   4.500000e+01           NA           NA           NA 5.021210e+01\n7   3.100000e+01           NA           NA           NA 3.375384e+01\n8   3.200000e+01           NA           NA           NA 2.548416e+01\n9   6.200000e+01           NA           NA           NA 5.773505e+01\n10  4.700000e+01           NA           NA           NA 3.582084e+01\n11  2.934771e+07 3.056003e+07 3.162270e+07 3.279252e+07 3.383176e+07\n12  1.289076e+10 1.231983e+10 1.277622e+10 1.322815e+10 1.138685e+10\n13  8.091600e+01 8.058900e+01 8.038700e+01 8.026700e+01 8.045100e+01\n14  7.579200e+01 7.566000e+01 7.566600e+01 7.583000e+01 7.628100e+01\n15  7.830300e+01 7.808400e+01 7.799500e+01 7.802900e+01 7.835800e+01\n16  9.600000e+01 9.600000e+01           NA           NA           NA\n17  9.800000e+01 9.800000e+01           NA           NA           NA\n18  9.700000e+01 9.700000e+01           NA           NA           NA\n19  9.900000e+01 9.900000e+01           NA           NA           NA\n20  9.900000e+01 9.900000e+01           NA           NA           NA\n21  9.900000e+01 9.900000e+01           NA           NA           NA\n22  2.905195e+06 2.900401e+06 2.895092e+06 2.889104e+06 2.880703e+06\n23  2.183319e+11 2.271437e+11 2.297014e+11 2.389427e+11 1.874939e+11\n24  7.554700e+01 7.576900e+01 7.598600e+01 7.618300e+01 7.637700e+01\n25  7.326600e+01 7.349300e+01 7.368000e+01 7.385000e+01 7.399200e+01\n26  7.438300e+01 7.460900e+01 7.480900e+01 7.499200e+01 7.515900e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  3.690338e+07 3.764617e+07 3.841417e+07 3.920503e+07 4.001953e+07\n34  5.700000e+08 6.400000e+08 6.380000e+08 6.430000e+08 6.730000e+08\n35  7.528600e+01 7.537200e+01 7.541800e+01 7.529600e+01 7.526800e+01\n36  7.029600e+01 7.030900e+01 7.037900e+01 7.033000e+01 7.029400e+01\n37  7.266200e+01 7.270900e+01 7.276900e+01 7.268700e+01 7.265400e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.489500e+04 5.448900e+04 5.400600e+04 5.346600e+04 5.287800e+04\n45  3.629134e+09 3.188653e+09 3.193513e+09 3.271686e+09 2.789881e+09\n46  8.669200e+01 8.666900e+01 8.665200e+01 8.662600e+01 8.658400e+01\n47  8.218800e+01 8.227100e+01 8.236100e+01 8.249300e+01 8.258100e+01\n48  8.429600e+01 8.433400e+01 8.440600e+01 8.448500e+01 8.453200e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.778300e+04 7.683400e+04 7.519400e+04 7.373700e+04 7.217400e+04\n56  1.117897e+11 1.280529e+11 1.323391e+11 1.359668e+11 9.049642e+10\n57  6.021000e+01 6.115700e+01 6.200900e+01 6.272800e+01 6.341200e+01\n58  5.597600e+01 5.667700e+01 5.740400e+01 5.806800e+01 5.868000e+01\n59  5.809300e+01 5.891600e+01 5.970500e+01 6.039600e+01 6.104200e+01\n60            NA           NA           NA 5.300000e+01 5.192598e+01\n61            NA           NA           NA 8.000000e+01 8.377277e+01\n62            NA           NA           NA 6.600000e+01 6.623586e+01\n63            NA           NA           NA 7.100000e+01 6.742760e+01\n64            NA           NA           NA 8.500000e+01 8.396919e+01\n65            NA           NA           NA 7.700000e+01 7.566081e+01\n66  2.421835e+07 2.517739e+07 2.616562e+07 2.716077e+07 2.815780e+07\n67  1.281337e+09 1.327107e+09 1.325426e+09 1.378830e+09 1.437756e+09\n68  8.023400e+01 8.037900e+01 8.032500e+01 8.013800e+01 7.997300e+01\n69  7.357900e+01 7.358800e+01 7.353700e+01 7.343800e+01 7.353600e+01\n70  7.702300e+01 7.710000e+01 7.705000e+01 7.691200e+01 7.689200e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.633200e+04 8.726000e+04 8.806400e+04 8.876500e+04 8.940900e+04\n78  5.301581e+11 5.459824e+11 5.520251e+11 5.263197e+11 5.947493e+11\n79  7.940200e+01 7.867200e+01 7.862300e+01 7.915000e+01 7.979500e+01\n80  7.273900e+01 7.285100e+01 7.296300e+01 7.330300e+01 7.336700e+01\n81  7.610000e+01 7.580200e+01 7.582900e+01 7.626800e+01 7.660000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  4.173066e+07 4.216172e+07 4.258246e+07 4.302407e+07 4.347701e+07\n89  1.014211e+10 1.061932e+10 1.112146e+10 1.160951e+10 1.055334e+10\n90  7.730000e+01 7.750000e+01 7.790000e+01 7.810000e+01 7.820000e+01\n91  7.050000e+01 7.090000e+01 7.150000e+01 7.180000e+01 7.170000e+01\n92  7.381707e+01 7.411951e+01 7.462195e+01 7.487317e+01 7.487073e+01\n93  1.000000e+02           NA           NA           NA           NA\n94  1.000000e+02           NA           NA           NA           NA\n95  1.000000e+02           NA           NA           NA           NA\n96  1.000000e+02           NA           NA           NA           NA\n97  1.000000e+02           NA           NA           NA           NA\n98  1.000000e+02           NA           NA           NA           NA\n99  3.027900e+06 3.024100e+06 3.022000e+06 3.013800e+06 3.004600e+06\n100 2.637859e+09 2.615208e+09 2.727850e+09 2.790850e+09 2.962907e+09\n            2016         2017         2018         2019         2020\n1   1.811657e+10 1.875346e+10 1.805322e+10 1.879944e+10 1.995593e+10\n2   6.464000e+01 6.560600e+01 6.594200e+01 6.614400e+01 6.465600e+01\n3   6.066100e+01 5.938800e+01 5.917500e+01 5.991000e+01 5.845500e+01\n4   6.264600e+01 6.240600e+01 6.244300e+01 6.294100e+01 6.145400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  3.470061e+07 3.568894e+07 3.674304e+07 3.785612e+07 3.906898e+07\n12  1.186120e+10 1.301973e+10 1.537951e+10 1.558511e+10 1.524146e+10\n13  8.062500e+01 8.079500e+01 8.100100e+01 8.106000e+01 8.034500e+01\n14  7.666200e+01 7.699700e+01 7.744800e+01 7.783400e+01 7.542900e+01\n15  7.864300e+01 7.890000e+01 7.923800e+01 7.946700e+01 7.782400e+01\n16            NA 9.904904e+01           NA           NA           NA\n17            NA 9.857200e+01           NA           NA           NA\n18            NA 9.881623e+01           NA           NA           NA\n19            NA 9.952556e+01           NA           NA           NA\n20            NA 9.858999e+01           NA           NA           NA\n21            NA 9.902406e+01           NA           NA           NA\n22  2.876101e+06 2.873457e+06 2.866376e+06 2.854191e+06 2.837849e+06\n23  1.807638e+11 1.898809e+11 1.945545e+11 1.934597e+11 1.648734e+11\n24  7.657000e+01 7.675000e+01 7.692800e+01 7.709100e+01 7.494300e+01\n25  7.410600e+01 7.417700e+01 7.425500e+01 7.435000e+01 7.173300e+01\n26  7.531000e+01 7.543100e+01 7.555500e+01 7.568200e+01 7.325700e+01\n27            NA           NA 7.532297e+01 7.421020e+01           NA\n28            NA           NA 8.742296e+01           NA           NA\n29            NA           NA 8.140784e+01           NA           NA\n30            NA           NA 9.725216e+01 9.798970e+01           NA\n31            NA           NA 9.759406e+01 6.479000e+01           NA\n32            NA           NA 9.742652e+01 7.403000e+01           NA\n33  4.085072e+07 4.168930e+07 4.250504e+07 4.329455e+07 4.404209e+07\n34  6.710000e+08 6.120000e+08 6.390000e+08 6.470000e+08 7.210000e+08\n35  7.530500e+01 7.558800e+01 7.568700e+01 7.572300e+01 7.568200e+01\n36  7.024000e+01 7.030400e+01 7.021100e+01 7.010500e+01 6.999500e+01\n37  7.264000e+01 7.280100e+01 7.279400e+01 7.275100e+01 7.267200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.224500e+04 5.158600e+04 5.090800e+04 5.020900e+04 4.976100e+04\n45  2.896610e+09 3.000162e+09 3.218420e+09 3.155149e+09 2.891001e+09\n46  8.646800e+01 8.632200e+01 8.619600e+01 8.610100e+01 8.384000e+01\n47  8.256900e+01 8.246200e+01 8.235900e+01 8.218300e+01 7.582300e+01\n48  8.448900e+01 8.435900e+01 8.424200e+01 8.409800e+01 7.941800e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.218100e+04 7.376300e+04 7.516200e+04 7.647400e+04 7.738000e+04\n56  5.276162e+10 7.369015e+10 7.945069e+10 7.089796e+10 4.850156e+10\n57  6.400900e+01 6.452700e+01 6.505700e+01 6.550600e+01 6.577400e+01\n58  5.923700e+01 5.972700e+01 6.019900e+01 6.060900e+01 6.050900e+01\n59  6.161900e+01 6.212200e+01 6.262200e+01 6.305100e+01 6.311600e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  2.918307e+07 3.023484e+07 3.129716e+07 3.237563e+07 3.345113e+07\n67  1.489693e+09 1.531152e+09 1.661530e+09 1.725352e+09 1.410796e+09\n68  7.992300e+01 7.988000e+01 7.988700e+01 7.984400e+01 7.981300e+01\n69  7.371100e+01 7.385900e+01 7.404000e+01 7.414300e+01 7.415700e+01\n70  7.696800e+01 7.703000e+01 7.713200e+01 7.716800e+01 7.716100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.996900e+04 9.046800e+04 9.092600e+04 9.136400e+04 9.184600e+04\n78  5.575323e+11 6.436284e+11 5.248199e+11 4.477547e+11 3.857405e+11\n79  7.913100e+01 7.920400e+01 7.950500e+01 7.943900e+01 7.878300e+01\n80  7.304400e+01 7.379100e+01 7.395100e+01 7.416300e+01 7.298100e+01\n81  7.610500e+01 7.654300e+01 7.677000e+01 7.684700e+01 7.587800e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  4.390031e+07 4.428889e+07 4.465488e+07 4.497346e+07 4.519196e+07\n89  1.054614e+10 1.152746e+10 1.245794e+10 1.361929e+10 1.264170e+10\n90  7.830000e+01 7.870000e+01 7.900000e+01 7.950000e+01 7.860000e+01\n91  7.160000e+01 7.190000e+01 7.240000e+01 7.310000e+01 6.840000e+01\n92  7.486829e+01 7.521707e+01 7.561951e+01 7.622195e+01 7.337561e+01\n93  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n94  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n95  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n96  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n97  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n98  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n99  2.992300e+06 2.979400e+06 2.969000e+06 2.962500e+06 2.961500e+06\n100 2.983635e+09 3.092429e+09 3.276184e+09 3.395799e+09 2.481857e+09\n            2021         2022         2023 2024\n1   1.426000e+10 1.449724e+10 1.723305e+10   NA\n2   6.407900e+01 6.723600e+01 6.753600e+01   NA\n3   5.705200e+01 6.394100e+01 6.446700e+01   NA\n4   6.041700e+01 6.561700e+01 6.603500e+01   NA\n5   2.300000e+01 2.659656e+01           NA   NA\n6   5.200000e+01           NA           NA   NA\n7   3.700000e+01           NA           NA   NA\n8   4.200000e+01 4.417171e+01           NA   NA\n9   7.100000e+01 8.340000e+01           NA   NA\n10  5.600000e+01 6.266000e+01           NA   NA\n11  4.000041e+07 4.057884e+07 4.145476e+07   NA\n12  1.803201e+10 1.901724e+10 2.354718e+10   NA\n13  7.900200e+01 8.078100e+01 8.144600e+01   NA\n14  7.474200e+01 7.675100e+01 7.772800e+01   NA\n15  7.684400e+01 7.876900e+01 7.960200e+01   NA\n16            NA 9.830000e+01           NA   NA\n17            NA 9.870000e+01           NA   NA\n18            NA 9.850000e+01           NA   NA\n19            NA 9.990000e+01           NA   NA\n20            NA 9.910000e+01           NA   NA\n21            NA 9.950000e+01           NA   NA\n22  2.811666e+06 2.777689e+06 2.745972e+06   NA\n23  1.862312e+11 2.256385e+11 2.476262e+11   NA\n24  7.665000e+01 7.759200e+01 7.769600e+01   NA\n25  7.384500e+01 7.474000e+01 7.489500e+01   NA\n26  7.520800e+01 7.612900e+01 7.626100e+01   NA\n27            NA           NA           NA   NA\n28            NA           NA           NA   NA\n29            NA           NA           NA   NA\n30            NA           NA           NA   NA\n31            NA           NA           NA   NA\n32            NA           NA           NA   NA\n33  4.476110e+07 4.547739e+07 4.616422e+07   NA\n34  7.500000e+08 8.710000e+08           NA   NA\n35  7.573000e+01 7.579400e+01 7.583800e+01   NA\n36  7.002300e+01 7.005500e+01 7.020200e+01   NA\n37  7.270800e+01 7.275200e+01 7.285200e+01   NA\n38            NA           NA           NA   NA\n39            NA           NA           NA   NA\n40            NA           NA           NA   NA\n41            NA           NA           NA   NA\n42            NA           NA           NA   NA\n43            NA           NA           NA   NA\n44  4.922500e+04 4.834200e+04 4.752100e+04   NA\n45  3.324648e+09 3.380613e+09 3.785067e+09   NA\n46  8.467800e+01 8.607500e+01 8.610700e+01   NA\n47  8.021600e+01 8.208300e+01 8.210000e+01   NA\n48  8.233100e+01 8.401600e+01 8.404100e+01   NA\n49            NA           NA           NA   NA\n50            NA           NA           NA   NA\n51            NA           NA           NA   NA\n52            NA           NA           NA   NA\n53            NA           NA           NA   NA\n54            NA           NA           NA   NA\n55  7.836400e+04 7.970500e+04 8.085600e+04   NA\n56  6.650513e+10 1.043997e+11 8.482465e+10   NA\n57  6.544100e+01 6.675300e+01 6.714400e+01   NA\n58  6.049800e+01 6.174800e+01 6.209900e+01   NA\n59  6.295800e+01 6.424600e+01 6.461700e+01   NA\n60            NA 6.250000e+01           NA   NA\n61            NA 8.280000e+01           NA   NA\n62            NA 7.240000e+01           NA   NA\n63            NA 8.070000e+01           NA   NA\n64            NA 8.590000e+01           NA   NA\n65            NA 8.330000e+01           NA   NA\n66  3.453243e+07 3.563503e+07 3.674991e+07   NA\n67  1.601367e+09 1.867733e+09 2.033085e+09   NA\n68  7.975700e+01 8.015400e+01 8.029400e+01   NA\n69  7.429500e+01 7.446100e+01 7.454900e+01   NA\n70  7.719700e+01 7.748300e+01 7.759800e+01   NA\n71            NA           NA           NA   NA\n72            NA           NA           NA   NA\n73            NA           NA           NA   NA\n74            NA           NA           NA   NA\n75            NA           NA           NA   NA\n76            NA           NA           NA   NA\n77  9.234900e+04 9.284000e+04 9.331600e+04   NA\n78  4.865641e+11 6.327901e+11 6.460753e+11   NA\n79  7.686000e+01 7.831800e+01 7.987500e+01   NA\n80  7.111300e+01 7.324900e+01 7.480500e+01   NA\n81  7.394800e+01 7.580600e+01 7.739500e+01   NA\n82            NA           NA           NA   NA\n83            NA           NA           NA   NA\n84            NA           NA           NA   NA\n85            NA           NA           NA   NA\n86            NA           NA           NA   NA\n87            NA           NA           NA   NA\n88  4.531228e+07 4.540790e+07 4.553840e+07   NA\n89  1.387891e+10 1.951351e+10 2.408575e+10   NA\n90  7.740000e+01 7.830000e+01 8.100000e+01   NA\n91  6.740000e+01 7.140000e+01 7.410000e+01   NA\n92  7.227805e+01 7.476585e+01 7.746585e+01   NA\n93            NA           NA           NA   NA\n94            NA           NA           NA   NA\n95            NA           NA           NA   NA\n96            NA           NA           NA   NA\n97            NA           NA           NA   NA\n98            NA           NA           NA   NA\n99  2.962300e+06 2.969200e+06 2.990900e+06   NA\n100 2.929447e+09 3.279344e+09 3.648573e+09   NA"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-2",
    "href": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-2",
    "title": "Data Visualization",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nHow do the GDPs of countries vary as a function of average life expectancy at birth?\nDoes the nature of this relationship change across continents?"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-3",
    "href": "DSCol-F25/DataVis/DataVis.html#world-bank-dataset-3",
    "title": "Data Visualization",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nHow do the GDPs of countries vary as a function of average life expectancy at birth?\nDoes the nature of this relationship change across continents?"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#data-visualizations",
    "href": "DSCol-F25/DataVis/DataVis.html#data-visualizations",
    "title": "Data Visualization",
    "section": " Data Visualizations",
    "text": "Data Visualizations\nOverview\n\nNotice how, with just a single well-crafted visualization, we were able to answer our initial questions with ease!\nThis illustrates one of the major reasons why visualizations are so important: they can succinctly summarize data, and highlight important patterns that would be otherwise very difficult (or impossible) to see.\nMy goal in this workshop is to help you craft presentation-quality graphics, which are highly curated for maximal impact.\n\nContrast these with exploratory visualizations, which are more “quantity over quality”."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#data-visualizations-1",
    "href": "DSCol-F25/DataVis/DataVis.html#data-visualizations-1",
    "title": "Data Visualization",
    "section": " Data Visualizations",
    "text": "Data Visualizations\nBasic Building Blocks\n\n\nUnivariate Categorical Data:\n\nBargraphs (aka barplots)\n\nUnivariate Numerical Data:\n\nHistograms\nBoxplots\n\nBivariate Numerical Data:\n\nScatterplot"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#data-visualizations-2",
    "href": "DSCol-F25/DataVis/DataVis.html#data-visualizations-2",
    "title": "Data Visualization",
    "section": " Data Visualizations",
    "text": "Data Visualizations\nScatterplots"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#scatterplot",
    "href": "DSCol-F25/DataVis/DataVis.html#scatterplot",
    "title": "Data Visualization",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends\n\nWhen considering scatterplots, certain patterns may become apparent.\n\nFor example, notice that, on average, as commute distance increases, so does commute time.\n\nSuch patterns are called trends.\nMost trends can be classified along two axes: positive/negative, and linear/nonlinear.\nA positive trend is observed when as x increases so does y; a negative trend is observed when as x increases y decreases.\nA trend whose rate of change is constant is said to be linear; a trend whose rate of change is nonconstant is said to be nonlinear"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#scatterplot-1",
    "href": "DSCol-F25/DataVis/DataVis.html#scatterplot-1",
    "title": "Data Visualization",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#scatterplot-2",
    "href": "DSCol-F25/DataVis/DataVis.html#scatterplot-2",
    "title": "Data Visualization",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends\n\n\nAnother way to describe the findings of a scatterplot is in terms of the association between the variables being compared.\n\nFor instance, if the scatterplot of y vs. x displays a positive linear trend, we would say that x and y have a positive linear association, or that x and y are positively linearly associated."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#penguins",
    "href": "DSCol-F25/DataVis/DataVis.html#penguins",
    "title": "Data Visualization",
    "section": " Penguins",
    "text": "Penguins\nAn Example\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\nThe penguins dataset, from the palmerpenguins package, contains information on 344 penguins, collected by Dr. Kristen Gorman, at the Palmer Research Station in Antarctica.\nThree species of penguins were observed: Adélie, Chinstrap, and Gentoo\n\n\n\n\n\nVarious characteristics of each penguin were also observed, including: flipper length, bill length, bill depth, sex, and island.\nIt seems plausible that a penguin’s bill length should be related to its body mass.\n\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#penguins-1",
    "href": "DSCol-F25/DataVis/DataVis.html#penguins-1",
    "title": "Data Visualization",
    "section": " Penguins",
    "text": "Penguins\nAn Example\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs there a trend?\n\nIncreasing or decreasing?\nLinear or nonlinear?\n\nDo heavier penguins tend to have longer bills?\n\n\n\n\n\n\n\n\n\nQuestion\n\n\nDoes our answer change depending on the penguins’ species?\n\n\n\n\n\nThat is, do different species exhibit different relationships between body mass and bill length?"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#penguins-2",
    "href": "DSCol-F25/DataVis/DataVis.html#penguins-2",
    "title": "Data Visualization",
    "section": " Penguins",
    "text": "Penguins\nTwo Ideas:\n\n\n\nFirst Idea: Color each point according to the associated species:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Idea: Use different shapes for different species:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey takeaway: we can encode information from additional variables by modifying certain attributes about the objects on our plots."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#penguins-3",
    "href": "DSCol-F25/DataVis/DataVis.html#penguins-3",
    "title": "Data Visualization",
    "section": " Penguins",
    "text": "Penguins\nExample"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics",
    "href": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics",
    "title": "Data Visualization",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nIntroduction\n\nThough we can make graphs “by hand” (with pen and paper), how can we tell a computer to make a graph?\n\nTo answer this question, we need to establish a framework with which we can decompose a plot into its constituent parts.\n\nSeveral such frameworks exist; one of the most popular is the Grammar of Graphics\n\nFirst proposed by Leland Wilkinson in 1999, and then modified by Hadley Wickham in the 2000s\n\nWe start with data (often in tidy format)."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-1",
    "href": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-1",
    "title": "Data Visualization",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nIntroduction\n\nThen, we need to specify axes / a coordinate system\n\nWhat variable goes on the x-axis? What about the y-axis? Should we include a radial axis? Should we make a map?\n\nFinally, we need geometric objects (shortened to geoms)\n\nDo we need bars or points? Lines or sectors? Etc.\n\nAesthetics are additional attributes of the geoms, to which variables can be mapped (e.g. coordinates of points, heights of bars, etc.)\n\nBe careful to distinguish the aesthetics from the aesthetic mappings - the latter is what maps the data to the former."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-2",
    "href": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-2",
    "title": "Data Visualization",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nSome Common Aesthetics"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-3",
    "href": "DSCol-F25/DataVis/DataVis.html#the-grammar-of-graphics-3",
    "title": "Data Visualization",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nExample: Basic Scatterplot"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#mtcars",
    "href": "DSCol-F25/DataVis/DataVis.html#mtcars",
    "title": "Data Visualization",
    "section": " mtcars",
    "text": "mtcars\nCheck Your Understanding\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many variables are being compared?\nWhat aesthetic is each mapped to?\nWhat conclusions can we draw from the plot?"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#extensions",
    "href": "DSCol-F25/DataVis/DataVis.html#extensions",
    "title": "Data Visualization",
    "section": " Extensions",
    "text": "Extensions\nLots of Other Types of Plots Too!"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility",
    "href": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility",
    "title": "Data Visualization",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility\n\nEspecially when it comes to presentation-oriented graphics, accessibility is key.\nOne thing to keep in mind that many readers may suffer from Color-Vision Deficiency (CVD; aka colorblindness), and may not be able to easily perceive differences in colors.\n\nDeuteranomaly: difficulty perceiving green\nProtanomaly: difficulty perceiving red\nTritanomaly: difficulty perceiving blue\n\n\n\n\n\n\n\n\n\nTrichromatic persons (i.e. people with no colorblindness) possess all three retinal cone cell types (and have cone cell types that function “as expected”, and are therefore able to process and perceive red, green, and blue light\n\nImage Source: https://www.aao.org/eye-health/anatomy/cones"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-1",
    "href": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-1",
    "title": "Data Visualization",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-2",
    "href": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-2",
    "title": "Data Visualization",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-3",
    "href": "DSCol-F25/DataVis/DataVis.html#cvd-and-accessibility-3",
    "title": "Data Visualization",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility\nThe Okabe-Ito Palette\n\n\n\npalette.colors(palette = \"Okabe-Ito\")\n\n[1] \"#000000\" \"#E69F00\" \"#56B4E9\" \"#009E73\" \"#F0E442\" \"#0072B2\" \"#D55E00\"\n[8] \"#CC79A7\" \"#999999\"\n\n\n\n\nAnother resource: https://www.color-blindness.com/coblis-color-blindness-simulator/"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-python-1",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-python-1",
    "title": "Data Visualization",
    "section": " Plotting in Python",
    "text": "Plotting in Python\nAn Overview\n\nThere are many modules available in Python to generate plots.\n\nSome popular ones include: matplotlib and seaborn.\nBoth are pretty good… but I prefer a different one!\n\nFor this workshop, we’ll be using Altair.\n\nI particularly like Altair because it is built upon the grammar of graphics, making it (in my opinion) fairly intuitive to use.\n\nSidebar: most data scientists agree that R (specifically, a library called ggplot2) is the best for creating graphics/visualizations.\n\nBut, Altair is a pretty good dupe for ggplot2!"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair",
    "title": "Data Visualization",
    "section": " Plotting in Altair",
    "text": "Plotting in Altair\nExample: Basic Scatterplot"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-1",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-1",
    "title": "Data Visualization",
    "section": " Plotting in Altair",
    "text": "Plotting in Altair\nExample: Simple Dataset\n\n\nCode\ndf = pd.DataFrame({\n    'col1': [1, 2, 3, 4],\n    'col2': [2, 3, 1, 1]\n})\n\nalt.Chart(\n    df,\n    title = \"My First Scatterplot\"\n).mark_point().encode(\n    x = 'col1',\n    y = 'col2'\n)"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-2",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-2",
    "title": "Data Visualization",
    "section": " Plotting in Altair",
    "text": "Plotting in Altair\nExample: Simple Dataset, with Formatting\n\n\nCode\nalt.Chart(\n    df,\n    title = \"My Second Scatterplot\"\n).mark_point(\n    filled = True,\n    size = 200,\n    color='blue'\n).encode(\n    x = alt.X('col1', axis=alt.Axis(tickCount=6)),\n    y = alt.Y('col2', axis=alt.Axis(tickCount=6))\n).properties(\n    width = 600,\n    height = 400\n).configure_title(\n    fontSize = 24\n).configure_axis(\n    labelFontSize = 14,\n    titleFontSize = 16\n)"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-3",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-3",
    "title": "Data Visualization",
    "section": " Plotting in Altair",
    "text": "Plotting in Altair\nExample: Static Function\n\n\nCode\ndef f(x):\n  \"\"\"a trigonometric function\"\"\"\n  return np.cos(x) * np.sin(2*x) + 0.3 * x\n\nx = np.linspace(-2, 3, 200)\ndf2 = pd.DataFrame({\n  'x': x,\n  'f(x)': f(x)\n})\n\nalt.Chart(\n    df2,\n    title = \"Graph of f(x) = cos(x)*sin(2x) + 0.3x\"\n).mark_line(strokeWidth = 4.5).encode(\n    x = alt.X('x', axis=alt.Axis(tickCount=6)),\n    y = alt.Y('f(x)', axis=alt.Axis(tickCount=6))\n).properties(\n    width = 600,\n    height = 400\n).configure_title(\n    fontSize = 24\n).configure_axis(\n    labelFontSize = 14,\n    titleFontSize = 16\n)"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-4",
    "href": "DSCol-F25/DataVis/DataVis.html#plotting-in-altair-4",
    "title": "Data Visualization",
    "section": " Plotting in Altair",
    "text": "Plotting in Altair\nExample: Multiple Encodings\n\n\nCode\nnp.random.seed(100)\nnum1 = sps.norm.rvs(loc = 0, size = 300)\ncat1 = np.random.choice(['A', 'B'], size = 300, p = [0.5, 0.5])\nnum2 = []\nfor k in np.arange(300):\n  num2.append(sps.norm.rvs(loc = 0.5*num1[k] if cat1[k] == 'A' else 1.5*num1[k], scale = 0.5, size = 1)[0])\n\nnum3 = []\nfor k in np.arange(300):\n  if num1[k] &lt;= -2:\n    num3.append(np.random.choice([1, 2, 3, 4, 5], size = 1, p = [0.6, 0.1, 0.1, 0.1, 0.1])[0])\n  elif -2 &lt; num1[k] &lt;= -1:\n    num3.append(np.random.choice([1, 2, 3, 4, 5], size = 1, p = [0.1, 0.6, 0.1, 0.1, 0.1])[0])\n  elif -1 &lt; num1[k] &lt;= 0:\n    num3.append(np.random.choice([1, 2, 3, 4, 5], size = 1, p = [0.1, 0.1, 0.6, 0.1, 0.1])[0])\n  elif 0 &lt; num1[k] &lt;= 1:\n    num3.append(np.random.choice([1, 2, 3, 4, 5], size = 1, p = [0.1, 0.1, 0.1, 0.6, 0.1])[0])\n  else:\n    num3.append(np.random.choice([1, 2, 3, 4, 5], size = 1, p = [0.1, 0.1, 0.1, 0.1, 0.6])[0])\n\ndf3 = pd.DataFrame({\n  'num1': num1,\n  'num2': num2,\n  'num3': num3,\n  'cat1': cat1\n})\n\nalt.Chart(\n    df3,\n    title = \"Scatterplot with Multiple Encodings\"\n).mark_point(\n    filled = True\n).encode(\n    x = alt.X('num1', axis=alt.Axis(tickCount=6)),\n    y = alt.Y('num2', axis=alt.Axis(tickCount=6)),\n    color = 'cat1',\n    size = 'num3'\n).properties(\n    width = 600,\n    height = 400\n).configure_title(\n    fontSize = 24\n).configure_axis(\n    labelFontSize = 14,\n    titleFontSize = 16\n).configure_legend(\n    labelFontSize = 14,\n    titleFontSize = 16,\n    padding = 20,\n)"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualization",
    "href": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualization",
    "title": "Data Visualization",
    "section": " Principles of Good Visualization",
    "text": "Principles of Good Visualization\nSetting Goals\n\nWhen setting out to make a plot, it’s important to be intentional about our goals.\nThere are two main types of plots: exploratory, and presentation-quality.\n\n\n\nExploratoryPresentation-Quality\n\n\n\nSummarize trends/patterns before performing more sophisticated statistical analyses\nDetails not too important; quantity over quality\n\n\n\n\nHighly curated for maximal impact and understandability\nCurate for communication; quality over quantity"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualizations",
    "href": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualizations",
    "title": "Data Visualization",
    "section": " Principles of Good Visualizations",
    "text": "Principles of Good Visualizations\nTips and Tricks\nHere are some tips I’ve found useful when crafting visualizations\n\n\n\nKeep things simple. You can (and in many cases should) try to communicate as much information as is effective. But, don’t take it to an extreme.\n\n\n\n\n\n3D-Styling is almost NEVER effective. As neat and “cool” as 3D barplots might be, the 3D-styling elements often obfuscate the plot’s true meaning\n\n\n\n\n\nBeware of Scales and Areas. We;ll talk about this one more in a bit - spoiler alert, pie charts are a notoriously bad graphic!"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualizations-1",
    "href": "DSCol-F25/DataVis/DataVis.html#principles-of-good-visualizations-1",
    "title": "Data Visualization",
    "section": " Principles of Good Visualizations",
    "text": "Principles of Good Visualizations\nTips and Tricks\n\n\n\nLabel Axes, and Title your Plots. This one should (hopefully) be self-explanatory, but make sure you are using descriptive (but not overly complex) labels for your axes, and make sure your plots are titled.\n\n\n\n\nInterpret your plots. All too often I see “floating” plots - that is, figures that appear mysteriously and suddenly with no explanation whatsoever. No matter how self-explanatory you think your plot is, make sure you actively describe it and its conclusions somewhere in your report.\n\n\n\n\n\n\nThere’s a bit more I’d like to say on the use of color as well."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#color-scales",
    "href": "DSCol-F25/DataVis/DataVis.html#color-scales",
    "title": "Data Visualization",
    "section": " Color Scales",
    "text": "Color Scales\nThree Main Types\n\nIt is also important to make sure you are using a color scale that is appropriate for your visualization\n\nLoosely speaking, you can think of a “color scale” as a palette of colors that will appear on your plot.\n\nThere are three main types of color scales:\n\nQualitative: colors are distinct, with no natural order. Good for use with categorical variables.\nSequential: colors range from light to dark, and are used to convey a direction. Similar to what we colloquially call “gradients”\nDiverging:: two sequential scales stitched together at a neutral midpoint."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#color-scales-1",
    "href": "DSCol-F25/DataVis/DataVis.html#color-scales-1",
    "title": "Data Visualization",
    "section": " Color Scales",
    "text": "Color Scales\nThree Main Types\n\nQualitativeSequentialDiverging\n\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke\n\n\n\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke\n\n\n\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#color-scales-2",
    "href": "DSCol-F25/DataVis/DataVis.html#color-scales-2",
    "title": "Data Visualization",
    "section": " Color Scales",
    "text": "Color Scales\nExample\n\nMisuseImprovement\n\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke\n\n\n\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#facetting",
    "href": "DSCol-F25/DataVis/DataVis.html#facetting",
    "title": "Data Visualization",
    "section": " Facetting",
    "text": "Facetting\n\nColor may not always be the most effective way to convey information."
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#facetting-1",
    "href": "DSCol-F25/DataVis/DataVis.html#facetting-1",
    "title": "Data Visualization",
    "section": " Facetting",
    "text": "Facetting\n\nOne potential alternative is facetting"
  },
  {
    "objectID": "DSCol-F25/DataVis/DataVis.html#transformations",
    "href": "DSCol-F25/DataVis/DataVis.html#transformations",
    "title": "Data Visualization",
    "section": " Transformations",
    "text": "Transformations\n\nAlso note how transformations may be useful, especially when one or more of your variables has comparatively high spread.\n\n\n\n\nRaw:\n\n\n\n\n\n\n\n\n\n\n\n\nLog-Transformed:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan’s Section Material",
    "section": "",
    "text": "This is a GitHub site, designed to host material created by Ethan Marzban for his teaching duties at the University of California, Santa Barbara."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#roadmap-for-today",
    "href": "120B-F25/FinRev/FinRev.html#roadmap-for-today",
    "title": "Final Exam Review",
    "section": " Roadmap for Today",
    "text": "Roadmap for Today\n\nGo through some slides (including some interactive problems)\nWork through some problems together (on the worksheet; copies can be found at the front of the room)\n\n\n\n\n\n\n\n\nDisclaimer\n\n\nI have not seen the exam yet, so I do not know exactly what will or will not be on it. Just because something does or does not show up on these slides doesn’t mean it is guaranteed to show up / not show up on the exam.\n\n\n\n\n\n\n\n\n\n\n\nDisclaimer\n\n\nThis review is not intended to be comprehensive; I encourage you to consult the lecture notes, textbook, homework, and your own notes."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#roadmap-for-today-1",
    "href": "120B-F25/FinRev/FinRev.html#roadmap-for-today-1",
    "title": "Final Exam Review",
    "section": " Roadmap for Today",
    "text": "Roadmap for Today\n\nNow, there is far too much material for me to be able to meaningfully cover everything that I think is important for the final.\nInstead, I’ve elected to select a handful of topics which I think might be confusing (or topics I’d like to expound upon). I’ll go through these relatively quickly, though, as the best way to learn is to practice - so I’d like to leave plenty of time for us to work through some of the problems on the worksheet!\nOrder of coverage:\n\nEstimation\nCI for a Difference in Means (time permitting)\nHypothesis Testing"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#estimation-1",
    "href": "120B-F25/FinRev/FinRev.html#estimation-1",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nGeneral Framework\n\n\n\nWe have a population, governed by a set of population parameters that are unobserved (but that we’d like to make claims about).\nTo make claims about the population parameters, we take a sample.\nWe then use our sample to make inferences (i.e. claims) about the population parameters.\n\n\n\n\n\n\n\nInference can mean either estimation or hypothesis testing."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#estimation-2",
    "href": "120B-F25/FinRev/FinRev.html#estimation-2",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nTerminology\n\nIn estimation, we seek to estimate a particular population parameter.\nWe do so by taking a sample (Y1, …, Yn) from the population, and constructing an estimator: \\[ \\widehat{\\theta}_n := \\widehat{\\theta}_n(Y_1, \\cdots, Y_n) \\]\nCrucially, an estimator is a random quantity.\n\nContrast this with an estimate, which we obtain by plugging specific data into our estimator.\nE.g. we use the sample mean as an estimator for the population mean; after getting a specific set of observations, their numerical sample mean is the estimate."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#estimation-3",
    "href": "120B-F25/FinRev/FinRev.html#estimation-3",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nProperties\n\nA “good” point estimator is one that possesses one (or several) desirable properties, which we can measure in a few different ways:\n\nUnbiasedness: \\(\\E[\\widehat{\\theta}_n] = \\theta\\)\nConsistency: \\(\\widehat{\\theta}_n \\probto \\theta\\)\nMSE: \\(\\mathrm{MSE}(\\widehat{\\theta}_n) = \\mathrm{Bias}^2(\\widehat{\\theta}_n) + \\Var(\\widehat{\\theta}_n)\\)\n\nQuestion: do we want high or low MSE?\n\nMVUE: \\(\\widehat{\\theta}_n\\) is unbiased and possesses the smallest variance among all possible unbiased estimators.\n\nCheck your understanding: are all consistent estimators unbiased? Are all unbiased estimators consistent?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#consistency",
    "href": "120B-F25/FinRev/FinRev.html#consistency",
    "title": "Final Exam Review",
    "section": " Consistency",
    "text": "Consistency\nDefinition\n\n\n\n\n\n\nDefinition: Consistency\n\n\nAn estimator \\(\\widehat{\\theta}_n\\) is said to be a consistent estimator for \\(\\theta\\), denoted \\(\\widehat{\\theta}_n \\probto \\theta\\) if, for any \\(\\varepsilon &gt; 0\\), either of the following equivalent statements hold: \\[\\begin{align*}\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon \\right)  & = \\underline{\\qquad \\qquad} \\\\\n  \\lim_{n \\to \\infty} \\Prob\\left( |\\widehat{\\theta}_n - \\theta| &gt;  \\varepsilon \\right)  & = \\underline{\\qquad \\qquad}\n\\end{align*}\\]\n\n\n\n\n\\(|\\widehat{\\theta}_n - \\theta| \\leq \\varepsilon\\) means “the distance between \\(\\widehat{\\theta}_n\\) and \\(\\theta\\) is very small.” Equivalently: “\\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”\nThe definition of consistency asserts that this probability goes to zero as the sample size increases. That is: “as our sample size becomes larger, we become more certain that \\(\\widehat{\\theta}_n\\) is very close to \\(\\theta\\).”"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#consistency-1",
    "href": "120B-F25/FinRev/FinRev.html#consistency-1",
    "title": "Final Exam Review",
    "section": " Consistency",
    "text": "Consistency\nBiased but Consistent\nExample: \\(\\widehat{\\sigma^2}_n := \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\bar{Y}_n)^2\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#estimation-4",
    "href": "120B-F25/FinRev/FinRev.html#estimation-4",
    "title": "Final Exam Review",
    "section": " Estimation",
    "text": "Estimation\nConstructing Estimators\n\nSo far, we’ve primarily been concerned with assessing the performance of an estimator. Now, we turn our attention to the question of how to construct an estimator.\nThere are two main methods we use:\n\nThe Method of Moments (MoM)\nThe method of Maximum Likelihood Estimation (MLE)\n\nIntuition behind the method of moments: our sample moments should closely match the population moments (the sample average cat weight should probably be close to the true average of all cat weights).\nIntuition behind maximum likelihood estimation: a good guess for the true value of the parameter is that was most likely to have given rise to the data we observed."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#method-of-moments",
    "href": "120B-F25/FinRev/FinRev.html#method-of-moments",
    "title": "Final Exam Review",
    "section": " Method of Moments",
    "text": "Method of Moments\n\n\n\n\n\n\nMethod of Moments\n\n\n\nSet up p equations (where p is the number of parameters that are desired to be estimated) of the form \\[\\begin{align*}\n  M_1   &= \\mu_1 \\\\\n  M_2   & = \\mu_2  \\\\\n  \\vdots & \\hspace{5mm} \\vdots \\\\\n  M_p   & = \\mu_p\n\\end{align*}\\] where \\[ M_k := \\frac{1}{n} \\sum_{i=1}^{n} Y_i^k ; \\qquad \\mu_k := \\E[Y_i^k] \\] denote the kth sample moment and population moment, respectively\nSolve the equations for the p parameters; these will be the method of moments estimators for the parameters."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-2",
    "href": "120B-F25/FinRev/FinRev.html#example-2",
    "title": "Final Exam Review",
    "section": " Example 2",
    "text": "Example 2\n\n\n\n\n\n\nExample 1\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathrm{Geom}(p)\\). Derive an expression for \\(\\widehat{p}_{\\mathrm{MoM}}\\), the method of moments estimator for p.\n\n\n\n\nWe have only one parameter, so we only need to set up one equation.\nThe first population moment is given by \\(\\mu_1 := \\E[Y_i] = 1/p\\)\nHence, our method of moments estimator satisfies the equation \\[ \\overline{Y}_n = \\frac{1}{\\widehat{p}_{\\mathrm{MoM}}} \\]\nWhen solved for \\(\\widehat{p}_{\\mathrm{MoM}}\\), we obtain \\(\\boxed{\\widehat{p}_{\\mathrm{MoM}} = \\frac{1}{\\overline{Y}_n}}\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#sampling",
    "href": "120B-F25/FinRev/FinRev.html#sampling",
    "title": "Final Exam Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#leadup",
    "href": "120B-F25/FinRev/FinRev.html#leadup",
    "title": "Final Exam Review",
    "section": " Leadup",
    "text": "Leadup\n\nEach one of these samples provides some information about µ, the true average weight of all cats.\nFor example, suppose we only observed the first sample: \\[ \\vec{\\boldsymbol{y}} = (8.5, \\ 12.0, \\ 7.5, \\ 11.1, ... , \\ 8.8, 10.4) \\]\n\nFor reference, the average weight of cats in this sample is 9.11 lbs.\n\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, 8 lbs?\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, 30 lbs?\nGiven this sample, how likely do we think it is that the true average weight of all cats is, say, some arbitrary value µ?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#likelihoods",
    "href": "120B-F25/FinRev/FinRev.html#likelihoods",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\n\nThe answer to this last question is precisely the likelihood of a sample.\nMore generally, \\[ \\Lik(\\theta; Y_1, \\cdots, Y_n) \\] denotes the likelihood of the true value of the parameter being θ, given observations (Y1, …, Yn).\nMathematically, the likelihood is just the joint density function of (Y1, …, Yn); conceptually, we are now viewing it as a function of θ.\nAs a concrete example, suppose \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\) (if it helps, you can think of these at cat weights)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#likelihoods-1",
    "href": "120B-F25/FinRev/FinRev.html#likelihoods-1",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample\n\nSince our sample is stated to be i.i.d.,\n\n\\[\\begin{align*}\n  \\class{fragment}{{} \\Lik(\\theta; Y_1, \\cdots, Y_n) }\n    &\\class{fragment}{{} := f_{Y_1, \\cdots, Y_n}(y_1, \\cdots, y_n ; \\theta) }            \\\\[3px]\n    &\\class{fragment}{{}  = \\prod_{i=1}^{n} f_{Y_i}(y_i; \\theta) }    \\\\[3px]\n    &\\class{fragment}{{}  = \\prod_{i=1}^{n} \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ - \\frac{1}{2} (Y_i - \\mu)^2 \\right\\} \\right]  }    \\\\[3px]\n    &\\class{fragment}{{}  = \\left( \\frac{1}{2\\pi} \\right)^{n/2} \\cdot \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^{n} (\\mu - Y_i)^2 \\right\\}  }\n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#likelihoods-2",
    "href": "120B-F25/FinRev/FinRev.html#likelihoods-2",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#likelihoods-3",
    "href": "120B-F25/FinRev/FinRev.html#likelihoods-3",
    "title": "Final Exam Review",
    "section": " Likelihoods",
    "text": "Likelihoods\nExample"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#maximum-likelihood-estimation",
    "href": "120B-F25/FinRev/FinRev.html#maximum-likelihood-estimation",
    "title": "Final Exam Review",
    "section": " Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nConsider again the likelihood of a sample; \\(\\Lik(\\theta; Y_1, \\cdots, Y_n)\\).\nRecall that this represents how likely any specified value of θ is to be the truth, given the data (Y1, …, Yn).\nA good guess for the true value of θ, therefore, is perhaps the one that was most likely to have given rise to the data we observed.\n\nIn other words, the value that maximizes the likelihood.\n\n\n\n\n\n\n\n\n\nDefinition: Maximum Likelihood Estimator\n\n\n\\[ \\widehat{\\theta}_{\\mathrm{MLE}} := \\argmax_{\\theta} \\left\\{ \\Lik(\\theta; Y_1, \\cdots, Y_n) \\right\\} \\]\n\n\n\n\n\nSometimes it’s more convenient to work with the log-likelihood, though it is not always necessary."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-3-1",
    "href": "120B-F25/FinRev/FinRev.html#example-3-1",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\n\n\n\n\n\n\nExample 3\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\). Derive an expression for \\(\\widehat{\\mu}_{\\mathrm{MLE}}\\), the maximum likelihood estimator for µ.\n\n\n\n\nFrom before, the likelihood is \\[ \\Lik(\\mu; Y_1, \\cdots, Y_n) = \\left( \\frac{1}{2\\pi} \\right)^{n/2} \\cdot \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^{n} (\\mu - Y_i)^2 \\right\\}\\]\nThe log-likelihood and its first derivative are therefore given by \\[\\begin{align*}\n  \\class{fragment}{{} \\ell(\\mu; Y_1, \\cdots, Y_n) }\n&\\class{fragment}{{} = -\\frac{n}{2} \\ln(2\\pi) - \\frac{1}{2} \\sum_{i=1}^{n}(Y_i - \\mu)^2 }            \\\\[3px]\n\\class{fragment}{{} \\frac{\\partial}{\\partial \\mu} \\ell(\\mu; Y_1, \\cdots, Y_n) } & \\class{fragment}{{}  = \\sum_{i=1}^{n} (Y_i - \\mu) = n \\bar{Y} - n \\mu }  \n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-2-1",
    "href": "120B-F25/FinRev/FinRev.html#example-2-1",
    "title": "Final Exam Review",
    "section": " Example 2",
    "text": "Example 2\n\n\n\n\n\n\nExample 2\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\). Derive an expression for \\(\\widehat{\\mu}_{\\mathrm{MLE}}\\), the maximum likelihood estimator for µ.\n\n\n\n\nSetting this equal to zero and solving for µ reveals that a critical value of the likelihood is given by \\(\\mu = \\overline{Y}_n\\).\n\n\nThe second derivative of the log-likelihood is given by \\[\\frac{\\partial^2}{\\partial \\mu^2} \\ell(\\theta; Y_1, \\cdots, Y_n) = - n \\] which is negative everywhere; hence the critical value we found above must be a maximum.\nThus, \\(\\boxed{\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{Y}_n}\\)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#maximum-likelihood-estimation-1",
    "href": "120B-F25/FinRev/FinRev.html#maximum-likelihood-estimation-1",
    "title": "Final Exam Review",
    "section": " Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nIf the support of the population distribution depends on the parameter of interest, the likelihood will be nondifferentiable (with respect to the parameter of interest).\nIn such cases, the likelihood must be maximized by inspection - there’s an example of this on the worksheet we’ll go over later today.\n\n\n\n\n\n\n\n\nCaution\n\n\nIn cases like this (where the support depends on the parameter), do NOT forget about the indicator in the density function."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#leadup-1",
    "href": "120B-F25/FinRev/FinRev.html#leadup-1",
    "title": "Final Exam Review",
    "section": " Leadup",
    "text": "Leadup\n\nDo UCSB students have, on average, the same commute times as SBCC students?\nAssume we have two samples: \\[\\begin{align*}\n  Y_{1,1}, Y_{1,2}, \\cdots, Y_{1, n_1} & \\iid \\mathcal{N}(\\mu_1, \\ \\sigma^2) \\\\\n  Y_{2,1}, Y_{2,2}, \\cdots, Y_{2, n_2} & \\iid \\mathcal{N}(\\mu_2, \\ \\sigma^2)\n\\end{align*}\\] (note crucially that we are assuming the two population variances are equal).\n\nFor example, the Y1,i might represent UCSB commute times and the Y2,i might represent SBCC commute times.\n\nSay we want to construct a confidence interval for (µ1 - µ2 ), the difference in true average commute times."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means",
    "href": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\nBy previously-established results, \\[\\begin{align*}\n  \\bar{Y}_1 := \\frac{1}{n_1} \\sum_{i=1}^{n_1} Y_i & \\sim  \\\\\n  \\bar{Y}_2 := \\frac{1}{n_2} \\sum_{i=1}^{n_2} Y_i & \\sim\n\\end{align*}\\] which in turn implies \\[ (\\bar{Y}_1 - \\bar{Y}_2)  \\sim  \\] \\[ \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - \\qquad \\qquad \\qquad }{} \\sim \\mathcal{N}(0, 1) \\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means-1",
    "href": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means-1",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\n\nIn practice, \\(\\sigma^2\\) is often unknown so we replace it with an unbiased estimator: the pooled sample variance \\[ S_p^2 := \\left( \\frac{n_1 - 1}{n_1 + n_2 - 2} \\right) S_1^2  + \\left( \\frac{n_2 - 1}{n_1 + n_2 - 2} \\right) S_2^2 \\]\n\nIntuition: we take a weighted average of the two sample standard deviations, placing more weight on the sample with more information (i.e. a greater sample size), that is still an unbiased estimator for \\(\\sigma^2\\).\n\nReplacing \\(\\sigma^2\\) with \\(S_p := \\sqrt{S_p^2}\\) breaks the normality of our point estimator, requiring us to instead use the \\(t_{n_1 + n_2 - 2}\\) distribution."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means-2",
    "href": "120B-F25/FinRev/FinRev.html#confidence-interval-for-a-difference-in-means-2",
    "title": "Final Exam Review",
    "section": " Confidence Interval for a Difference in Means",
    "text": "Confidence Interval for a Difference in Means\n\\[ (\\bar{Y}_1 - \\bar{Y}_2) \\pm t_{n_1 + n_2 - 2, \\ \\frac{\\alpha}{2}} \\cdot S_p \\cdot \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\\]\n\nAssumptions:\n\n\nNormally-distributed population\nEqual population variances\n\n\n\n\nMake sure you understand how to interpret these intervals with respect to whether or not zero is contained in them."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#cats",
    "href": "120B-F25/FinRev/FinRev.html#cats",
    "title": "Final Exam Review",
    "section": " Cats",
    "text": "Cats\nToe Beans…\n\nAccording to a Quora post, the average cat has about a 10% chance of being born with polydactyly\n\n\n\n\n\n\n\nImage Source: https://www.treehugger.com/thing-didnt-know-polydactyl-cats-4864197\n\n\n\n\n\nPolydactyly refers to a condition whereby an animal is born with extra digits (e.g. extra fingers in humans, extra toes in cats, etc.)\nSuppose we wish to assess the validity of the Quora claim, using data.\n\nNote that we’re not necessarily trying to estimate the true incidence of polydactyly among cats!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#cats---again",
    "href": "120B-F25/FinRev/FinRev.html#cats---again",
    "title": "Final Exam Review",
    "section": " Cats - Again!",
    "text": "Cats - Again!\nToe Beans…\n\nSay we collect a simple random sample of 100 cats, and observe 9 polydactyl cats in this sample (i.e. \\(\\widehat{p}\\) = 9%).\nDoes this provide concrete evidence that the Quora claim is incorrect? Not really!\nBut, say our sample of 100 cats contains 80 polydactyl cats (\\(\\widehat{p}\\) = 80%). Or, say we saw only 1 polydactyl cat in a sample of 100 (\\(\\widehat{p}\\) = 1%).\nNow, it is possible that the Quora claim is true and we just happened to get extraordinarily lucky (or unlucky).\nBut, it’s probably more likely that we should start to question the validity of the Quora statistic."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-1",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-1",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nGeneral Framework\n\nSo where’s the cutoff - how many polydactyl cats do we need to observe in a sample of n before we start to question the Quora statistic?\nThis is the general framework of hypothesis testing.\nWe start off with a pair of competing claims, called the null hypothesis and the alternative hypothesis.\n\nThe null hypothesis is usually set to be the “status quo”. For instance, in our polydactyly example, we would set the null hypothesis (denoted H0, and read “H-naught”) to be “10% of cats are polydactyl.”\n\nFor the purposes of this class, the null hypothesis is always a statement of equality: \\(H_0: \\ \\theta = \\theta_0\\) for some null value \\(\\theta_0\\)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-2",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-2",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nGeneral Framework\n\nGiven a null \\(H_0: \\ \\theta = \\theta_0\\), three possible alternative hypotheses present themselves to us (among which we must pick one):\n\n\\(H_1: \\ \\theta &lt; \\theta_0\\) (lower-tailed)\n\\(H_1: \\ \\theta &gt; \\theta_0\\) (upper-tailed)\n\\(H_1: \\ \\theta \\neq \\theta_0\\) (two-tailed)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThere should be NO OVERLAP between the null and alternative.\n\n\n\n\n\nFor example, it is incorrect to write a lower-tailed alternative as \\(H_1: \\ \\theta \\leq \\theta_0\\). Can anyone tell me why, conceptually, this is?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#states-of-the-world",
    "href": "120B-F25/FinRev/FinRev.html#states-of-the-world",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\n\nIn a given hypothesis testing setting, the null is either true or not (though we won’t ever get to know for sure).\nIndependently, our test will either reject the null or not.\nThis leads to four states of the world:\n\n\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\n\n\n\n\n\n\nFalse\n\n\n\n\n\n\n\n\n\nSome of these states are good, others are bad. Which are which?"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#states-of-the-world-1",
    "href": "120B-F25/FinRev/FinRev.html#states-of-the-world-1",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\nBAD\n\n\nGOOD\n\n\n\n\nFalse\n\n\nGOOD\n\n\nBAD\n\n\n\n\nWe give names to the two “bad” situations: Type I and Type II errors.\n\n\n\n\n\n\n\n\nResult of Test\n\n\n\n\n\n\n\nReject\n\n\nFail to Reject\n\n\n\n\nH0\n\n\nTrue\n\n\nType I Error\n\n\nGOOD\n\n\n\n\nFalse\n\n\nGOOD\n\n\nType II Error\n\n\n\n\n\n\n\n\n\n\n\nDefinition: Type I and Type II errors\n\n\n\n\nA Type I Error occurs when we reject \\(H_0\\), when \\(H_0\\) was actually true.\nA Type II Error occurs when we fail to reject \\(H_0\\), when \\(H_0\\) was actually false."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#states-of-the-world-2",
    "href": "120B-F25/FinRev/FinRev.html#states-of-the-world-2",
    "title": "Final Exam Review",
    "section": " States of the World",
    "text": "States of the World\nLevel and Power\n\nThe level of significance (aka “significance level”; aka “level”) of a test, denoted by \\(\\alpha\\), is defined to be the probability of committing a Type I error.\nThe power of a test, often denoted \\(Q(\\theta')\\), is \\[Q(\\theta') := \\mathbb{P}(\\text{Reject $H_0$, when the true value of $\\theta$ was $\\theta'$}) \\]\nGenerally, we fix the level and try and find the test with the most power (or, equivalently, with the smallest probability of committing a Type II error).\n\nThis leads us to the notion of a Most Powerful Test of Level α (from Topic 15)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-1-1",
    "href": "120B-F25/FinRev/FinRev.html#example-1-1",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\n\n\n\n\n\n\nExample 1\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\) for some unknown µ, and suppose we wish to test H0: µ = µ0 vs HA: µ &gt; µ0 at a 0.05 level of significance. We propose two tests:\n\nTest 1: Reject H0 when \\(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)\\)\nTest 2: Reject H0 when \\(\\frac{\\overline{Y}_n - \\mu_0}{1/\\sqrt{n}} &gt; \\Phi^{-1}(0.95)\\)\n\n\nVerify that both tests have a 5% level of significance.\nDerive expressions for the power functions of both tests."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-1-3",
    "href": "120B-F25/FinRev/FinRev.html#example-1-3",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\nPart (a)\n\nLet’s focus on Test 1.\nBy definition, the level of the test is the probability of rejecting the null when the null was true.\nSaying that “the null was true” is saying that the true value of µ is µ0, in which case \\(Y_1 \\sim \\mathcal{N}(\\mu_0, 1)\\).\nHence, the probability of rejecting the null (i.e. that \\(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)\\)) if the null is true is:\n\n\n\\[\\begin{align*}\n  \\Prob_{H_0}(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)) & = 1 - \\Prob_{H_0}(Y_1 - \\mu_0 \\leq \\Phi^{-1}(0.95)) \\\\\n    & = 1 - \\Phi[\\Phi^{-1}(0.95)] = 1 - 0.95 = 0.05 \\ \\checkmark\n\\end{align*}\\]\n\n\nTry Test 2 on your own."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-1-4",
    "href": "120B-F25/FinRev/FinRev.html#example-1-4",
    "title": "Final Exam Review",
    "section": " Example 1",
    "text": "Example 1\nPart (b)\n\nWe now turn our attention to the power curves. Again, we start with Test 1.\nQ(µA) is the probability of rejecting the null when the true value of µ is in fact µA.\nSaying that “the true value of µ is in fact µA” means \\(Y_1 \\sim \\mathcal{N}(\\mu_A, 1)\\). Furthermore, we reject the null when \\(Y_1 &gt; \\Phi^{-1}(0.95)\\).\nHence,"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-3-3",
    "href": "120B-F25/FinRev/FinRev.html#example-3-3",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\nPart (b)\n\n\\[\\begin{align*}\n  Q_1(\\mu_A) & = \\Prob_{\\mu_A}(Y_1 - \\mu_0 &gt; \\Phi^{-1}(0.95)) \\\\\n  &  = \\Prob_{\\mu_A}(Y_1 - {\\color{blue} \\mu_A + \\mu_A} -  \\mu_0 &gt; \\Phi^{-1}(0.95)) \\\\\n   &  = \\Prob_{\\mu_A}({\\color{red}Y_1 - \\mu_A} &gt; \\Phi^{-1}(0.95) + (\\mu_0 - \\mu_A)) \\\\\n   &  = 1 - \\Phi[\\Phi^{-1}(0.95) + (\\mu_0 - \\mu_A)]\n\\end{align*}\\]\n\n\nFor test 2:\n\n\n\\[\\begin{align*}\n  Q_2(\\mu_A) & = \\Prob_{\\mu_A}\\left(\\frac{\\overline{Y}_n - {\\color{blue} \\mu_A + \\mu_A} - \\mu_0}{1/\\sqrt{n}} &gt; \\Phi^{-1}(0.95) \\right) \\\\\n  & = \\cdots = 1 - \\Phi\\left[\\Phi^{-1}(0.95) + \\sqrt{n}(\\mu_0 - \\mu_A) \\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#example-3-4",
    "href": "120B-F25/FinRev/FinRev.html#example-3-4",
    "title": "Final Exam Review",
    "section": " Example 3",
    "text": "Example 3\nPart (b)"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-3",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-3",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\np-Value Framework\n\nInstead of the critical value framework, we can also conduct hypothesis tests using p-values\nThe p-value is the probability of observing something as or more extreme (in the direction of the alternative) than what we actually observed.\n\n\n\n\nLower-tailed: ℙ(TS &lt; ts)\nUpper-tailed: ℙ(TS &gt; ts)\nTwo-sided: ℙ(|TS| &gt; ts)\nA picture is worth a thousand words!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-4",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-4",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nIn PSTAT 120B, we covered:\n\nLarge- and small-sample tests for the mean\nSmall-sample tests for a difference in means\nTests for the variance (assuming a normal population)\n\nMake sure that, for each, you understand:\n\nWhat assumptions are required\nHow to conduct them (in both the critical value and p-value frameworks)\n\nKeep in mind, hypothesis test questions on the final exam for PSTAT 120B are often (not always, though) word problems!"
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-5",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-5",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nI find it useful to also quickly review how these tests are derived. This can, in my opinion, help with the memorization aspect.\nFor example, suppose we are testing \\(H_0: \\mu = \\mu_0\\) against \\(H_A: \\mu \\neq \\mu_0\\) using data \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\).\n\nA natural point estimator for \\(\\mu\\) is \\(\\bar{Y}\\), which we know is normally-distributed, so a natural test statistic is its standardized form, under the null: \\(Z := (\\bar{Y} - \\mu_0)/(\\sigma / \\sqrt{n})\\).\nIf \\(\\bar{Y}\\) is far from \\(\\mu_0\\) (equivalently, that \\(Z\\) is far from zero), we have evidence that the true mean is not \\(\\mu_0\\): i.e. we have evidence against the null and in favor of the alternative.\nThis reveals a rejection region of the form \\(|Z| &gt; c\\) for some critical value \\(c\\), which can be derived by setting the level of the test to be \\(\\alpha\\)."
  },
  {
    "objectID": "120B-F25/FinRev/FinRev.html#hypothesis-testing-6",
    "href": "120B-F25/FinRev/FinRev.html#hypothesis-testing-6",
    "title": "Final Exam Review",
    "section": " Hypothesis Testing",
    "text": "Hypothesis Testing\nPSTAT 120B\n\nTake a look through 10.7 of the textbook, titled “Some Comments on the Theory of Hypothesis Testing.” The authors provide some (in my opinion) very useful and practical comments on hypothesis testing.\nAlso, even though material from Topic 15 will not feature heavily on the exam (if at all - again, I haven’t seen the exam yet!) I HIGHLY recommend you take a look at it before moving on to your future statistics courses.\n\nPretty much every course will at least in part make reference to that material, even if behind the scenes.\n\nAny time you perform a hypothesis test (e.g. in: Machine Learning, Time Series, etc.), you’re often concerned with finding a test with optimal power. The Neyman-Pearson Lemma and Likelihood Ratio Tests gives you such a test in many cases."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#announcements",
    "href": "120B-F25/Wk04/wk4.html#announcements",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Announcements",
    "text": "Announcements\n\nMidterm Review (hosted by me): Tuesday October 28, 2025 from 7:00 - 8:30 pm in BUCHN 1920\n\nThe plan is to review some material and thenwork through some new practice problems together\n\nMidterm Advice: write a note sheet (even though you don’t technically get one on the exam)!\n\nStudies show: the act of writing things down and synthesizing information is a great way to commit things to long-term memory.\n\nHomework 5: remember that it is due 5pm on Wednesday (instead of 11:59pm), and that no late submissions will be accepted for ANY reasons"
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#recap",
    "href": "120B-F25/Wk04/wk4.html#recap",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Recap",
    "text": "Recap\nFramework for Statistical Inference\n\n\n\n\n\nGoal: to make inferences about a population parameter.\nTo do so, we take random samples from the population.\nA statistic is a function of a random sample: \\(T := T(Y_1, \\cdots, Y_n)\\)\n\nStatistics, therefore, are random variables; their distributions are called sampling distributions"
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation",
    "href": "120B-F25/Wk04/wk4.html#estimation",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nGeneral Framework\n\n\n\n\n\n\nGoal\n\n\nTo estimate the true average weight of all cats in the world.\n\n\n\n\nLast week, we talked about taking samples of cats and recording their weights.\nIt seems natural that the average of our sampled cat weights should correspond, in some way, to the average of all cats in the world.\nThis is the basic idea behind estimation: we’ll use statistics (functions of our sample) to estimate the true value of a parameter.\n\nE.g. using the sample average cat weight to say something about the true population average cat weight."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-1",
    "href": "120B-F25/Wk04/wk4.html#estimation-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nGeneral Framework\n\nThree key terms:\n\nEstimand: another word for the parameter we are trying to estimate.\nEstimator: a statistic being used to estimate the estimand.\n\nAnother way to think about this: a “rule” used to estimate the parameter.\n\nEstimate: a particular realization (i.e. observed instance) of an estimator."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-2",
    "href": "120B-F25/Wk04/wk4.html#estimation-2",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nExample\n\n\n\n\n\n\nExample\n\n\nA vet wishes to estimate the true weight of all cats in the world. She takes a sample of 10 cats, and finds their average weight to be 9.12 lbs.\n\n\n\n\nThe estimand is the true average weight of all cats in the world (which we can call µ).\nThe estimator is the sample mean: we are using sample means to estimate µ.\nThe estimate in this scenario is 9.12 lbs, as this is a particular realization of our estimator."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-3",
    "href": "120B-F25/Wk04/wk4.html#estimation-3",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nDesirable Properties of Estimators\n\nThere are potentially many estimators we can use to estimate a particular parameter.\nAs such, it is necessary to establish a notion of what makes a “good” estimator (or, equivalently, what makes one estimator “better” than another).\nOne notion is unbiasedness: an estimator \\(\\widehat{\\theta}_n\\) for \\(\\theta\\) is said to be unbiased if \\(\\E[\\widehat{\\theta}_n] = \\theta\\).\n\n“On average, the estimator gets it right.”\nMathematically: means the sampling distribution is centered at the right (true) value."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-4",
    "href": "120B-F25/Wk04/wk4.html#estimation-4",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nAn Analogy\n\nUnbiasedness, however, is often not enough. To motivate why, let’s take a look at an analogy.\nAn analogy is often drawn between estimation and hitting a bullseye.\n\nThe bullseye is akin to our estimand, and estimates are represented by shots fired at the target.\nThe estimator is, therefore, akin to the marskperson.\n\nAn unbiased estimator is analogous to a marksperson for whom the average location of shots is the bullseye."
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-5",
    "href": "120B-F25/Wk04/wk4.html#estimation-5",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nTwo Markspersons\n\nWhich of the following markspersons is “better”?\n\n\n\n\n\nMarksperson 1\n\n\n\n\nMarksperson 2"
  },
  {
    "objectID": "120B-F25/Wk04/wk4.html#estimation-6",
    "href": "120B-F25/Wk04/wk4.html#estimation-6",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Estimation",
    "text": "Estimation\nTwo Markspersons\n\nSo, unbiasedness is not enough; we’d also like small variance.\nTo that end, we introduce the mean squared-error (MSE) of an estimator: \\[ \\mathrm{MSE}(\\widehat{\\theta}_n, \\theta) := \\E\\left[(\\widehat{\\theta}_n - \\theta)^2 \\right] \\]\n\n\n\n\n\n\n\n\nBias-Variance Decomposition\n\n\n\\[ \\mathrm{MSE}(\\widehat{\\theta}_n, \\theta) := \\mathrm{Bias}^2(\\widehat{\\theta}_n, \\theta) + \\Var(\\widehat{\\theta}_n) \\]\nwhere \\(\\mathrm{Bias}(\\widehat{\\theta}_n, \\theta) := \\E[\\widehat{\\theta}_n] - \\theta\\)."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#roadmap-for-today",
    "href": "120B-F25/MTRev/MTRev.html#roadmap-for-today",
    "title": "Midterm Review",
    "section": " Roadmap for Today",
    "text": "Roadmap for Today\n\nGo through some slides (including some interactive problems)\nWork through some problems together (on the worksheet; copies can be found at the front of the room)\n\n\n\n\n\n\n\n\nDisclaimer\n\n\nThis review is not intended to be comprehensive; I encourage you to consult the lecture notes, textbook, homework, and your own notes. Just because something does or does not show up on these slides doesn’t mean it is guaranteed to show up / not show up on the exam."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nGeneral Framework\n\n\n\n\n\n\nGoal: Univariate Transformations\n\n\nGiven a random variable Y ~ fY(y), we seek the distribution of U := g(Y) for some real-valued function g.\n\n\n\n\nThree things uniquely characterize a distribution:\n\nIts CDF\nIts PDF\nIts MGF\n\nSo, to identify the distribution of U, we can either find: its CDF (CDF Method), PDF (Method of Transformations), or MGF (MGF Method)\n\n\n\n\n\n\n\n\nExample 1: Guiding Example\n\n\nLet Y ~ Exp(β) for some β &gt; 0, and define U := c Y for some c &gt; 0."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-1",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-1",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nCDF Method\n\nFirst idea: find the CDF FU(u).\nOften a three-step procedure:\n\nWrite \\(F_U(u) := \\Prob(U \\leq u) = \\Prob(g(Y) \\leq u)\\)\nManipulate the event \\(\\{g(Y) \\leq u\\}\\) to be of the form \\(\\{Y \\in B_u\\}\\) for some set Bu\nUse the PDF of Y (which is known!) to evaluate \\(\\Prob(B_u)\\), thereby finding an expression for the CDF FU(u) of U.\n\nAny assumptions? Downsides/potential issues?"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-2",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-2",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nTransforming Intervals/Sets"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-3",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-3",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nCDF Method: Guiding Example\n\n\n\n\n\n\nExample 1: Guiding Example\n\n\nLet Y ~ Exp(β) for some β &gt; 0, and define U := c Y for some c &gt; 0.\n\n\n\n\nStep 1: \\(F_U(u) := \\Prob(U \\leq u) = \\Prob( \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\leq u)\\) \nStep 2: \\(\\{ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\leq u \\} =\\) \nStep 3: \\(F_U(u) =\\)"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-4",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-4",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nMethod of Transformations\n\nIf g is strictly monotonic over the support of X, then \\[ f_U(u) = f_X[g^{-1}(u)] \\cdot \\left| \\frac{\\mathrm{d}}{\\mathrm{d}u} g^{-1}(u) \\right| \\]\n\n\n\n\n\n\n\n\nCaution\n\n\nThis method can only be used if the following assumptions hold:\n\nThe underlying transformation is univariate (i.e. a function of only one random variable)\nThe underlying transforamtion is strictly monotonic (can anyone tell me why?)"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-5",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-5",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nPDF Method: Guiding Example\n\n\n\n\n\n\nExample 1: Guiding Example\n\n\nLet Y ~ Exp(β) for some β &gt; 0, and define U := c Y for some c &gt; 0.\n\n\n\n\nTransformation: \\(g(y) =\\) \nInverse Transformation: \\(g^{-1}(u) =\\) \nDerivative of Inverse: \\(\\left| \\frac{\\mathrm{d}}{\\mathrm{d} u} g^{-1}(u) \\right| =\\) \nPlugging Into Formula:"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-6",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-6",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nMethod of MGFs\n\nA useful fact is that MGFs uniquely determine distributions.\n\nFor example, if I tell you X has MGF \\(M_X(t) = e^{t^2}\\), then you can automatically conclude that \\(X \\sim \\mathcal{N}(0, 2)\\).\n\nTwo useful facts about MGFs:\n\n\\(M_{aX + b}(t) =\\)\nFor independent X and Y, \\(M_{X + Y}(t) =\\)\n\nIn light of these, we see that the MGF method is particularly useful when our transformation involves a linear combination of independent random variables."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#univariate-transformations-7",
    "href": "120B-F25/MTRev/MTRev.html#univariate-transformations-7",
    "title": "Midterm Review",
    "section": " Univariate Transformations",
    "text": "Univariate Transformations\nMGF Method: Guiding Example\n\n\n\n\n\n\nExample 1: Guiding Example\n\n\nLet Y ~ Exp(β) for some β &gt; 0, and define U := c Y for some c &gt; 0.\n\n\n\n\nBy a previously-derived formula, \\(M_U(t) = M_Y(      )\\) \nThe MGF of Y, which we can find                                         , is given by  \nTherefore, the MGF of U is given by \nWe recognize the MGF of U as that of the                        distribution, allowing us to conclude that U ~"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#multivariate-transformations",
    "href": "120B-F25/MTRev/MTRev.html#multivariate-transformations",
    "title": "Midterm Review",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nOutline\n\nWhen it comes to multivariate transformations (i.e. transformations of multiple random variables), there often is not a one-size-fits-all approach.\nA safe bet is usually the CDF method, though the corresponding integrals may be intractable.\nIf the transformation is a linear combination of independent random variables, then the MGF method might be a good bet.\nWe also saw some examples about minima and maxima; take a look through the lecture slides for those."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#multivariate-transformations-1",
    "href": "120B-F25/MTRev/MTRev.html#multivariate-transformations-1",
    "title": "Midterm Review",
    "section": " Multivariate Transformations",
    "text": "Multivariate Transformations\nExample\n\n\n\n\n\n\nExample 2\n\n\nLet \\(X, Y \\iid \\mathrm{Exp}(\\beta)\\) for some \\(\\beta &gt; 0\\). Using whichever method you feel is most appropriate, identify the distribution of:\n\n\\(S := (X + Y)\\)\n\\(Z := \\min\\{X, Y\\}\\)"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling",
    "href": "120B-F25/MTRev/MTRev.html#sampling",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nGeneral Framework\n\n\n\n\n\nGoal: to make inferences about a population parameter.\nTo do so, we take random samples from the population.\nA statistic is a function of a random sample: \\(T := T(Y_1, \\cdots, Y_n)\\)\n\nStatistics, therefore, are random variables; their distributions are called sampling distributions"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-1",
    "href": "120B-F25/MTRev/MTRev.html#sampling-1",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-2",
    "href": "120B-F25/MTRev/MTRev.html#sampling-2",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-3",
    "href": "120B-F25/MTRev/MTRev.html#sampling-3",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-4",
    "href": "120B-F25/MTRev/MTRev.html#sampling-4",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nExample: Cats!"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-5",
    "href": "120B-F25/MTRev/MTRev.html#sampling-5",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nNotation\n\nWith this example, we can highlight an important distinction.\nLet Yi denote the weight of a randomly-selected cat. Random or deterministic?\n\nRandom.\n\nLet yi denote the weight of a specific cat (e.g. Kitty). Random or deterministic?\n\nDeterministic.\n\nDenote \\(\\vect{Y} := \\{Y_i\\}_{i=1}^{n}\\) to be our random sample; let \\(\\vect{y} := \\{y_i\\}_{i=1}^{n}\\) be a realization (aka an observed instance) of our sample \\(\\vect{Y}\\)."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-6",
    "href": "120B-F25/MTRev/MTRev.html#sampling-6",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nNormal Population\n\nTwo common statistics that arise frequently are the sample mean and sample variance, defined as \\[ \\overline{Y}_n := \\frac{1}{n} \\sum_{i=1}^{n} Y_i; \\qquad S_n^2 := \\frac{1}{n - 1} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2 \\]\n\n\n\n\n\n\n\n\nTheorem\n\n\nLet \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, \\sigma^2)\\). Then:\n\n\\(\\overline{Y}_n \\sim \\mathcal{N}\\left( \\mu, \\ \\frac{\\sigma^2}{n} \\right)\\)\n\\(\\left( \\frac{n - 1}{\\sigma^2} \\right) S_n^2 \\sim \\chi^2_{n - 1}\\)"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#review-the-gamma-distribution",
    "href": "120B-F25/MTRev/MTRev.html#review-the-gamma-distribution",
    "title": "Midterm Review",
    "section": " Review: The Gamma Distribution",
    "text": "Review: The Gamma Distribution\n\n\n\nviewof alph = Inputs.range(\n  [0.2, 10], \n  {value: 2, step: 0.1, label: \"α:\"}\n)\n\nviewof bet = Inputs.range(\n  [0.2, 3.1], \n  {value: 1, step: 0.01, label: \"β:\"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njstat = require(\"jstat\")\n\nplt_pdf = Plot.plot({\n    width: 850,\n    height: 375,\n    color: {\n      legend: true\n    },\n    x: {\n      label: \"x\",\n      axis: true\n    },\n    y: {\n      label: \"f(x)\",\n      //axis: false,\n      //domain: [0, d3.max(pdfvals.map(d =&gt; d.pdf))]  \n    },\n    marks: [\n      Plot.ruleY([0]),\n      Plot.ruleX([0]),\n      Plot.line(pdfvals, {x: \"x\", y: \"pdf\", stroke : \"blue\", strokeWidth: 4})\n    ]\n  })\n  \npdfvals = {\n  const x = d3.range(0, 12, 0.01);\n  var pdf;\n  pdf = x.map(x =&gt; ({x: x, pdf: jstat.gamma.pdf(x, alph, bet)}));\n  return pdf\n}"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#review-the-chi2_nu-distribution",
    "href": "120B-F25/MTRev/MTRev.html#review-the-chi2_nu-distribution",
    "title": "Midterm Review",
    "section": " Review: The \\(\\chi^2_{\\nu}\\) distribution",
    "text": "Review: The \\(\\chi^2_{\\nu}\\) distribution\n\n\n\nviewof nu = Inputs.range(\n  [0.2, 10], \n  {value: 3, step: 0.1, label: \"ν:\"}\n)\n\n\n\n\n\n\n\nplt_pdf2 = Plot.plot({\n    width: 850,\n    height: 375,\n    color: {\n      legend: true\n    },\n    x: {\n      label: \"x\",\n      axis: true\n    },\n    y: {\n      label: \"f(x)\",\n      //axis: false,\n      //domain: [0, d3.max(pdfvals.map(d =&gt; d.pdf))]  \n    },\n    marks: [\n      Plot.ruleY([0]),\n      Plot.ruleX([0]),\n      Plot.line(pdfvals2, {x: \"x\", y: \"pdf\", stroke : \"blue\", strokeWidth: 4})\n    ]\n  })\n  \npdfvals2 = {\n  const x = d3.range(0, 12, 0.01);\n  var pdf;\n  pdf = x.map(x =&gt; ({x: x, pdf: jstat.gamma.pdf(x, nu/2, 2)}));\n  return pdf\n}"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-7",
    "href": "120B-F25/MTRev/MTRev.html#sampling-7",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nt- and F-distributions\n\n\n\n\n\n\n\nDefinition: t-Distribution\n\n\nIf \\(Z \\sim \\mathcal{N}(0, 1)\\) and \\(U \\sim \\chi^2_{\\nu}\\) with \\(Z \\perp U\\), then \\[ T := \\frac{Z}{\\sqrt{U / \\nu}} \\sim t_{\\nu} \\]\n\n\n\n\n\n\n\n\n\n\n\nDefinition: F-Distribution\n\n\nIf \\(U_1 \\sim \\chi^2_{\\nu_1}\\) and \\(U_2 \\sim \\chi^2_{\\nu_2}\\) with \\(U_1 \\perp U_2\\), then \\[ F := \\frac{U_1 / \\nu_1}{U_2 / \\nu_2} \\sim F_{\\nu_1, \\nu_2} \\]"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-8",
    "href": "120B-F25/MTRev/MTRev.html#sampling-8",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nConvergence in Distribution\n\n\n\n\n\n\nDefinition: Convergence in Distribution\n\n\nA sequence \\(\\{X_n\\}_{n \\geq 1}\\) of random variables is said to converge in distribution to another random variable \\(X\\) if, for every point \\(x\\) at which the CDF of \\(X\\) is continuous, \\[ \\lim_{n \\to \\infty} \\Prob(X_n \\leq x) = \\Prob(X \\leq x) \\] in which case we write \\[ X_n \\distto X \\]"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-9",
    "href": "120B-F25/MTRev/MTRev.html#sampling-9",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nCentral Limit Theorem\n\n\n\n\n\n\nCentral Limit Theorem\n\n\nLet \\(Y_1, \\cdots, Y_n\\) denote an i.i.d. sample from a distribution with mean \\(\\mu\\) and finite variance \\(\\sigma^2 &lt; \\infty\\). Then \\[ \\frac{\\sqrt{n}(\\overline{Y}_n - \\mu)}{\\sigma} \\distto \\mathcal{N}(0, 1) \\] which we can sometimes write as, for sufficiently large n, \\[ \\overline{Y}_n \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left( \\mu , \\ \\frac{\\sigma^2}{n} \\right) \\sim \\mathcal{N}\\left( \\E[Y_i], \\ \\frac{\\Var(Y_i)}{n} \\right) \\]\n\n\n\n\nThe symbol \\(\\stackrel{\\cdot}{\\sim}\\) can be read as “approximately distributed as”\nhttps://epm027.shinyapps.io/CLT_Gamma/"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#sampling-10",
    "href": "120B-F25/MTRev/MTRev.html#sampling-10",
    "title": "Midterm Review",
    "section": " Sampling",
    "text": "Sampling\nDeMoivre-Laplace Theorem (Normal Approx. to Binomial)\n\n\n\n\n\n\nDeMoivre-Laplace Theorem\n\n\nLet \\(X_n \\sim \\mathrm{Bin}(n, p)\\). Then \\[ \\frac{X_n - np}{\\sqrt{np(1 - p)}} \\distto \\mathcal{N}\\left( 0, 1 \\right) \\] More specifically, provided that \\(n &gt; p \\cdot (\\max\\{p, 1 - p\\} / \\min\\{p, 1 - p\\})\\) then \\[ X_n \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left( np, \\ np(1 - p) \\right) \\]\n\n\n\n\nThis is what we called the “Normal Approximation to the Binomial Distribution” (in Topic 06). Keep in mind the continuity correction.\n\nNotice that it is essentially just a special case of the CLT, since a Binomial distribution can be decomposed as a sum of i.i.d. Bernoulliis!"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-1",
    "href": "120B-F25/MTRev/MTRev.html#estimation-1",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nGeneral Framework\n\nThe goal of estimation is, as the name suggests, to use samples (specifically, sample statistics) to estimate the value of a population parameter.\nThree key terms:\n\nEstimand: another word for the parameter we are trying to estimate.\nEstimator: a statistic being used to estimate the estimand.\n\nAnother way to think about this: a “rule” used to estimate the parameter.\n\nEstimate: a particular realization (i.e. observed instance) of an estimator."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-2",
    "href": "120B-F25/MTRev/MTRev.html#estimation-2",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nExample\n\n\n\n\n\n\nExample\n\n\nA vet wishes to estimate the true weight of all cats in the world. She takes a sample of 10 cats, and finds their average weight to be 9.12 lbs.\n\n\n\n\nThe estimand is the true average weight of all cats in the world (which we can call µ).\nThe estimator is the sample mean: we are using sample means to estimate µ.\nThe estimate in this scenario is 9.12 lbs, as this is a particular realization of our estimator."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-3",
    "href": "120B-F25/MTRev/MTRev.html#estimation-3",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nGoodness-of-Fit\n\nGiven that there are potentially many estimators we could use to estimate a particular estimand, it’s useful to develop a metric of how well a particular estimator is performing (or, equivalently, on how to compare the performance of two estimators).\n\n\n\n\n\n\n\n\nDefinition: Bias\n\n\nThe bias of an estimator \\(\\widehat{\\theta}_n\\) being used to estimate a parameter \\(\\theta\\) is defined to be \\[ \\mathrm{Bias}(\\widehat{\\theta}_n) := \\E[\\widehat{\\theta}_n] - \\theta \\] The estimator is said to be unbiased if its bias is zero; i.e. if \\(\\E[\\widehat{\\theta}_n] = \\theta\\).\n\n\n\n\n\nAn unbiased estimator, “on average, gets it right”."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-4",
    "href": "120B-F25/MTRev/MTRev.html#estimation-4",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nAn Analogy\n\nUnbiasedness, however, is often not enough. To motivate why, let’s take a look at an analogy.\nAn analogy is often drawn between estimation and hitting a bullseye.\n\nThe bullseye is akin to our estimand, and estimates are represented by shots fired at the target.\nThe estimator is, therefore, akin to the marskperson.\n\nAn unbiased estimator is analogous to a marksperson for whom the average location of shots is the bullseye."
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-5",
    "href": "120B-F25/MTRev/MTRev.html#estimation-5",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nTwo Markspersons\n\nWhich of the following markspersons are “better”?\n\n\n\n\n\nMarksperson 1\n\n\n\n\nMarksperson 2"
  },
  {
    "objectID": "120B-F25/MTRev/MTRev.html#estimation-6",
    "href": "120B-F25/MTRev/MTRev.html#estimation-6",
    "title": "Midterm Review",
    "section": " Estimation",
    "text": "Estimation\nMean Squared-Error (MSE)\n\nSo, unbiasedness is not enough; we’d also like small variance.\nTo that end, we introduce the mean squared-error (MSE) of an estimator: \\[ \\mathrm{MSE}(\\widehat{\\theta}_n) := \\E\\left[(\\widehat{\\theta}_n - \\theta)^2 \\right] \\]\n\n\n\n\n\n\n\n\nBias-Variance Decomposition\n\n\n\\[ \\mathrm{MSE}(\\widehat{\\theta}_n) := \\mathrm{Bias}^2(\\widehat{\\theta}_n) + \\Var(\\widehat{\\theta}_n) \\]\n\n\n\n\n\nQuestion: should a “good” estimator have very high or very low MSE?"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#hello",
    "href": "120B-F25/Wk01/wk1.html#hello",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Hello!",
    "text": "Hello!\nA Quick Introduction\n\nHello! My name is Ethan (he/him), and I will be taking over from Sirui.\n\nI am a sixth year PhD; this is my fourth time with this course (including having been the Instructor once :) )\n\nMy Office Hours: Wednesdays, 11:30 am - 12:30 pm in South Hall 5607F (Inside the PSTAT Main Office, on the Fifth Floor of South Hall)\n\nThese have been posted to Canvas as well.\n\nMy Email: epmarzban@pstat.ucsb.edu (please allow a 24 business hour response time)"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#distributions",
    "href": "120B-F25/Wk01/wk1.html#distributions",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Distributions",
    "text": "Distributions\nWhat Makes Them Unique?\n\n\n\n\n\n\nQuestion\n\n\nWhat uniquely determines a distribution?\n\n\n\n\nOne of three things:\n\n\nAn MGF (Moment-Generating Function)\nA CDF/CMF (Cumulative Distribution/Mass Function)\nA PDF/PMF (Probability Density/Mass Function)"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#distributions-1",
    "href": "120B-F25/Wk01/wk1.html#distributions-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Distributions",
    "text": "Distributions\nWhat Makes Them Unique?\nFor Example:\n\nIf I tell you X is a random variable with MGF MX(t) = et2, you can immediately tell me that X follows a Normal Distribution with mean 0 and variance 2.\nIf I tell you Y is a random variable with density given by fY(y) = 2e-2y for y &gt; 0 and 0 otherwise, you can immediately tell me that Y follows an Exponential Distribution with scale parameter 1/2.\n\n\nNot all distributions have names, but they can still be uniquely defined; e.g. a random variable Z with density fZ(z) = π cos(π z) for 0 ≤ z ≤ 1 and 0 otherwise"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#transformations",
    "href": "120B-F25/Wk01/wk1.html#transformations",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Transformations",
    "text": "Transformations\n\n\n\n\n\n\nGoal\n\n\nGiven a random variable Y and a function h, we wish to identify the distribution of U := h(Y).\n\n\n\n\nCan be accomplished by finding:\n\nThe MGF of U (MGF Method)\nThe CDF/CMF of U (CDF Method)\nThe PDF/PMF of U (Inverse Transformation Method, or Change of Variable)\n\n\n\nThis is essentially the roadmap for the next few lectures/weeks in this course!"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#transformations-1",
    "href": "120B-F25/Wk01/wk1.html#transformations-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Transformations",
    "text": "Transformations\nMight seem abstract… but quite applicable!\n\nUnit Conversion: the temperature C in Centigrade at a randomly-selected location in a city follows some distribution; what is the distribution of temperatures F as measured in Fahrenheit?\n\nExample of a univariate transformation; i.e. a transformation of only one random variable\n\nData Summary: given an i.i.d. collection of random variables, what is the distribution of the sample mean? Or, the sample variance? Or, the sample maximum?\n\nExamples of multivariate transformations; i.e. transformations involving multiple random variables"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#moment-generating-functions",
    "href": "120B-F25/Wk01/wk1.html#moment-generating-functions",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Moment Generating Functions",
    "text": "Moment Generating Functions\n\n\n\n\n\n\nDefinition\n\n\nThe Moment Generating Function (MGF) for a random variable Y is defined as \\[ M_Y(t) := \\mathbb{E}[e^{tY}] \\]\n\n\n\n\nQuestion for you: When do we compute an MGF as a sum, and when do we compute it as an integral?\n\n\n\n\n\n\n\n\nProperties of MGFs\n\n\n\n\\(M_{aY + b}(t) = e^{bt} M_Y(at)\\)\nFor independent \\(X\\) and \\(Y\\), \\(M_{X + Y}(t) = M_X(t) \\cdot M_Y(t)\\)\nMoment-Generating Property: \\(M_Y^{(n)}(0) = \\E[Y^n]\\)"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#moment-generating-functions-1",
    "href": "120B-F25/Wk01/wk1.html#moment-generating-functions-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " Moment Generating Functions",
    "text": "Moment Generating Functions\nExample\n\nPartially Worked-Out Example: Y ~ Exp(β) (note the parametrization being used in 120B is different from that in 120A!)\n\n\n\\[ M_Y(t) = \\int_{0}^{\\infty} e^{ty} \\cdot \\frac{1}{\\beta} e^{-y/\\beta} \\ \\mathrm{d}y = \\frac{1}{\\beta} \\int_{0}^{\\infty} e^{-\\left(\\frac{1}{\\beta} - t \\right)y}  \\ \\mathrm{d}y \\]\n\n\nThis integral is finite only when \\((\\frac{1}{\\beta} - t) &gt; 0\\); i.e. when \\(t &lt; 1/\\beta\\). When it is finite: \\[\\begin{align}\n  \\class{fragment}{{} M_Y(t)}\n&\\class{fragment}{{} = \\frac{1}{\\beta} \\cdot {\\color{blue} \\frac{1}{\\left( \\frac{1}{\\beta} - t \\right)} } \\cdot  \\int_{0}^{\\infty} {\\color{blue} \\left( \\frac{1}{\\beta} - t \\right) }  e^{-\\left(\\frac{1}{\\beta} - t \\right)y}  \\ \\mathrm{d}y}  \\\\[1mm]\n&\\class{fragment}{{} = \\frac{1}{\\beta} \\cdot  \\frac{1}{\\left( \\frac{1}{\\beta} - t \\right)} = \\frac{1}{1 - \\beta t}}   \\\\[3mm]\n\\end{align}\\]"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#cdf-method",
    "href": "120B-F25/Wk01/wk1.html#cdf-method",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " CDF Method",
    "text": "CDF Method\n\nGeneral Idea: Write \\(F_U(u) := \\mathbb{P}(U \\leq u)\\)\n\nMain task is to write the event \\(\\{U \\leq u\\}\\) in terms of Y, since everything about Y is known.\nMy advice: a picture is worth a thousand words!"
  },
  {
    "objectID": "120B-F25/Wk01/wk1.html#cdf-method-1",
    "href": "120B-F25/Wk01/wk1.html#cdf-method-1",
    "title": "PSTAT 120B: Mathematical Statistics",
    "section": " CDF Method",
    "text": "CDF Method\n\nRecall the example from lecture: X ~ Unif[-1, 1] and Y = X2\n\nhttps://www.youtube.com/watch?v=HtzqjHfoRbw"
  }
]