---
title: "PSTAT 120B: Mathematical Statistics"
subtitle: "Ethan's Week 4 Discussion Section"
footer: "PSTAT 120B - Fall 2025 with Dr. Uma Ravat; material © Ethan P. Marzban"
logo: "Images/120b_logo.svg"
format: 
  clean-revealjs:
    theme: ../slides.scss
    transition: fade
    slide-number: true
    incremental: true 
    chalkboard: true
    menu:
      side: left
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Ethan P. Marzban
    affiliations: Department of Statistics and Applied Probability; UCSB <br /> <br />
institute: October 24, 2025
title-slide-attributes:
    data-background-image: "Images/120b_logo.svg"
    data-background-size: "30%"
    data-background-opacity: "0.5"
    data-background-position: 80% 50%
code-annotations: hover
---

<style>
mjx-math {
  font-size: 80% !important;
}
</style>

<script>
MathJax = {
  options: {
    menuOptions: {
      settings: {
        assistiveMml: false
      }
    }
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async src="path-to-MathJax/tex-chtml.js"></script>


$$
\newcommand\R{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\1}{1\!\!1}
\newcommand{\comp}[1]{#1^{\complement}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\SD}{\mathrm{SD}}
\newcommand{\vect}[1]{\vec{\boldsymbol{#1}}}
\newcommand{\tvect}[1]{\vec{\boldsymbol{#1}}^{\mathsf{T}}}
\newcommand{\hvect}[1]{\widehat{\boldsymbol{#1}}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\tmat}[1]{\mathbf{#1}^{\mathsf{T}}}
\newcommand{\Cov}{\mathrm{Cov}}
\DeclareMathOperator*{\argmin}{\mathrm{arg} \ \min}
\newcommand{\iid}{\stackrel{\mathrm{i.i.d.}}{\sim}}
$$

```{css echo = F}
.hscroll {
  height: 100%;
  max-height: 600px;
  max-width: 2000px;
  overflow: scroll;
}
```

```{r setup, echo = F}
library(tidyverse)
library(countdown)
library(fixest)
library(modelsummary) # Make sure you have >=v2.0.0
library(GGally)
library(ggokabeito)
library(reshape2)
library(pander)
library(gridExtra)
library(cowplot)
library(palmerpenguins)
library(plotly)
library(tidymodels)
```


## {{< fa backward-fast >}} Recap
### Framework for Statistical Inference

:::: {.columns}

::: {.column width="50%"}
![](Images/Inference.svg)
:::

::: {.column width="50%"}
-   **Goal:** to make inferences about a population parameter.

-   To do so, we take random [**samples**]{.alert} from the population.

-   A [**statistic**]{.alert} is a function of a random sample: $T := T(Y_1, \cdots, Y_n)$
    -   Statistics, therefore, are random variables; their distributions are called [**sampling distributions**]{.alert}

:::

::::



## {{< fa backward-fast >}} Recap
### Inference

-   Inference is, broadly speaking, divided into two subcategories: [**estimation**]{.alert} and [**hypothesis testing**]{.alert}

-   We'll start by talking about estimation, and then later talk about hypothesis testing.

-   In estimation, we specifically seek to _estimate_ the value of a population parameter
    -   E.g. the true average weight of all cats in the world

-   In fact, let's continue with this "average cat weight" example.


## {{< fa sign-hanging >}} Estimation
### General Framework

::: {.callout-tip}
## **Goal**

To estimate the true average weight of all cats in the world.
:::

-   Last week, we talked about taking samples of cats and recording their weights.

-   It seems natural that the average of our _sampled_ cat weights should correspond, in some way, to the average of _all_ cats in the world.

-   This is the basic idea behind estimation: we'll use _statistics_ (functions of our sample) to estimate the true value of a parameter.
    -   E.g. using the _sample_ average cat weight to say something about the true _population_ average cat weight.

## {{< fa sign-hanging >}} Estimation
### General Framework

-   Three key terms:
    -   [**Estimand:**]{.alert} another word for the parameter we are trying to estimate.
    -   [**Estimator:**]{.alert} a statistic being used to estimate the estimand.
        -   Another way to think about this: a "rule" used to estimate the parameter.
    -   [**Estimate:**]{.alert} a particular _realization_ (i.e. _observed instance_) of an estimator.
    
## {{< fa sign-hanging >}} Estimation
### Example

::: {.callout-tip}
## **Example**

A vet wishes to estimate the true weight of all cats in the world. She takes a sample of 10 cats, and finds their average weight to be 9.12 lbs.
:::

-   The **estimand** is the true average weight of all cats in the world (which we can call µ).

-   The **estimator** is the sample mean: we are using sample means to estimate µ.

-   The **estimate** in this scenario is 9.12 lbs, as this is a particular realization of our estimator.

## {{< fa sign-hanging >}} Estimation
### Desirable Properties of Estimators

-   There are potentially _many_ estimators we can use to estimate a particular parameter.

-   As such, it is necessary to establish a notion of what makes a "good" estimator (or, equivalently, what makes one estimator "better" than another).

-   One notion is [**unbiasedness**]{.alert}: an estimator $\widehat{\theta}_n$ for $\theta$ is said to be _unbiased_ if $\E[\widehat{\theta}_n] = \theta$.
    -   "On average, the estimator gets it right."
    -   Mathematically: means the sampling distribution is centered at the right (true) value.
  

## {{< fa sign-hanging >}} Estimation
### An Analogy

-   Unbiasedness, however, is often not enough. To motivate why, let's take a look at an analogy.

-   An analogy is often drawn between estimation and hitting a bullseye.
    -   The bullseye is akin to our estimand, and estimates are represented by shots fired at the target. 
    -   The estimator is, therefore, akin to the marskperson.
    
-   An unbiased estimator is analogous to a marksperson for whom the average location of shots is the bullseye.

## {{< fa sign-hanging >}} Estimation
### Two Markspersons

-   Which of the following markspersons are "better"? 

:::: {.columns}

::: {.column width="50%"}
::: {.fragment style="text-align:center"}
![](Images/mark1.svg){width="50%"}

**Marksperson 1**
:::
:::


::: {.column width="50%"}
::: {.fragment style="text-align:center"}
![](Images/mark2.svg){width="50%"}

**Marksperson 2**
:::
:::

::::



## {{< fa sign-hanging >}} Estimation
### Two Markspersons

-   So, unbiasedness is not enough; we'd also like small _variance_.

-   To that end, we introduce the [**mean squared-error**]{.alert} (MSE) of an estimator:
$$ \mathrm{MSE}(\widehat{\theta}_n, \theta) := \E\left[(\widehat{\theta}_n - \theta)^2 \right] $$

::: {.fragment}
::: {.callout-important}
## **Bias-Variance Decomposition**
$$ \mathrm{MSE}(\widehat{\theta}_n, \theta) := \mathrm{Bias}^2(\widehat{\theta}_n, \theta) + \Var(\widehat{\theta}_n) $$

where $\mathrm{Bias}(\widehat{\theta}_n, \theta) := \E[\widehat{\theta}_n] - \theta$.
:::
:::

